Respondent ID,Collector ID,Start Date,End Date,IP Address,Email Address,First Name,Last Name,Custom Data 1,What is your name?,What is your work email?,Which TII research center are you from?,What is your job role or job title?,Have you heard about generative AI?,"Have you tried generative AI applications such as ChatGPT, MidJourney, or Dall-E?",Have you written any prompts with an AI tool before?,Can you list some AI tools that you have worked with?,How do you think AI tools such as ChatGPT can help with your job?,Can you think of any potential generative AI use cases in your work?,What do you want to get the most out of the generative AI training courses?,,,,,,,,,Do you have experience with Python programming?,How many years of python programming experience do you have?,"On a scale of 1 to 10, how would you rate your python skills?

1 indicating that you do not know python
","Select the all correct way to remove the key ""marks"" from a dictionary https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/203560f2-adaf-4cdf-beb8-1cb48ddc8bdd.png",,,,What is the output of the following nested loop? https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/747d416d-861d-44cb-b352-9c6b1c684675.png,Guess the correct output of the following code? https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/54147750-fd55-4a69-b477-f74d8af6cea8.png,"A palindrome is a word, phrase, number, or other sequence of characters that reads the same forwards and backwards (ignoring spaces, punctuation, and capitalization, in the case of phrases). In other words, it is a symmetric sequence.in this challenge we are trying to find the best code to solve a palindrome task, what are the best code examples to achieve this results from the following options [Check all that applies]:",,,,"In this task, we are attempting to rank the highest salaries within an organization. After running this code, we encountered unexpected results. For instance, the 3rd and 5th highest salaries are shown as 85,000 and 80,000, respectively. However, the expected values for the 3rd and 5th ranks should be 80,000 and 72,000, respectively. What possible edits can you suggest to make the code display the correct results? [Check all that applies] https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/2767c342-fafa-4062-9ff3-29db2399cb97.png",,,,"Here's an Example for sales made by company X for two products. Using pandas, what is the correct code to use to summarize the sales by product: https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/52f01251-78aa-41ea-94e8-56bae994a391.png",,,,"In the next example, there is a 'Shape' superclass that has a function. There are two subclasses: the first one is 'Circle,' and the second one is 'Rectangle.' When creating new instances from the 'Circle' or 'Rectangle' subclasses, the user is able to use the 'area' function from the 'Shape' superclass. Which core principle from OOP is being used here? https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/b166aa3f-f7c4-4b64-b4f2-639af818b2f7.png","On a scale of 1 to 10, how would you rate your machine learning experience?

1 → I have not worked with machine learning at all 
5 → I'm familiar with data analysis & manipulation using Python, understand ML concepts, but don't have a lot of hands-on experience 
7 → I have practical experience with ML with Python but I haven't worked with deep learning and libraries such as PyTorch 
10 → I'm very familiar with ML concepts and have worked on Machine Learning and Deep Learning problems in my current/past jobs for 2+ years 
","Hands-on Coding Challenge---------------------------------------Alternatively, you can access the Google Colab environment here: NotebookGiven the following sentence: ""Hello! We are super excited to have you join the program to learn about generative AI amongst other things!"", package the word count without punctuation into a {'word1': count,...} dictionary-------Input: python string type (str)Constraints:

Ensure punctuation are stripped.
Cannot use python `Counter` function

Example incorrect output below :{'hello!': 1, ""we're"": 1, 'super': 1, 'excited': 1, 'to': 1, 'have': 1, 'you': 1, 'join': 1, 'our': 1, 'ai': 1, 'bootcamp': 1, 'learn': 1, 'about': 1, 'nlp': 1, 'amongst': 1, 'other': 1, 'things!': 1}Example expected output:{'hello': 1, 'super': 1, 'excited': 1, 'join': 1, 'bootcamp': 1, 'learn': 1, 'nlp': 1, 'amongst': 1, 'things': 1}To submit your solution, you can do one of the following:

Upload your code to OneDrive and share the link in the comment box below (please make it accessible to all)
Use Colab to complete the task and share the colab link below
Paste your python code directly in the box below 
","Given g(x, y), find its partial derivative with respect to x https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/67aab7f5-bddf-4332-94fa-52a43457a98f.png",There are several tree splitting criterion for classification problems in a decision tree. Choose the correct splitting criterion,,,,,,"To study factors affecting the decision of a frog to jump (or not) (label), a data scientist collects data pertaining to several independent binary co-variates (features) from a Brazilian rain-forest.Without explicitly determining the information gain values for each of the three attributes, which attribute should be chosen as the attribute by which the decision tree should be first partitioned? e.g which attribute has the highest predictive power regarding the decision of the frog to jump. https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f61f9b65-ecc0-49c2-8e27-1a46448d8287.png",Which of the following is a common loss function for classification problems?,,,,,Which of the following evaluation metrics is/are commonly used for classification problems?,,,,,,"You trained a model that gives 99% accuracy, what's the next action you'd take?",,,,,What following approaches would you apply to improve your ML model performance?,,,,,What is the difference between bagging and boosting?,"In PyTorch when we build a neural networks model, we sometimes use zero_grad() function. Choose the answers that are correct",,,,,Choose all that applies regarding the nn.Squential and nn.Module APIs in PyTorch,"During the training of an ANN, a sigmoid layer applies the sigmoid function to every element in the forward pass, while in the backward pass the chain rule is being utilized as part of the back-propagation algorithm. With respect to the back-propagation algorithm, given a sigmoid activation function, and a J as the cost function. Code snippet below provides a pure Python-based implementation of the forward pass for the sigmoid function. Complete the backward pass that directly computes the analytical gradients.Expected answer: grad_input =  _______________________________  https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/e113fa40-d515-4d71-a3d3-dcb68a064e2a.png","Hands-on Coding Challenge---------------------------------------This is a technical test to assess your hands-on experience with building ML models. You will be working with a ficticious dataset and follow the questions to build a machine learning classification model.Libraries to consider using: 

Pandas
NumPy
Matplotlib
Sklearn (scikit-learn) or PyTorch
imbalanced-learn

Starter Code---------------------------------------import pandas as pdimport numpy as npimport matplotlib.pyplot as plt%matplotlib inline# Download the test datasetfrom imblearn.datasets import fetch_datasetsdata = fetch_datasets()['wine_quality']# Separate data into features [X] and lable [y]data['target']X = data['data']y = data['target']Assessment Questions---------------------------------------Please follow the suggested steps below to build and evaluate an ML model that predicts wine quality.1. Apply visualizations techniques to explore the dataset2. Create holdout dataset (or apply cross validation)3. Scale the features4. Check for label distribution and apply resampling accordingly5. Choose one of the classification algorithms: random forest, gradient boosting, xgboost6. Tune hyperparameters7. Evaluate and create the performance report8. Explain the top variables.Submission---------------To submit your solution, you can do one of the following:

Upload your code to OneDrive and share the link in the comment box below (please make it accessible to all)
Use Colab to complete the task and share the colab link below
Paste your python code directly in the box below
","On a scale of 1 to 10, how would you rate your experience with data management and processing when it comes to augmentation, synthetic data generation, data cleaning, etc.?

1 - I don't know about data processing
10 - I have expert experience with data augmentation, synthetic data generation, data cleaning
",Select data augmentation techniques that are commonly used for Computer Vision tasks,,,,,,,"As one of the simplest image labeling techniques, bounding boxes are rectangular boxes that identify the position of an object in an image or video. Select all computer vision applications that can be labelled using bounding box techniques",,,,,,,,Select data augmentation techniques that are commonly used for NLP tasks,,,,,,,What type of NLP labelling is the following? https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/feea7761-cd9d-4873-b04c-c1611a87576c.png,Can you list different methods of noise removal for time series data?,,,,"Coding Challenge #1 Use python to extract all images (urls) and captions (or taglines) on this wikipedia page: https://en.wikipedia.org/wiki/Generative_artificial_intelligenceSuggested library: beautifulsoupSubmission---------------To submit your solution, you can do one of the following:

Upload your code to OneDrive and share the link in the comment box below (please make it accessible to all)
Use Colab to complete the task and share the colab link below
Paste your python code directly in the box below
","Coding Challenge #2Download the following image from wikipedia using python request library and then create augmented versions of the image:

rotated image
flipped image
sharpened image

Submission---------------To submit your solution, you can do one of the following:

Upload your code to OneDrive and share the link in the comment box below (please make it accessible to all)
Use Colab to complete the task and share the colab link below
Paste your python code directly in the box below
 https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/b6942c75-c56e-4454-ae13-4d163074b7dc.png","On a scale of 1 to 10, how would you rate your experience with NLP?

1 - I don't know NLP
10 - I have expert experience with NLP
",Which of the following is/are text pre-processing techniques? (select all that applies).,,,,,Choose the models below that are large language models,,,,,Choose all that applies regarding Transformer models,,,,,What are some common data preprocessing practices for LLM? (Select all that apply),,,,,,What is Morphological Segmentation?,What is Coreference Resolution?,,,,,,What following topics are commonly discussed and researched in the Semantic Analysis?,,,,,,,Why does the following code fail? https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/2a6b5514-ff19-46e5-82c7-2ba72d43a5d7.png,Is the following statement True or false? A language model usually does not need labels for its pretraining.,Which of those types of models would you use for summarizing texts?,,,,,"How many dimensions does the tensor output by the base Transformer model have, and what are they?",Which of the following is an example of subword tokenization? (Choose all that applies),,,,,,Choose all that applies about attention mechanism,,,,,What does the result variable contain in this code sample? https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/18c20501-f6c0-4ab8-846c-20d7f21c8275.png,What's possibly wrong with the code below?  https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f17aa752-4823-44d1-b6fa-0e50ba8c4822.png,Which of the following tasks can be framed as a token classification problem?,What are the labels in a masked language modeling problem?,Which of these tasks can be seen as a sequence-to-sequence problem?,,,,,"On a scale of 1 to 10, how would you rate your experience with Computer Vision?1 - I don't know Computer Vision10 - I have expert experience with Computer Vision",Choose all the CNN architectures below,,,,,,,"Is the following statement true :With the convolution and pooling layers, CNN models don't need a fully connected layer anymore.","The following question discusses the method of fixed feature extraction from layers of the VGG19 architecture for the classification of pancreatic cancer. It depicts FE principles which are applicable with minor modifications to other CNNs as well. In the figure below, three different classes of pancreatic cancer are displayed: A, B and C, curated from a dataset of 4K Whole Slide Images (WSI) labeled by a board certified pathologist. Your task is to use FE feature extraction to correctly classify the images in the dataset.Describe how the VGG19 CNN may be used as fixed feature extractor for a classification task. In your answer be as detailed as possible regarding the stages of feature extraction and the method used for classification. https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/c8cacc75-c128-4fe4-8445-8edc6791540a.png","Referring to VGG Architecture table in the previous question, suggest three different ways in which features can be extracted from a trained VGG19 CNN model. In each case, state the extracted feature layer name and the size of the resulting feature vector.","Referring to VGG Architecture table in the previous questions, after successfully extracting the features for the 4K images from the dataset, how can you now classify the images into their respective categories?","Referring to the VGG10 code snippet in the previous example, what should be the value of pretrained, self.features, self.num_feats, and f ?","Image shown below is artistic style transfer using the style of Francis Picabia's Udnie painting. In neural style transfer models, which loss is being utilized during the training process? Also, please briefly describe the use of activations in the training process. https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/5378985f-3d94-4b6b-920c-fb620b36deaf.png","In computer vision, what does the equation below represent? What does g(t) represent? https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/54927c8e-48cd-4213-b265-6643630f51da.png",What morphological operations do you know?,,,,,,,What's the difference between sampling and quantization?,,,,
,,,,,,,,,Open-Ended Response,Open-Ended Response,Open-Ended Response,Open-Ended Response,Response,Response,Response,Open-Ended Response,Open-Ended Response,Open-Ended Response,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,Gain some exposure and jargon in the generative AI field,Other (please specify),Response,Response,Response,"del student[""marks""]","student.pop(""marks"")","student.remove(""marks"")",I don't' know,Response,Response,def is_palindrome(s): return s == s[::-1],def is_palindrome_1(s): return s == s[::2],def is_palindrome_2(s): return s.lower() == s[::-1].lower(),I don't know,adding .drop_duplicates() to employee['salary'],reverse the table order ascending=True,adjust the referencing to be iloc[N],I don't know,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/a8a2caac-d234-4be3-96e6-ab97d88fb9cb.png,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/4b0a1e6b-c3dd-48f4-9437-0286177c6d83.png,I don't know,Response,Response,Open-Ended Response,Response,Gini,Entropy,Sum of squared error (variance),Hinge,All of the mentioned,I don't know,Response,Cross-entropy loss,Huber loss,Mean squared error,All of the above,I don't know,F-1 score,R-squared,Mean squared error,Precision & Recall,All of the above,I don't know,Celebrate the great performance and try to deploy the model,Look for data leakage,See if it's an imbalanced dataset and apply oversampling,Try a different evaluation metric,I don't know,Keep adding more training data,Try different algorithms,Combine different models,Try stochastic gradient descent instead of batch gradient descent,Apply feature engineering techniques,Response,PyTorch uses zero_grad() to sets all the gradients to zero for all the parameters in the model.,It ensures that the gradients are fresh and ready to be computed for the current iteration.,It's often called after running the backward() function during training.,All of the above,I don't know,Response,Open-Ended Response,Open-Ended Response,Response,Adding noise,Synonym replacement,Flipping,Random insertion,Scaling,All of the above,I don't know,"Autonomous driving and robotics to detect objects such as cars, people, or houses",e-Commerce product categorization,Household object detection for augmented reality applications,Anomaly detection in medical diagnostic imaging,Facial feature points for face detection,"Irregular objects such as buildings, vehicles, or trees for autonomous vehicles",All of the mentioned,I don't know,Back translation,Synonym replacement,Random deletion,Cropping,Text generation,Trasformer-based,Scaling,Response,binning,moving average smoothing,random sampling,all of the above,Open-Ended Response,Open-Ended Response,Response,Stop-word Removal,Sentence Segmentation,Stemming,Lemmatization,Tokenization,Word2Vec,GPT,T5,BERT,I don't know,T5 is a encoder-decoder mixed models,BERT models are encoder models,GPT-3 is an autoregressive model,GPT models are encoder-only models,I don't know,Data cleaning,Deduplication,Decontamination,Toxicity and Bias Control,PII Control,I don't know,Response,Anaphora Resolution,"Given a sentence or larger chunk of text, determine which words (“mentions”)",Refer to the same objects (“entities”),All of the above,None of the above mentioned,I don't know,Co-reference resolution,Semantic-role labelling,Named entity recognition,Word sense disambiguation,Machine Translation,All of the mentioned,I don't know,Response,Response,An encoder model,A decoder model,A sequence-to-sequence model,All of the above,I don't know,Response,WordPiece,Character-based tokenization,Splitting on whitespace and punctuation,BPE,Unigram,All of the above,"In NLP, attention mechanism is useful in sequence to sequence tasks such as translation, speech recognition, and summarization",The attention mechanism is good at handling long sequence input,Local attention helps reduce the computation burden,Attention mechanism is good at context-aware processing,I don't know,Response,Response,Response,Response,Writing short reviews of long documents,Answering questions about a document,Translating a text in Arabic into English,Fixing the messages sent by my nephew/friend so they're in proper English,I don't know,Response,MobileNet,LeNet,GAN,ViT,VGG,Stable Diffusion,I don't know,Response,Open-Ended Response,Open-Ended Response,Open-Ended Response,Response,Open-Ended Response,Open-Ended Response,Erosion,Dilation,Opening,Closing,Morphological Gradient,Top Hat,Black Hat,Sampling is the process that determines the size of the image to be obtained,Sampling is dependent on both the content and the size of the image,Quantization is a process that determines the value of each pixel in the image,All of the above,I don't know
1.14428E+11,427913904,10/04/2023 03:46:30 PM,10/04/2023 03:57:18 PM,2.50.149.139,,,,,Ali Saleh Alblooshi,Ali.Alblooshi@tii.ae,DERC,Mechanical Engineer,Yes,No,I do not understand what a prompt is,NA,professional writing ,Target Detection ,,,,To gain technical experience with machine learning and AI,,,,,,No,I do not know Python,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 12:39:43 PM,10/04/2023 03:36:03 PM,86.97.116.11,,,,,Shamma Almazrouei ,Shamma.almazrouei@tii.ae,DERC,Senior associate researcher ,Yes,Yes,Yes,Fathom,Taking the meeting's notes ,-,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,,,,To implement generative AI solutions in the lab or production environment,,,Yes,3 months to 1 year,8,,,"student.remove(""marks"")",,10 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),I don't know,,,adjust the referencing to be iloc[N],,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/a8a2caac-d234-4be3-96e6-ab97d88fb9cb.png,,,Abstraction,5,"N = ""Hello, We're super excited to have you join the program to learn about generative AI among other things !""  N = N.replace("","", """")    N= N.replace(""!"", """")  print(N)",x^2 + x,Gini,Entropy,,,,,Green,Cross-entropy loss,,,,,,,,,,I don't know,,Look for data leakage,,,,,Try different algorithms,Combine different models,,,"Bagging reduces model complexity by randomly selecting subsets of features, while boosting reduces model variance by randomly selecting subsets of data",,,,,I don't know,I don't know,Don't know ,I'm having errors ..,5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 03:20:37 PM,10/04/2023 03:33:52 PM,2.50.149.139,,,,,Oliver Silva,oliver.silva@tii.ae,DERC,Lead Research,Yes,Yes,No,"ChatGPT, MidJourney","Correct redaction, Implement simple codes. get an overview of a specific topic. generate content free to use","data analysys, graphics. maybe some kind of integration with matlab.",,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,,,,To implement generative AI solutions in the lab or production environment,,,Yes,1-3 months,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 01:07:49 PM,10/04/2023 03:27:47 PM,2.50.149.139,,,,,Pavel,Pavel.Bahdanovich@tii.ae,DERC,Senior researcher,Yes,Yes,No,"ChatGPT, windows copilot",Less routine searching,See Q.9,,,,,,,,,-,No,I do not know Python,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 03:13:48 PM,10/04/2023 03:15:58 PM,5.195.220.140,,,,,Jaideep Singh,jaideep.singh@tii.ae,Quantum Research Center,Associate Researcher,Yes,Yes,Yes,Chat gpt,brainstorm some kind of ideas and generate a rough draft of what you want to say so it can be improved upon,writing papers,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,,,,,,,Yes,1-3 months,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 03:05:57 PM,10/04/2023 03:14:21 PM,2.50.149.139,,,,,Ramzil,ramzil.galiev@tii.ae,DERC,Senior Researcher ,Yes,Yes,Yes,"pytorch, scikit learn, pandas, tensorboard, weights and biases, .....","For example, it is possible to fine tune LLM on papers from my field. So that the fine tuned model will be used as tool, which helps students to enter the field.","For example, it is possible to fine tune LLM on papers from my field. So that the fine tuned model will be used as tool, which helps students to enter the field.",,,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,Gain some exposure and jargon in the generative AI field,"Efficient DL, Distributed learning",Yes,2+ years,10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 07:54:04 AM,10/04/2023 03:10:31 PM,83.110.1.129,,,,,Abdelrahman AlMahmoud,Abdelrahman.Almahmoud@tii.ae,SSRC,Pribncipal Researcher,Yes,Yes,Yes,"Tensorflow, keras",Automate certain processes,Yes,,,To be self-sufficient with no-code AI tools for business,,To learn how to fine-tune and apply AI models for my business domains,,To implement generative AI solutions in the lab or production environment,,,Yes,2+ years,8,,"student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,def is_palindrome(s): return s == s[::-1],,,,,,adjust the referencing to be iloc[N],,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,10,"import string  text = text.translate(text.maketrans('', '', string.punctuation))  counts = dict()  line = text.split()  for raw_word in line:      word = raw_word.lower()      if word in counts:          counts[word] += 1      else:          counts[word] = 1    print(counts)  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14423E+11,427913904,09/28/2023 01:36:11 PM,10/04/2023 03:00:28 PM,5.195.137.87,,,,,Biniam Demissie,biniam.demissie@tii.ae,DSRC,Senior Security Researcher,Yes,Yes,Yes,"LLM models from huggingface, and different open-source NLP libraries",Information retrieval ,a cybersecurity assistant for emerging threats,To have a solid understanding of the concepts and trends in generative AI,,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,Gain some exposure and jargon in the generative AI field,,Yes,3 months to 1 year,6,"del student[""marks""]","student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,,,,,,I don't know,Abstraction,5,"import re    words = list()  for s in text.split("" ""):    words.append(re.search('[\w]+', s)[0])    words.sort()    result = []  for word in words:    count = 0    for w in words[words.index(word):]:      if word == w:        count += 1    entry = {word : count}    if entry not in result:      result.append(entry)      print(result)",2xy + y,,,,,,I don't know,Green,,,Mean squared error,,,F-1 score,,,,,,,,,Try a different evaluation metric,,Keep adding more training data,,,,Apply feature engineering techniques,I don't know,,,,,I don't know,"When creating a new nn class in PyTorch, we need to define both forward and backward methods",I do not know.,I do not know.,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 12:36:12 PM,10/04/2023 02:03:53 PM,2.50.149.139,,,,,Dr. Kiran Kabotu,kiran.kabotu@tii.ae,DERC,Senior Researcher ,Yes,No,No,Not used ,Scientific information data ,"Yes, it will be useful to develop predictive models.",To have a solid understanding of the concepts and trends in generative AI,,,To gain technical experience with machine learning and AI,,,,,,Yes,3 months to 1 year,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 01:49:31 PM,10/04/2023 01:54:38 PM,2.48.17.131,,,,,Mariam,Mariam.almenhali@tii.ae,Directed Energy Research Center ,Senior Electrical Engineer,No,Yes,Yes,ChatGPT,"Assist in tasks that do not require much technicalities such as paraphrasing, summarizing, etc. It can also assist in analyzing data as it may assist in the use of different softwares such as MATLAB and suggest different approaches that may be simpler than usual. ",Creating a function library for MATLAB,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,,,,To implement generative AI solutions in the lab or production environment,,,Yes,1-3 months,6,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 01:33:54 PM,10/04/2023 01:51:43 PM,5.194.222.172,,,,,Eisa Khamis Alneyadi,Eisa.alneyadi@gmail.com,Directed Energy Research Centre,Associate Researcher,Yes,Yes,Yes,"Chatgpt, pdf.ai, Runway, Photoshop Ai","It can help me to understand the basic concepts and principles for different categories. Also, it can help you in organizing texts and review it and find the wanted points from it.",It can give you different Informational details about what you are looking for.,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,,,Gain some exposure and jargon in the generative AI field,,Yes,3 months to 1 year,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 01:41:17 PM,10/04/2023 01:46:22 PM,2.50.149.139,,,,,asilah almesmari,asilah.almesmari@tii.ae,Directed Energy Research Centre,Mechanical Engineer,Yes,Yes,Yes,ChatGPT,yes,#NAME?,To have a solid understanding of the concepts and trends in generative AI,,,To gain technical experience with machine learning and AI,,,To implement generative AI solutions in the lab or production environment,,,No,I do not know Python,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 09:52:58 AM,10/04/2023 01:46:15 PM,5.195.220.140,,,,,GIANLUCA DE SANTIS,gianluca.desantis@tii.ae,QRC,Associate Researcher,Yes,Yes,Yes,I had to deliver a ML project during my studies using scikit-learn library. I also attended some lectures where ML examples were shown in PyTorch framework.,"Personally, tools such as ChatGPT strongly increase my productivity whenever I have to code something on Python (e.g., simulation, data visualization and processing)","From an elementary approach, AI helps me in coding much faster whenever I have to create simulations or analyze data.  On a more sophisticated approach, generative AI is an emerging tool in physics when we want to deal with phenomena for which the mathematical laws are complex. As an example, AI was used to classify different values of orbital angular momentum of photons after aberration due to propagation, or to compress the wavefunction (STO-3G) of molecular hydrogen.",To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,Yes,1-2 years,5,,,"student.remove(""marks"")",,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,,I don't know,adding .drop_duplicates() to employee['salary'],reverse the table order ascending=True,,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/a8a2caac-d234-4be3-96e6-ab97d88fb9cb.png,,,I don't know,5,I don't know,2xy + y,Gini,Entropy,,,,,Green,,,Mean squared error,,,F-1 score,,,Precision & Recall,,,,,,Try a different evaluation metric,,Keep adding more training data,Try different algorithms,,,,"Bagging creates multiple datasets by sampling with replacement, while boosting adds models sequentially and adjusts their weights based on the error of the previous models",,,,,I don't know,I don't know,np.exp(-x)/((1+np.exp(-x))^2),"import pandas as pd  import numpy as np  import matplotlib.pyplot as plt  %matplotlib inline      from imblearn.datasets import fetch_datasets  from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split  from sklearn.ensemble import RandomForestClassifier   from sklearn.preprocessing import StandardScaler  from imblearn.over_sampling import SMOTE  from sklearn.metrics import accuracy_score, confusion_matrix    # Fetch the wine_quality dataset  wine_quality_data = fetch_datasets()['wine_quality']    # Extract features (X) and labels (y) from the dataset  X = wine_quality_data.data  y = wine_quality_data.target    #############  ############# DATASET VISUALIZATION  #############    # Create a Pandas DataFrame from the dataset's features  df = pd.DataFrame(data=wine_quality_data.data)    # Add the target variable to the DataFrame  df['target'] = wine_quality_data.target    # Display the first few rows of the DataFrame to inspect the data  print(df.head())    # Summary statistics of the dataset  print(df.describe())      # Histogram of features and target:  plt.figure()  plt.hist(df[0], bins=20, color='blue', alpha=0.7)    plt.xlabel('Feature 0')  plt.ylabel('Frequency')  plt.title('Histogram of Feature 0')    plt.figure()  plt.hist(df[1], bins=20, color='blue', alpha=0.7)    plt.xlabel('Feature 1')  plt.ylabel('Frequency')  plt.title('Histogram of Feature 1')    plt.figure()  plt.hist(df[2], bins=20, color='blue', alpha=0.7)    plt.xlabel('Feature 2')  plt.ylabel('Frequency')  plt.title('Histogram of Feature 2')    plt.figure()  plt.hist(df[3], bins=20, color='blue', alpha=0.7)    plt.xlabel('Feature 3')  plt.ylabel('Frequency')  plt.title('Histogram of Feature 3')  plt.figure()    plt.hist(df[4], bins=20, color='blue', alpha=0.7)    plt.xlabel('Feature 4')  plt.ylabel('Frequency')  plt.title('Histogram of Feature 4')    plt.figure()  plt.hist(df[5], bins=20, color='blue', alpha=0.7)    plt.xlabel('Feature 5')  plt.ylabel('Frequency')  plt.title('Histogram of Feature 5')    plt.figure()  plt.hist(df[6], bins=20, color='blue', alpha=0.7)    plt.xlabel('Feature 6')  plt.ylabel('Frequency')  plt.title('Histogram of Feature 6')    plt.figure()  plt.hist(df[7], bins=20, color='blue', alpha=0.7)    plt.xlabel('Feature 7')  plt.ylabel('Frequency')  plt.title('Histogram of Feature 7')    plt.figure()  plt.hist(df[8], bins=20, color='blue', alpha=0.7)    plt.xlabel('Feature 8')  plt.ylabel('Frequency')  plt.title('Histogram of Feature 8')    plt.figure()  plt.hist(df[9], bins=20, color='blue', alpha=0.7)    plt.xlabel('Feature 9')  plt.ylabel('Frequency')  plt.title('Histogram of Feature 9')    plt.figure()  plt.hist(df[10], bins=20, color='blue', alpha=0.7)    plt.xlabel('Feature 10')  plt.ylabel('Frequency')  plt.title('Histogram of Feature 10')    plt.show()      plt.hist(df['target'], bins=5, color='green', alpha=0.7)  plt.xlabel('Quality')  plt.ylabel('Frequency')  plt.title('Histogram of Wine Quality')  plt.show()    #############  ############# CROSS-VALIDATION, SCALING, RESAMPLING, AND CLASSIFICATION TASKS  #############     # Initialize the StandardScaler to scale the features  scaler = StandardScaler()    # Fit and transform the features using the scaler  X_scaled = scaler.fit_transform(X)    # Check the label distribution before resampling  unique_labels, label_counts = np.unique(y, return_counts=True)  print(""Label Distribution Before Resampling:"")  for label, count in zip(unique_labels, label_counts):      print(f""Class {label}: {count} samples"")    # Apply SMOTE oversampling to address class imbalance (if needed)  smote = SMOTE(sampling_strategy='auto', random_state=42)  X_resampled, y_resampled = smote.fit_resample(X_scaled, y)    # Check the label distribution after resampling  unique_labels_resampled, label_counts_resampled = np.unique(y_resampled, return_counts=True)  print(""\nLabel Distribution After Resampling:"")  for label, count in zip(unique_labels_resampled, label_counts_resampled):      print(f""Class {label}: {count} samples"")    # Initialize the classifier (Random Forest in this example)  classifier = RandomForestClassifier()    # Perform cross-validation with 5 folds (you can adjust the number of folds as needed)  num_folds = 5  cross_val_scores = cross_val_score(classifier, X_resampled, y_resampled, cv=num_folds, scoring='accuracy')    # Print the cross-validation scores  print(""\nCross-Validation Scores after Resampling:"")  print(cross_val_scores)  print(""Mean Accuracy:"", np.mean(cross_val_scores))    #############  ############# HYPERPARAMETER TUNING  #############    param_grid = {      'n_estimators': [100, 200, 300],      'max_depth': [None, 10, 20],      'min_samples_split': [2, 5, 10],      'min_samples_leaf': [1, 2, 4]  }    # Initialize GridSearchCV to find the best hyperparameters  grid_search = GridSearchCV(estimator=classifier, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)    # Fit GridSearchCV to the data  grid_search.fit(X_resampled, y_resampled)    # Print the best hyperparameters and corresponding score  print(""\nBest Hyperparameters:"")  print(grid_search.best_params_)  print(""Best Score:"", grid_search.best_score_)    #############  ############# EVALUATION  #############      # Get the best classifier from GridSearchCV  best_classifier = grid_search.best_estimator_    # Make predictions on the resampled data  y_pred = best_classifier.predict(X_resampled)    # Calculate accuracy  accuracy = accuracy_score(y_resampled, y_pred)  print(""\nAccuracy:"", accuracy)    # Create a confusion matrix  conf_matrix = confusion_matrix(y_resampled, y_pred)  print(""\nConfusion Matrix:"")  print(conf_matrix)    # Calculate error rate  error_rate = 1 - accuracy  print(""\nError Rate:"", error_rate)",4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 12:39:08 PM,10/04/2023 01:45:16 PM,2.50.149.139,,,,,Santiago,santiago.morales@tii.ae,DERC,Senier RF & Electronics Researcher ,Yes,Yes,Yes,"Tensorflow, Keras, ChatGPT, Dall-E",Help on explaining basic concepts when introducing to a new topic,Translating code snippets between different programming languages,,,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,,,,,Yes,2+ years,10,"del student[""marks""]","student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,def is_palindrome(s): return s == s[::-1],,,,adding .drop_duplicates() to employee['salary'],,adjust the referencing to be iloc[N],,,,,I don't know,Inheritance,7,"possible_puncts = ["","", ""."", ""!"", "";"", ""'""]  w_list = text.split("" "")  for i in range(len(w_list)):    for p in possible_puncts:      w_list[i] = w_list[i].replace(p,"""")    w_dict ={}  for w in w_list:    if w in w_dict: w_dict[w]+=1    else: w_dict[w] = 1  print(w_dict)",2xy + y,Gini,Entropy,Sum of squared error (variance),,,,Green,Cross-entropy loss,,Mean squared error,,,F-1 score,,,Precision & Recall,,,,,,Try a different evaluation metric,,Keep adding more training data,,,,,"Bagging speeds up model training by parallelizing computation, while boosting reduces overfitting by adding regularization",,,,,I don't know,I don't know,grad * (1.0 - grad),#sorry no more time for this,5,Adding noise,,Flipping,,Scaling,,,"Autonomous driving and robotics to detect objects such as cars, people, or houses",,Household object detection for augmented reality applications,,,"Irregular objects such as buildings, vehicles, or trees for autonomous vehicles",,,,Synonym replacement,Random deletion,,Text generation,,,Classification,binning,moving average smoothing,,,"#sorry, busy","#sorry, busy",5,,Sentence Segmentation,,,,,,,,I don't know,,,,,I don't know,,,,,,I don't know,Separate words into individual morphemes and identify the class of the morphemes,,,Refer to the same objects (“entities”),,,,,,,,,,I don't know,This pipeline requires that labels be given to classify this text.,FALSE,,,,,I don't know,I don't know,,Character-based tokenization,,,Unigram,,,,,,I don't know,I don't know,I don't know,I don't know,I don't know,,,,,I don't know,5,,LeNet,,,VGG,,,TRUE,not familiar with VGG,not familiar with VGG,not familiar with VGG,I don't know,not familiar with VGG,"Convolution, g is a kernel",Erosion,Dilation,Opening,Closing,,,,Sampling is the process that determines the size of the image to be obtained,,Quantization is a process that determines the value of each pixel in the image,,
1.14428E+11,427913904,10/03/2023 09:20:59 AM,10/04/2023 01:07:40 PM,2.50.149.139,,,,,Qingjie Yang,qingjie.yang@tii.ae,DERC,Lead Researcher,Yes,Yes,I do not understand what a prompt is,"Grammer, ChatGPT",AI tools like ChatGPT is very helpful as I want to search any knowledge that I am not familiar and will show me the most accurate answers basically.,Help to write a simple but useful code to figure out the hurry tasks.,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,Yes,1-2 years,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 12:56:52 PM,10/04/2023 01:03:12 PM,2.50.149.139,,,,,Islem YAHI,islem.yahi@tii.ae,DERC,Principal Researcher,Yes,Yes,I do not understand what a prompt is,"ChatGPT, MidJourney",generate initial text. ,"generate test reports for customer based on experiment results, also help to classify and sort different phenomena",To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,,To implement generative AI solutions in the lab or production environment,,,No,I do not know Python,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 12:38:24 PM,10/04/2023 01:01:35 PM,2.50.149.139,,,,,Andri Haryono,andri.haryono@tii.ae,DERC,Senior Electronic Engineer,Yes,Yes,Yes,"Chatgpt v3.5, falcon40B, midjourney, Dall-E2",help with small coding and rephrasing the email letter,(hard to realize)   generated electronic circuit design. ,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,Yes,2+ years,7,"del student[""marks""]","student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Encapsulation,1,"import string    def word_count_without_punctuation(sentence):      # Remove punctuation from the sentence      sentence = sentence.translate(str.maketrans('', '', string.punctuation))        # Split the sentence into words      words = sentence.split()        # Create a dictionary to store word counts      word_count = {}        # Count the frequency of each word      for word in words:          # Convert the word to lowercase to ensure case-insensitivity          word = word.lower()          if word in word_count:              word_count[word] += 1          else:              word_count[word] = 1        return word_count    # Example sentence  sentence = ""Hello! We are super excited to have you join the program to learn about generative AI amongst other things!""    # Get word count without punctuation  result = word_count_without_punctuation(sentence)  print(result)  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14426E+11,427913904,10/01/2023 08:57:58 PM,10/04/2023 12:59:53 PM,5.31.246.28,,,,,Stavros Efthymiou,stavros.efthymiou@tii.ae,Quantum Research Center,Researcher,Yes,Yes,Yes,From generative AI tools I have only tried the web interface of ChatGPT.  In the past I have also written machine learning models using TensorFlow and Keras.,I primarily do software development so it can help with code suggestions or autocompletion.  In research it has helped me in providing references to past works on a given subject or question.,"Machine learning can be useful on some tasks such as qubit calibration, state classification or quantum circuit transpilation.   These tasks do not necessarily require generative models.",To have a solid understanding of the concepts and trends in generative AI,,,To gain technical experience with machine learning and AI,,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,Yes,2+ years,8,"del student[""marks""]","student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,,,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/4b0a1e6b-c3dd-48f4-9437-0286177c6d83.png,,Abstraction,7,https://colab.research.google.com/drive/1iNyaA1Ej3zGxMkFaz8-vfw2yQn9xwqer?usp=sharing,2xy + y,Gini,Entropy,Sum of squared error (variance),,,,Green,Cross-entropy loss,Huber loss,Mean squared error,All of the above,,F-1 score,,,Precision & Recall,,,,Look for data leakage,,,,,Try different algorithms,Combine different models,,Apply feature engineering techniques,"Bagging creates multiple datasets by sampling with replacement, while boosting adds models sequentially and adjusts their weights based on the error of the previous models",PyTorch uses zero_grad() to sets all the gradients to zero for all the parameters in the model.,It ensures that the gradients are fresh and ready to be computed for the current iteration.,,,,nn.Module is the base class for all neural network modules in PyTorch,sx = self.forward(self.x)  grad_input = grad * sx * (1 - sx),TODO,5,Adding noise,,Flipping,,Scaling,,,"Autonomous driving and robotics to detect objects such as cars, people, or houses",,Household object detection for augmented reality applications,Anomaly detection in medical diagnostic imaging,Facial feature points for face detection,"Irregular objects such as buildings, vehicles, or trees for autonomous vehicles",,,Back translation,Synonym replacement,,,Text generation,,,Part-of-speech tagging (POS),binning,moving average smoothing,,,"import requests  import bs4    response = requests.get(""https://en.wikipedia.org/wiki/Generative_artificial_intelligence"")    captions = []  images = []  for caption in soup.find_all(""figcaption""):      image = caption.parent.find(""img"")      if image is not None:          captions.append(caption.text)          images.append(image[""src""])","from PIL import Image, ImageFilter  import requests  from io import BytesIO    url = ""https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Example-dog-on-the-internet.png/220px-Example-dog-on-the-internet.png""  response = requests.get(url)    original = Image.open(BytesIO(response.content))    rotated = original.transpose(Image.ROTATE_90)  flipped = original.transpose(Image.FLIP_TOP_BOTTOM)  sharpened = original.filter(ImageFilter.SHARPEN)",3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 12:51:36 PM,10/04/2023 12:56:01 PM,2.50.149.139,,,,,KARIM ELAYOUBI,Karim.Elayoubi@tii.ae,DERC,Senior Optics Engineer,Yes,Yes,No,ChatGPT,Fast and quick search of fine information like open-source codes...,No preferences/idea ,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,,,,,,,Yes,1-2 years,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 12:35:56 PM,10/04/2023 12:53:01 PM,2.50.149.139,,,,,Fernando Albarracin,fernando.albarracin@tii.ae,DERC,Principal Researcher,Yes,Yes,No,ChatGPT,1. Giving an averaged view on general purpose definitions and concepts. 2. Automation of simple tasks at work like style correction and script generation.,"1. Style correction in documents like reports. 2. Generation of general purpose scripts to perform small tasks, part of larger codes for signal processing. ",To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,,,,Gain some exposure and jargon in the generative AI field,,No,1-3 months,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 12:45:40 PM,10/04/2023 12:50:03 PM,2.50.149.139,,,,,Sarah Alhosani,sara.alhousani@hotmail.com,Directed Energy,Associate Researcher ,Yes,Yes,No,ChatGPT,Spending less time on finding information or resources. ,Yes,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,,,"To learn how to build NLP, LLM, or Computer Vision models",,Gain some exposure and jargon in the generative AI field,,No,I do not know Python,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 12:43:11 PM,10/04/2023 12:49:54 PM,2.50.149.139,,,,,BHARATHIDASAN SUGUMARAN,Bharathidasan.Sugumaran@tii.ae,DERC,Senior High Power RF Engineer,No,Yes,No,"ChatGPT, Dall-E",Can provide  inputs  or innovative ideas for the projects we are working ,To Implement AI solution in Lab for automated measurement,,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,,,,To implement generative AI solutions in the lab or production environment,,,No,I do not know Python,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 12:39:56 PM,10/04/2023 12:48:26 PM,2.50.149.139,,,,,amit dubey,amit.dubey@tii.ae,DERC,Lead Laser Engineer,Yes,Yes,I do not understand what a prompt is,chatGPT,it will help to save time for reaching anything on multiple website/ books. ,Searching description of sub-topic of research. ,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,,,,,,,No,1-3 months,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 12:44:35 PM,10/04/2023 12:47:32 PM,2.50.149.139,,,,,Athra Alsuwaidi,athra.alsuwaidi@tii.ae,DERC,Associate Researcher,Yes,Yes,No,Chatgpt  Brad,Less time to search the information   More explanation related to the searched topic,No,,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,,,To implement generative AI solutions in the lab or production environment,,,No,I do not know Python,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 12:39:37 PM,10/04/2023 12:47:05 PM,2.50.149.139,,,,,Meixia Geng,meixia.geng@tii.ae,DERC,Senior Researcher,Yes,Yes,I do not understand what a prompt is,"ChatGPT, paper digest",It helps me write some specified codes efficiently. ,Summarize the related work conducted before.,,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,,,,,,Yes,1-3 months,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 12:12:41 PM,10/04/2023 12:47:04 PM,83.110.1.129,,,,,Sai Srinadhu K,Saisrinadhu.Katta@tii.ae,SSRC,Senior ML Engineer,Yes,Yes,Yes,Pytorch and all,"literature review, initial code base/faster coding",Maynot be now,To have a solid understanding of the concepts and trends in generative AI,,,,To learn how to fine-tune and apply AI models for my business domains,,To implement generative AI solutions in the lab or production environment,,,Yes,2+ years,8,"del student[""marks""]","student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],reverse the table order ascending=True,adjust the referencing to be iloc[N],,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,10,"https://colab.research.google.com/drive/1uAYKlw-6ZcC5F9DCtq0zboVyLMTKts84?usp=sharing%C2%A0#scrollTo=r_gc0Z8BGnem    AI is not a stop word, the question should be more clear",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 12:39:59 PM,10/04/2023 12:45:19 PM,2.50.149.139,,,,,Afra Rashed Almheiri,afra.almheiri@tii.ae,DERC,Associate Researcher,Yes,Yes,No,"ChatGPT, OpenAI",Minimal assistance,The incorporation of advanced research into the data ChatGPT answers with since it has fundamental theories and concepts not the advanced ones,,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,,,,To implement generative AI solutions in the lab or production environment,,,Yes,1-2 years,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 12:39:30 PM,10/04/2023 12:43:30 PM,2.50.149.139,,,,,Shaikha AlDhaheri,shaikha.aldhaheri@tii.ae,DERC,Senior associate research ,Yes,Yes,I do not understand what a prompt is,ChatGPT,save time more in researching about something,No idea,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,,,,Gain some exposure and jargon in the generative AI field,,No,I do not know Python,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 12:37:21 PM,10/04/2023 12:43:20 PM,5.31.230.30,,,,,Hamdan Alhashmi,Hamdan.alhashmi@tii.ae,DERC,Associate Researcher ,Yes,Yes,I do not understand what a prompt is,CharGPT,By reducing the time for any research topic,Not sure,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,,,To implement generative AI solutions in the lab or production environment,,,Yes,1-3 months,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 12:38:22 PM,10/04/2023 12:42:27 PM,2.50.149.139,,,,,Ernesto Neira,ernesto.neira@tii.ae,DERC,Lead Researcher,Yes,Yes,Yes,Chat GPT,Quality and speed,assistant,,,,To gain technical experience with machine learning and AI,,,,,,Yes,1-3 months,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 09:07:44 AM,10/04/2023 12:39:03 PM,83.110.1.129,,,,,Yury Durkin,Yury.Durkin@tii.ae,CRC,Senior Cryptography Hardware Engineer,Yes,Yes,Yes,ChatGPT,yes,"Help with coding, check and refine code, check and refine text for the papers",To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,Gain some exposure and jargon in the generative AI field,,Yes,1-2 years,5,,,"student.remove(""marks"")",,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,def is_palindrome(s): return s == s[::-1],,,,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,I don't know,1,"import string    def count_words_without_punctuation_and_stopwords(text):      # Define a list of stopwords      stopwords = [""i"", ""me"", ""my"", ""myself"", ""we"", ""our"", ""ours"", ""ourselves"", ""you"", ""your"", ""yours"", ""yourself"", ""yourselves"",                   ""he"", ""him"", ""his"", ""himself"", ""she"", ""her"", ""hers"", ""herself"", ""it"", ""its"", ""itself"", ""they"", ""them"", ""their"",                   ""theirs"", ""themselves"", ""what"", ""which"", ""who"", ""whom"", ""this"", ""that"", ""these"", ""those"", ""am"", ""is"", ""are"",                   ""was"", ""were"", ""be"", ""been"", ""being"", ""have"", ""has"", ""had"", ""having"", ""do"", ""does"", ""did"", ""doing"", ""a"", ""an"",                   ""the"", ""and"", ""but"", ""if"", ""or"", ""because"", ""as"", ""until"", ""while"", ""of"", ""at"", ""by"", ""for"", ""with"", ""about"",                   ""against"", ""between"", ""into"", ""through"", ""during"", ""before"", ""after"", ""above"", ""below"", ""to"", ""from"", ""up"",                   ""down"", ""in"", ""out"", ""on"", ""off"", ""over"", ""under"", ""again"", ""further"", ""then"", ""once""]        # Remove punctuation, convert to lowercase, and split into words      translator = str.maketrans('', '', string.punctuation)      cleaned_text = text.translate(translator).lower()      words = cleaned_text.split()        # Count the frequency of each word, excluding stopwords      word_count = {}      for word in words:          if word not in stopwords:              if word in word_count:                  word_count[word] += 1              else:                  word_count[word] = 1        return word_count    # Input sentence  sentence = ""Hello! We are super excited to have you join the program to learn about generative AI amongst other things!""    # Get the word count dictionary, excluding stopwords  word_count_dict = count_words_without_punctuation_and_stopwords(sentence)    # Print the result  print(word_count_dict)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14425E+11,427913904,09/29/2023 10:30:54 PM,10/04/2023 12:23:54 PM,86.96.84.114,,,,,Jiaming Zhou,jiaming.zhou@tii.ae,Biotechnology Researcher Center,Senior Researcher,Yes,Yes,No,"Canva, Fotor, Piscart","ChatGPT can increase the efficiency to my work. For example, the ChatGPT can generate a draft report according to my inputted requirement, and I can rephrase the report with my style, which is time-saving.",Yes. My research interest is regarding microbiome. A potential AI use case can be making a language model to search the microbiome data according to the public dataset and predict the potential probiotic.,,,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,Gain some exposure and jargon in the generative AI field,,Yes,2+ years,8,"del student[""marks""]","student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,def is_palindrome(s): return s == s[::-1],,,,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,6,"import string  sentence = ""Hello! We are super excited to have you join the program to learn about generative AI amongst other things!""  sentence = sentence.translate(str.maketrans('', '', string.punctuation)).lower()  # remove the punctuation of the sentence and lowercase each word  Temp = sentence.split(' ')  # generate a list with each word as an item  count=[]  Words=[]  for item in Temp:      if item not in Words:          Words.append(item)          count.append(1)      else:          count[Words.index(item)]=count[Words.index(item)]+1  # remove the duplicate items in the list ""Temp"" and store the unique items in the list ""Words"", and count the number of each word and store the information in ""count""  pack=dict(zip(Words,count))  # use the lists ""Words"" and ""counts"" as key and value to generate a dictionary  print(pack)",2x + y,Gini,Entropy,,,,,Rain,Cross-entropy loss,,,,,F-1 score,,,Precision & Recall,,,,Look for data leakage,See if it's an imbalanced dataset and apply oversampling,Try a different evaluation metric,,Keep adding more training data,Try different algorithms,Combine different models,,,"Bagging creates multiple datasets by sampling with replacement, while boosting adds models sequentially and adjusts their weights based on the error of the previous models",PyTorch uses zero_grad() to sets all the gradients to zero for all the parameters in the model.,It ensures that the gradients are fresh and ready to be computed for the current iteration.,,,,nn.Module is the base class for all neural network modules in PyTorch,x*(1-x),"import pandas as pd  import numpy as np  import matplotlib.pyplot as plt  from imblearn.datasets import fetch_datasets  from imblearn.over_sampling import RandomOverSampler  from sklearn.preprocessing import MinMaxScaler  from sklearn.decomposition import PCA  from sklearn.ensemble import RandomForestClassifier  from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay  from sklearn.model_selection import RandomizedSearchCV, train_test_split  from scipy.stats import randint    data = fetch_datasets()['wine_quality']  X, y = data['data'], data['target']  X.shape, y.shape  plt.scatter(X[:,0], X[:,1], c=y, alpha=0.5, s = 30, edgecolor=(0,0,0,0.5))  plt.show()  X_train, X_test, y_train, y_test = train_test_split(X,y,                                                      test_size = 0.2,                                                      random_state = 42)  X_train.shape, y_train.shape, X_test.shape, y_train.shape    scaler = MinMaxScaler()  scaler.fit(X_train)  X_train = scaler.transform(X_train)  X_test = scaler.transform(X_test)  pca = PCA(n_components=2)  pca.fit(X_train)  X_train_pca = pca.transform(X_train)  X_test_pca = pca.transform(X_test)  plt.scatter(X_train[:,0], X_train[:,1], c=y_train, alpha=0.5, s = 30, edgecolor=(0,0,0,0.5))  plt.show()  ros = RandomOverSampler(random_state=0)  X_train_ros, y_train_ros = ros.fit_resample(X_train_pca, y_train)  plt.scatter(X_train_ros[:,0], X_train_ros[:,1], c=y_train_ros, alpha=0.5, s = 30, edgecolor=(0,0,0,0.5))  plt.show()      rf = RandomForestClassifier()  rf.fit(X_train, y_train)    y_pred = rf.predict(X_test)    accuracy = accuracy_score(y_test, y_pred)  print(""Accuracy:"", accuracy)  param_dist = {'n_estimators': randint(50,500),                'max_depth': randint(1,20)}    # Create a random forest classifier  rf = RandomForestClassifier()    # Use random search to find the best hyperparameters  rand_search = RandomizedSearchCV(rf,                                   param_distributions = param_dist,                                   n_iter=5,                                   cv=5)    # Fit the random search object to the data  rand_search.fit(X_train, y_train)  best_rf = rand_search.best_estimator_    print('Best hyperparameters:',  rand_search.best_params_)  y_pred = best_rf.predict(X_test)    cm = confusion_matrix(y_test, y_pred)    ConfusionMatrixDisplay(confusion_matrix=cm).plot();  plt.show()    accuracy = accuracy_score(y_test, y_pred)  precision = precision_score(y_test, y_pred)  recall = recall_score(y_test, y_pred)    print(""Accuracy:"", accuracy)  print(""Precision:"", precision)  print(""Recall:"", recall)  X_train_pd = pd.DataFrame(X_train, columns = ['A','B','C','D','E','F','G','H','I','J','K'])    feature_importances = pd.Series(best_rf.feature_importances_, index=X_train_pd.columns).sort_values(ascending=False)    feature_importances.plot.bar();  plt.show()  # The evaluation of model is: Accuracy: 0.9704081632653061, Precision: 0.5714285714285714, Recall: 0.13333333333333333.   #The variables that data from the 6th column, 2nd column and 1 column are top variables.",6,,,Flipping,,Scaling,,,"Autonomous driving and robotics to detect objects such as cars, people, or houses",e-Commerce product categorization,Household object detection for augmented reality applications,Anomaly detection in medical diagnostic imaging,Facial feature points for face detection,"Irregular objects such as buildings, vehicles, or trees for autonomous vehicles",All of the mentioned,,Back translation,Synonym replacement,Random deletion,,,Trasformer-based,,Part-of-speech tagging (POS),binning,moving average smoothing,,,"import requests  from bs4 import BeautifulSoup  URL = ""https://en.wikipedia.org/wiki/Generative_artificial_intelligence""  r = requests.get(URL)  soup = BeautifulSoup(r.text, 'html.parser')  images = []    for item in soup.find_all('img'):      image=str(item['src'])      if image[1]!='/':          image=image[:1]+'/'+image[1:]      image='https:'+image      images.append(image)      print(image)  images","import requests  from PIL import Image  from PIL import ImageFilter  img_url = 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Example-dog-on-the-internet.png/220px-Example-dog-on-the-internet.png'  img = Image.open(requests.get(img_url, stream = True).raw)  new = (img.size[0] * 3, img.size[1] * 3)  new_image=img.resize(new)  rotated_image = new_image.rotate(180)  hori_flippedImage = new_image.transpose(Image.FLIP_LEFT_RIGHT)  tobu_flippedImage = new_image.transpose(Image.FLIP_TOP_BOTTOM)  sharpened = new_image.filter(ImageFilter.SHARPEN);  img_container=[img,new_image,rotated_image,hori_flippedImage,tobu_flippedImage,sharpened]  for item in img_container:      item.show()",6,Stop-word Removal,,Stemming,Lemmatization,Tokenization,,GPT,T5,BERT,,T5 is a encoder-decoder mixed models,BERT models are encoder models,GPT-3 is an autoregressive model,,,,Deduplication,,,,,Separate words into individual morphemes and identify the class of the morphemes,,"Given a sentence or larger chunk of text, determine which words (“mentions”)",Refer to the same objects (“entities”),,,,Co-reference resolution,Semantic-role labelling,Named entity recognition,Word sense disambiguation,Machine Translation,All of the mentioned,,This pipeline requires that labels be given to classify this text.,FALSE,,,A sequence-to-sequence model,,,"The sequence length, the batch size, and the hidden size",WordPiece,,,BPE,Unigram,,,The attention mechanism is good at handling long sequence input,Local attention helps reduce the computation burden,,,A list of IDs,The tokenizer and model should always be from the same checkpoint.,Find the persons mentioned in a sentence.,"Some of the tokens in the two input sentences are randomly masked, and the label is whether the two sentences are similar or not.",Writing short reviews of long documents,,Translating a text in Arabic into English,,,6,MobileNet,LeNet,,,VGG,,,TRUE,"A fixed size of (224 * 224) RGB image was given as input to this network which means that the matrix was of shape (224,224,3).  The only preprocessing that was done is that they subtracted the mean RGB value from each pixel, computed over the whole training set.  Used kernels of (3 * 3) size with a stride size of 1 pixel, this enabled them to cover the whole notion of the image.  spatial padding was used to preserve the spatial resolution of the image.  max pooling was performed over a 2 * 2 pixel windows with sride 2.  this was followed by Rectified linear unit(ReLu) to introduce non-linearity to make the model classify better and to improve computational time as the previous models used tanh or sigmoid functions this proved much better than those.  implemented three fully connected layers from which first two were of size 4096 and after that a layer with 1000 channels for 1000-way ILSVRC classification and the final layer is a softmax function.",I am not familiar with this part.,I am not familiar with this part.,"True, original_model.features, 4096, self.classifier(f)","Perceptual Loss is being utilized during the training process.  The activation in the training process is briefly mentioned below:  A fixed size of (224 * 224) RGB image was given as input to this network which means that the matrix was of shape (224,224,3).  The only preprocessing that was done is that they subtracted the mean RGB value from each pixel, computed over the whole training set.  Used kernels of (3 * 3) size with a stride size of 1 pixel, this enabled them to cover the whole notion of the image.  spatial padding was used to preserve the spatial resolution of the image.  max pooling was performed over a 2 * 2 pixel windows with sride 2.  this was followed by Rectified linear unit(ReLu) to introduce non-linearity to make the model classify better and to improve computational time as the previous models used tanh or sigmoid functions this proved much better than those.  implemented three fully connected layers from which first two were of size 4096 and after that a layer with 1000 channels for 1000-way ILSVRC classification and the final layer is a softmax function.",I am not familiar with this part.,Erosion,Dilation,Opening,Closing,Morphological Gradient,Top Hat,Black Hat,Sampling is the process that determines the size of the image to be obtained,Sampling is dependent on both the content and the size of the image,,,
1.14428E+11,427913904,10/04/2023 10:38:41 AM,10/04/2023 11:44:40 AM,83.110.1.129,,,,,Abdulla AlBreiki,abdulla.albreiki@tii.ae,ARRC,Engineer,Yes,Yes,Yes,ChatGPT,It helps with finding solutions quicker than before,Maybe dataset generation,,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,Yes,2+ years,6,,,"student.remove(""marks"")",,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,,I don't know,adding .drop_duplicates() to employee['salary'],,,,,,,I don't know,Inheritance,9,"text = 'Hello! We are super excited to have you join the program to learn about generative AI amongst other things.'  print(text)    ### Your Code Below  text = text.strip('.')  text = text.replace('!', '')  text = text.split(' ')    for i in range(len(text)):    text[i] = text[i].lower()    dictionary = {}    for word in text:    if word in dictionary:      dictionary[word] += 1    else:      dictionary[word] = 1    print(dictionary)",2xy + y,,,,,,I don't know,I don't know,,,,,I don't know,,,,,,I don't know,,,,,I don't know,Keep adding more training data,,,,,I don't know,,,,,I don't know,I don't know,.,.,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14425E+11,427913904,09/30/2023 10:21:33 AM,10/04/2023 11:44:11 AM,94.203.20.36,,,,,Ilia Lykov,ilia.lykov@tii.ae,Quantum Research Center,Associate Researcher,Yes,Yes,Yes,Keras Tensorflow library for Python,"It helps me to plan my working day and makes my timetable in the most efficient ways. Also, it gives answers on particular questions, which I have during my job. However, they aren't always precise.","Stabilization of the particle in the optical trap, accelometer applications. Computer vision for data analysis.",,,,To gain technical experience with machine learning and AI,,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,Yes,2+ years,9,,"student.pop(""marks"")","student.remove(""marks"")",,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,8,https://1drv.ms/u/s!AiS8T-kU2oRO7RVtccKyIOToBN3-?e=kyzvIz,2xy + y,,,,,,,Green,Cross-entropy loss,,,,,F-1 score,,,Precision & Recall,,,,Look for data leakage,See if it's an imbalanced dataset and apply oversampling,Try a different evaluation metric,,,Try different algorithms,Combine different models,,,"Bagging creates multiple datasets by sampling with replacement, while boosting adds models sequentially and adjusts their weights based on the error of the previous models",PyTorch uses zero_grad() to sets all the gradients to zero for all the parameters in the model.,,,,,"When creating a new nn class in PyTorch, we need to define both forward and backward methods",grad*(1-grad),https://1drv.ms/u/s!AiS8T-kU2oRO7Rb1IwEJ8raOKkQl?e=74XgSQ,5,Adding noise,,Flipping,,Scaling,,,"Autonomous driving and robotics to detect objects such as cars, people, or houses",e-Commerce product categorization,Household object detection for augmented reality applications,,,"Irregular objects such as buildings, vehicles, or trees for autonomous vehicles",,,,Synonym replacement,Random deletion,,Text generation,,,Classification,,moving average smoothing,,,https://1drv.ms/u/s!AiS8T-kU2oRO7RkAdEMFbrc8dNAt?e=godE2k,https://1drv.ms/u/s!AiS8T-kU2oRO7RcodIOCeIIhCEJy?e=jFOswo,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 10:13:27 AM,10/04/2023 11:30:56 AM,5.195.220.140,,,,,Rodrigo Piera,rodrigo.piera@tii.ae,QRC,Senior researcher,Yes,Yes,Yes,"Chat GPT, Grammer",Correct my grammar. Suggest lectures on some specific topic. Writting tool for papers. ,Write Papers. Suggest lectures. recomend books. Write programming codes. ,To have a solid understanding of the concepts and trends in generative AI,,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,,To implement generative AI solutions in the lab or production environment,,,Yes,2+ years,7,,"student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ vitanYP,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),I don't know,,,,I don't know,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,I don't know,5,N/A,2xy + y,Gini,Entropy,,,,,,Cross-entropy loss,,,,,F-1 score,,,Precision & Recall,,,,Look for data leakage,See if it's an imbalanced dataset and apply oversampling,Try a different evaluation metric,,,,,Try stochastic gradient descent instead of batch gradient descent,,I don't know,,,,,I don't know,I don't know,N/A,N/A,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 08:47:36 AM,10/04/2023 11:24:34 AM,83.110.1.129,,,,,Lorenzo Bellone,lorenzo.bellone@tii.ae,Autonomous Robotics Research Center,Researcher,Yes,Yes,Yes,"ChatGPT, Merlin, Dall-e, Generative Voice AI","They assist in writing code and text for generic applications (when you try to use it for some more specific fields, the results are usually incorrect). Furthermore, they can help in providing a summary of long documentation and explaining in simple words some concepts.","When you build and run a big project, also in the robotics field, usually you get some errors or logs that are difficult to quickly understand. Finding the error and understanding what went wrong takes time. A possible application of generative AI might be to provide a human-friendly output from the results of your application, in order to easily debug or provide reports.",,,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,Yes,2+ years,7,"del student[""marks""]","student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,def is_palindrome(s): return s == s[::-1],,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,8,"import string  text =  ""Hello! We are super excited to have you join the program to learn about generative AI amongst other things!""  # Define dict that will contain the word count  word_count = {}    # For loop on each word  for word in text.split():      word = word.lower() # ensure not to have different words just for capital letters      no_punct = """"      for char in word:          if char not in string.punctuation:              no_punct += char      if no_punct in word_count.keys():          word_count[no_punct] += 1      else:          word_count[no_punct] = 1",2xy + y,,,,,,I don't know,Green,Cross-entropy loss,,,,,F-1 score,,,Precision & Recall,,,,,See if it's an imbalanced dataset and apply oversampling,Try a different evaluation metric,,,Try different algorithms,Combine different models,,Apply feature engineering techniques,I don't know,PyTorch uses zero_grad() to sets all the gradients to zero for all the parameters in the model.,It ensures that the gradients are fresh and ready to be computed for the current iteration.,,,,nn.Module is the base class for all neural network modules in PyTorch,don't know,"import pandas as pd  import numpy as np  import matplotlib.pyplot as plt  %matplotlib inline    # Download the test dataset  from imblearn.datasets import fetch_datasets    data = fetch_datasets()['wine_quality']    # Separate data into features [X] and lable [y]  X = data['data']  y = data['target']    # Check the labels and their distribution  plt.hist(y)  plt.show()    # Create holdout datasets  X_train = X[:round(len(X)*80/100)]  y_train = y[:round(len(y)*80/100)]  X_test = X[round(len(X)*80/100):]  y_test = y[round(len(y)*80/100):]    # Resample with over and under-sampling  X_train_0 = X_train[y_train==-1]  y_train_0 = y_train[y_train==-1]  X_train_1 = X_train[y_train==1]  y_train_1 = y_train[y_train==1]    # under sampling  random_under = np.random.choice(X_train_0.shape[0], int(X_train_0.shape[0]/4), replace=False)  X_train_0_under = X_train_0[random_under]  y_train_0_under = y_train_0[random_under]    # over sampling  random_over = np.random.choice(X_train_1.shape[0], int(X_train_1.shape[0]*5), replace=True)  X_train_1_over = X_train_1[random_over]  y_train_1_over = y_train_1[random_over]    # Training set will be the concatenation of resampled datasets  X_train_resample = np.concatenate((X_train_0_under, X_train_1_over))  y_train_resample = np.concatenate((y_train_0_under, y_train_1_over))    # Let's check that the resampling was effective  plt.hist(y_train_resample)  plt.show()    # import necessary modules for ML modelling  # Modelling  from sklearn.ensemble import RandomForestClassifier  from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay  from sklearn.model_selection import RandomizedSearchCV, train_test_split    # Shuffle training data  tmp = list(zip(X_train_resample, y_train_resample))  np.random.shuffle(tmp)  X_train_resample, y_train_resample = zip(*tmp)  X_train_resample, y_train_resample = np.array(X_train_resample), np.array(y_train_resample)    # Train one classifier with the default parameters  rf = RandomForestClassifier()  rf.fit(X_train_resample, y_train_resample)    # Hyperparameter tuning   param_dist = {'n_estimators': randint(50,500),                'max_depth': randint(1,20)}    # Use random search to find the best hyperparameters  rand_search = RandomizedSearchCV(rf, param_distributions = param_dist, n_iter=5, cv=5)    # Fit the random search object to the data  rand_search.fit(X_train_resample, y_train_resample)  rf.fit(X_train_resample, y_train_resample)    # Create a variable for the best model  best_rf = rand_search.best_estimator_  # Print the best hyperparameters  print('Best hyperparameters:',  rand_search.best_params_)    # Generate predictions with the best model  y_pred = best_rf.predict(X_test)    # Create the confusion matrix  cm = confusion_matrix(y_test, y_pred)    ConfusionMatrixDisplay(confusion_matrix=cm).plot()    # Display other important evaluation metrics  accuracy = accuracy_score(y_test, y_pred)  precision = precision_score(y_test, y_pred)  recall = recall_score(y_test, y_pred)    print(""Accuracy:"", accuracy)  print(""Precision:"", precision)  print(""Recall:"", recall)",6,,,,,,All of the above,,,,,,,,All of the mentioned,,Back translation,Synonym replacement,,,Text generation,,,NER,binning,moving average smoothing,,,"from bs4 import BeautifulSoup  import requests    url = 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence'  # get contents from url  content = requests.get(url).text  # get soup  soup = BeautifulSoup(content,'html.parser').select('body')[0]  # find the tag :   image_tags = soup.findAll('img') # Image tags will store the urls of all the images on the page","from PIL import Image, ImageEnhance  url = 'https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Example-dog-on-the-internet.png/220px-Example-dog-on-the-internet.png'    response = requests.get(url, stream=True)  img = Image.open(response.raw)    img = img.rotate(90)  img = img.transpose(Image.FLIP_LEFT_RIGHT)    enhancer = ImageEnhance.Sharpness(img)  img = enhancer.enhance(2)",2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 10:34:02 AM,10/04/2023 10:38:36 AM,2.50.149.139,,,,,Mariam Alkhateri,Mariam.Alkhateri@tii.ae,Direct Energy Research Center (DERC),Associate Researcher,Yes,Yes,Yes,ChatGPT,It can help in giving a quick outlook on any new topic and give the researcher good recommendations associate with a specific topic.,"yes, it could recommend good resources about any relevant topic. ",To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,Gain some exposure and jargon in the generative AI field,,Yes,1-3 months,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14423E+11,427913904,09/28/2023 01:35:49 PM,10/04/2023 10:18:47 AM,83.110.1.129,,,,,Rashed Alnuaimi,rashed.alnuaimi@tii.ae,AIDRC,Associate Researcher,Yes,Yes,Yes,MidJourney (Mainly testing out of work hours),"Yes, given how the creation of prompted AI creations is already an advancement, it helps with the field I will be moving to.","Generative AI could assist the user with generating potential data sets, which can be correlated to learning algorithms of Machine Learning.",To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,,To implement generative AI solutions in the lab or production environment,,,Yes,2+ years,5,,,"student.remove(""marks"")",,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,def is_palindrome(s): return s == s[::-1],,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],reverse the table order ascending=True,,,,,,I don't know,Inheritance,4,"text = 'Hello! We are super excited to have you join the program to learn about generative AI amongst other things.'  print(text)    ### Your Code Below    import string  from collections import Counter    text_list = text.split()   punc = string.punctuation ; punc_list = list(punc)     for i in text_list:    for j in punc_list:      if i.endswith(j):        text_list.remove(i)    text_count = Counter(text_list)  print (text_count)    # Although the excercise requested punctuations to be removed, the expected output according to the example removed other words not connected to punctuations.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14427E+11,427913904,10/03/2023 08:29:34 AM,10/04/2023 10:17:37 AM,2.50.151.47,,,,,Ankita Singh,Ankita.singh@tii.ae,Biotech Research Centre,Senior Researcher,Yes,Yes,No,"ChatGPT, DALL-E",ChatGPT basically helped me in providing analyzing small to large dataset and enhance  in research query by providing detailed knowledge for different research topic instantly. ,"AI have many potential use in my use case for e.g,  AI models for developing different insilico analysis of drug and disease study.",To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,,,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,learning to use my few specific task,Yes,3 months to 1 year,5,"del student[""marks""]",,"student.remove(""marks"")",,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,def is_palindrome(s): return s == s[::-1],,,,,,,I don't know,,,,I don't know,Polymorphism,1,i dont know,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 10:02:22 AM,10/04/2023 10:07:23 AM,83.110.1.129,,,,,Belkacem Mouhouche,belkacem.mouhouche@tii.ae,DSTU,Principal Researcher,Yes,Yes,Yes,"chatGPT, DALL-E, python",Foundation models can be used in Telecommunication either to understand standard or to generate code or manage networks,"LLM for wireless commuincation in which the LLM generates code, manages a network , adapt its parameters.",To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",,,,Yes,3 months to 1 year,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 09:36:21 AM,10/04/2023 09:43:55 AM,92.96.104.49,,,,,Safa Al Hosani,safa.alhosani@tii.ae,DERC,Electronics Engineer ,Yes,Yes,No,ChatGBT  Grammarly  GitHub Copilot  aiXcoder,Saves time to confirm a concept before going further. + quick reminder for basic information ,?,,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",,Gain some exposure and jargon in the generative AI field,,Yes,1-2 years,7,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 09:30:46 AM,10/04/2023 09:33:29 AM,83.110.1.129,,,,,Jaroslaw Kurowski,jaroslaw.kurowski@tii.ae,SSRC,,No,Yes,No,ChatGPT,"Quickly find solutions, generate sample applications.",Generating sample application.,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,,,To implement generative AI solutions in the lab or production environment,,,Yes,2+ years,7,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 09:08:44 AM,10/04/2023 09:28:25 AM,2.50.149.139,,,,,venkata sasikiran,venkata.sasikiran@tii.ae,DERC,,Yes,Yes,No,"Chat GPT, BardAI, ","Data analysis and interpretation: AI can assist in processing and analyzing large datasets of acoustic recordings quickly and accurately. It can help identify patterns, anomalies, and trends in the data that might be challenging to discern manually.    Noise reduction and filtering: AI can be used to develop algorithms for noise reduction and background noise filtering in audio recordings, improving the quality of the data and making it easier to extract relevant information.","Data Augmentation: Generative models can be used to generate synthetic sonar data and underwater scenes. This synthetic data can be mixed with real data to augment training datasets for machine learning models. Augmentation can help improve the performance of detection algorithms by providing a more diverse range of training examples.    Anomaly Detection: Generative models can be used to create a baseline representation of normal underwater acoustic and sonar signals. Any deviations from this baseline can be considered anomalies, potentially indicating the presence of divers or other underwater objects that shouldn't be there. Generative models can be trained to recognize these anomalies.    Simulation for Training: Generative models can simulate various underwater conditions, such as different water temperatures, depths, or types of terrain. This simulated data can be used to train and test sonar and diver detection algorithms in a controlled and repeatable environment.    Environmental Mapping: Generative models can be used to create 3D maps of underwater environments based on sonar data. These maps can help in visualizing underwater terrains and identifying potential hiding spots for divers. Generative models can also assist in creating predictive models of how underwater conditions might change over time.    Noise Reduction: Generative adversarial networks (GANs) can be employed to reduce noise and clutter in sonar data. By training a GAN to generate clean sonar images, it can be used to denoise real data, improving the accuracy of detection algorithms.    Diver Behavior Modeling: Generative models can be used to simulate the acoustic signatures of different diver behaviors, such as swimming, breathing, or using equipment. This can aid in training detection algorithms to distinguish between divers and other underwater objects.    Enhanced Visualization: Generative models can help in generating more detailed and realistic visual representations of underwater scenes based on sonar data. This can assist operators in better understanding the underwater environment and potential threats.    Adaptive Sonar Systems: Generative AI can be used to create adaptive sonar systems that adjust their operating parameters based on the detected environment. For example, if divers are detected, the system can automatically change its scanning patterns or frequencies to improve detection.    Multi-Modal Fusion: Generative models can be used to fuse data from multiple sensors (e.g., sonar, optical cameras, acoustic sensors) to create a more comprehensive picture of underwater situations, enhancing diver detection capabilities.",,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,Gain some exposure and jargon in the generative AI field,,Yes,3 months to 1 year,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 07:38:38 AM,10/04/2023 09:11:01 AM,83.110.1.129,,,,,Fengbo Han,Fengbo.Han@tii.ae,AMRC,Senior Researcher,Yes,Yes,Yes,ChatGPT,"1. When I ask some specific questions, AI tools such as ChatGPT can give a relative good answer or give me some advice on how to do it.  2. I can ask ChatGPT to generate some python/fortran codes to help me solve problems.","1. Generative AI may help us to create finite element models (including geometry model, mesh, model setups, etc.) after AI learns the FE software very well.  2. Generative AI may help us to do optimization in our engineering design of a product.",To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,,,,,,Yes,2+ years,5,,,"student.remove(""marks"")",,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Polymorphism,4,"import string    str1 = ""Hello! We are super excited to have you join the program to learn about generative AI amongst other things!""    strSplited = str1.split(' ')  newStr = []    for item in strSplited:      if item[-1] in string.punctuation:          s1 = item[0:-1]      else:          s1 = item      newStr.append(s1)    counts = []  for item in newStr:      k = 0      for itemI in newStr:          if item == itemI:              k = k + 1      counts.append(k)     wordsCounts = dict(zip(newStr, counts))    print(wordsCounts)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/04/2023 08:20:52 AM,10/04/2023 09:09:08 AM,2.48.80.9,,,,,Alejandro Garcia-Vaquero Velasco,alejandro.garcia-vaquero@tii.ae,ARRC,Senior Hardware Design and System Integration Engineer,Yes,Yes,Yes,"ChatGPT, Bard",They boost performance by helping me brainstorm and also creat boilerplate code.,"Yes, in robotics in many ways. Maybe even full AIs that control drones up to the motor level.",To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,,To implement generative AI solutions in the lab or production environment,,,Yes,2+ years,7,"del student[""marks""]","student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,,,,I don't know,,,,I don't know,Polymorphism,5,"def count_repeated_words(inputStr):      ## filter input string to remove punctuation chars    for char in '!-.,\n':        inputStr=inputStr.replace(char,' ')    inputStr = inputStr.lower()      listWords = inputStr.split()      countDir = {}      ## pack into dictionary the number of times each word comes up in list of words    for word in listWords:         countDir[word] = countDir.get(word, 0) + 1      print(countDir)    Text = 'Hello! We are super excited to have you join the program to learn about generative AI amongst other things.'    count_repeated_words(Text)  ",2xy + y,Gini,Entropy,Sum of squared error (variance),,,,Green,,,,All of the above,,,,,,All of the above,,,,See if it's an imbalanced dataset and apply oversampling,Try a different evaluation metric,,,Try different algorithms,Combine different models,Try stochastic gradient descent instead of batch gradient descent,Apply feature engineering techniques,I don't know,,,,,I don't know,I don't know,I dont know,I dont know,5,,,,,,All of the above,,,,,,,,All of the mentioned,,Back translation,Synonym replacement,Random deletion,,Text generation,,,Part-of-speech tagging (POS),,moving average smoothing,,,idk,idk,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,8,MobileNet,LeNet,GAN,ViT,VGG,,,TRUE,idk,idk,idk,"True, original_model.features, 4096, self.classifier(f)",idk,convolution of f and g. g is one of the functions to be convoluted. it doesnt matter which is which because its commutative.,Erosion,Dilation,,,Morphological Gradient,,,,Sampling is dependent on both the content and the size of the image,Quantization is a process that determines the value of each pixel in the image,,
1.14424E+11,427913904,09/28/2023 03:00:57 PM,10/04/2023 06:55:08 AM,92.96.205.152,,,,,Adrian Bojko,adrian.bojko@tii.ae,ARRC,Senior Computer Vision and ML Researcher,Yes,Yes,Yes,"ChatGPT, MidJourney  TensorFlow, PyTorch, ONNX, TensorRT","Create  emails and PowerPoint templates, maybe help with some coding.","Long Range: augment desert maps for different times of day, improve model robustness and make training more efficient.  Indoor: improve training based on synthetic data.",To have a solid understanding of the concepts and trends in generative AI,,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,Yes,2+ years,9,"del student[""marks""]","student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,def is_palindrome(s): return s == s[::-1],,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,adjust the referencing to be iloc[N],,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/a8a2caac-d234-4be3-96e6-ab97d88fb9cb.png,,,Polymorphism,10,"import re    text = 'Hello! We are super excited to have you join the program to learn about generative AI amongst other things.'  words = re.findall(""[a-zA-Z]+"", text.lower())  result = {w: sum([1 for w2 in words if w2==w]) for w in words}  print(result)",2xy + y,Gini,Entropy,Sum of squared error (variance),,,,Green,Cross-entropy loss,,,,,F-1 score,,Mean squared error,Precision & Recall,,,,,See if it's an imbalanced dataset and apply oversampling,Try a different evaluation metric,,Keep adding more training data,Try different algorithms,,,Apply feature engineering techniques,"Bagging creates multiple datasets by sampling with replacement, while boosting adds models sequentially and adjusts their weights based on the error of the previous models",PyTorch uses zero_grad() to sets all the gradients to zero for all the parameters in the model.,It ensures that the gradients are fresh and ready to be computed for the current iteration.,,,,nn.Module is the base class for all neural network modules in PyTorch,grad_input = [( 1/(1+np.exp(-x)) )*( 1 - 1/(1+np.exp(-x)) ) ],"# If needed:  # pip install imbalanced-learn matplotlib numpy pandas seaborn sklearn xgboost  import imblearn  import pandas as pd  import numpy as np  import matplotlib.pyplot as plt  import seaborn as sns  import xgboost as xgb    from sklearn.metrics import mean_squared_error  from sklearn.model_selection import train_test_split  from sklearn.preprocessing import MinMaxScaler  from sklearn.utils import resample    #%matplotlib inline    # Download the test dataset  from imblearn.datasets import fetch_datasets    data = fetch_datasets()['wine_quality']    # Separate data into features [X] and label [y]  X = data['data']  y = data['target']        ## 1. Apply visualizations techniques to explore the dataset  # Split data and name the columns  data_as_dict = {""x""+str(i):X[:,i] for i in range(X.shape[-1])}  # Create dataframe  df = pd.DataFrame({**data_as_dict, ""target"":y}).astype(float)    sns.set_theme(style=""ticks"")    # Use Seaborn to plot all combinations of features + KDE histogram  # It may take a few minutes.  sns.pairplot(df, hue=""target"", diag_kind='hist')  plt.show()    # We can see that:  # - There are many more ""-1"" quality wines than ""1"" quality wines.  # - The labels are not uniformly distributed (unabalanced histograms)  # - The features are not uniformly distributed, i.e., scatter plots are not uniform  # - The features are not scaled.    # 2. Create holdout dataset (or apply cross validation)  # --> At the end of step 4    # 3. Scale the features  # Scale all features/labels to [0,1]  scaler = MinMaxScaler(feature_range=(0,1))  df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)    # 4. Check for label distribution and apply resampling accordingly  print(f""Labels count: {df['target'].value_counts()}"")  ros = imblearn.over_sampling.RandomOverSampler(sampling_strategy=""minority"", random_state=42)  df_balanced, balanced_labels = ros.fit_resample(df_scaled, df_scaled['target'])    # 5. Choose one of the classification algorithms: random forest, gradient boosting, xgboost  X_balanced, y_balanced = df_balanced.drop('target', axis=1), df_balanced[['target']] # Separate feature / label  X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42) # Compute train/test splits    # Use XGBoost  # Compute regression matrices  dtrain_reg = xgb.DMatrix(X_train, y_train)  dtest_reg = xgb.DMatrix(X_test, y_test)    # 6. Tune hyperparameters  # Define hyperparameters  params = {""objective"": ""binary:logistic""}  max_n_rounds = 1000    # Prepare hyperparameter tuning  evals = [(dtrain_reg, ""train""), (dtest_reg, ""validation"")]  evals_result = {}    print(np.max(y_train),np.min(y_train))    # Train and tune model, using test as validation  model = xgb.train(     params=params,     dtrain=dtrain_reg,     num_boost_round=max_n_rounds,     evals=evals,     early_stopping_rounds=100,     evals_result=evals_result,  )    print(""Best score: {:.2f} with {} rounds"".format(                   model.best_score,                   model.best_iteration+1))      # 7. Evaluate and create the performance report  # Plot confusion matrix  y_predicted = model.predict(dtest_reg)  df_corr = df.corr()  fig, ax = plt.subplots(figsize=(13,13))  sns.heatmap(df_corr, annot=True, cmap=""GnBu"", ax=ax)  plt.title(""Confusion matrix"")    # Plot learning curves  plt.figure(figsize=(16,8))  plt.plot(evals_result['validation']['logloss'], label='train')  plt.plot(evals_result['validation']['logloss'], label='test')  plt.title(""Learning curves"")  # show the legend  plt.legend()  # show the plot    # Plot feature importance  feature_important = model.get_score(importance_type='weight')  keys = list(feature_important.keys())  values = list(feature_important.values())    data = pd.DataFrame(data=values, index=keys, columns=[""score""]).sort_values(by = ""score"", ascending=False)  data.nlargest(40, columns=""score"").plot(kind='barh')  plt.title(""Feature importance"")    plt.show()    # 8. Explain the top variables.  #  # The features in the original dataset are:  # fixed acidity   volatile acidity   citric acid   residual sugar   chlorides   free sulfur dioxide   total sulfur dioxide   density   pH   sulphates   alcohol  # #0              #1                 #2            #3               #4          #5                    #6                     #8        #9   #10         #11   #  # We can see that feature #6 (total sulfur dioxide), #5 (free sulfur dioxide) are the most important.  # Features #10 (sulphates), #2 (citric acid) are the least important ones.  #  # This can be explained by the fact that sulfates (sulfur dioxyde) and citric acid are artificially added perservative whereas sulfites are natural preservatives.  # So the amount of citric/sulfites is more easily controlled during production than sulfates. Meaning that the amount of sulfates varies more, which implies a larger effect on wine quality (within the tested ranges).  ",9,Adding noise,,Flipping,,Scaling,,,"Autonomous driving and robotics to detect objects such as cars, people, or houses",e-Commerce product categorization,Household object detection for augmented reality applications,Anomaly detection in medical diagnostic imaging,,,,,Back translation,Synonym replacement,Random deletion,,,,,Part-of-speech tagging (POS),binning,moving average smoothing,,,"import bs4  import os  import requests    from urllib.parse import urlparse      url = ""https://en.wikipedia.org/wiki/Generative_artificial_intelligence""    response = requests.get(url)  response.raise_for_status()    parsed_html = bs4.BeautifulSoup(response.text, ""html.parser"")  img_dict = {}  base_domain = urlparse(url).netloc    def harmonize_url(u):      if u[:2] == ""//"":          # Full URL          u = f""https:{u}""        elif u[0] == ""/"":          # Site-relative URL          u = f""https://en.wikipedia.org/{u}""        return u    #  tags  img_tags = (parsed_html.body.find_all('img'))  for tag in img_tags:      img_url = tag.get(""src"")        if img_url is not None:          img_url = harmonize_url(img_url)          img_caption = tag.get(""alt"")          img_dict[img_url] = img_caption    #  tags, with a different structure for captions  # Some previously found  img_tags = (parsed_html.body.find_all('figure'))  for tag in img_tags:      img_url = None      img_caption = None            img_children = tag.findChildren(""img"")      caption_children = tag.findChildren(""figcaption"")            if len(img_children) > 0:          img_url = img_children[0].get(""src"")            if img_url is not None:              img_url = harmonize_url(img_url)                if len(caption_children) > 0:                  img_caption = caption_children[0].get_text()                img_dict[img_url] = img_caption      for img_url, img_caption in img_dict.items():      print(f""Downloading image {img_url} ({img_caption})..."")      # Download file.      r = requests.get(img_url, allow_redirects=False)      with open(os.path.basename(img_url), 'wb') as f:        f.write(r.content)        # Store img_caption somewhere (this is application dependent)  ","import cv2  import math  import numpy as np  import random  import requests    img_url = ""https://upload.wikimedia.org/wikipedia/commons/8/88/Example-dog-on-the-internet.png""  # img_url = ""https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/b6942c75-c56e-4454-ae13-4d163074b7dc.png""    # Download image  img_file = ""dog.png""    r = requests.get(img_url, allow_redirects=False)  with open(img_file, 'wb') as f:      f.write(r.content)    img = cv2.imread(img_file)    def rotate(image, angle, center = None, scale = 1.0):      (h, w) = image.shape[:2]        if center is None:          center = (w / 2, h / 2)        # Perform the rotation      M = cv2.getRotationMatrix2D(center, angle, scale)      rotated = cv2.warpAffine(image, M, (w, h))        return rotated    random.seed(42)    for i in range(100):      print(f""Generating image #{i+1}..."")        img_augmented = np.copy(img)      ## Flipping      # 0 means flipping around the x-axis      # 1 means flipping around y-axis.       # -1 means flipping around both axes.       # -2 means no flipping      flip = random.randint(-2, 1)      if flip != -2:          img_augmented = cv2.flip(img_augmented, flip)        ## Rotation      rotation_angle = random.random()*360      img_augmented = rotate(img_augmented, rotation_angle)        ## Sharpening      # 0 means no sharpening      # 1 means apply sharpening      sharpening = random.randint(0, 1)        if sharpening == 1:          # Use a basic sharpening kernel          kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])          img_augmented = cv2.filter2D(img_augmented, -1, kernel)              cv2.imshow(""Augmented dog"", img_augmented)      cv2.waitKey(0)",5,Stop-word Removal,,Stemming,Lemmatization,Tokenization,,GPT,,,,T5 is a encoder-decoder mixed models,BERT models are encoder models,GPT-3 is an autoregressive model,GPT models are encoder-only models,,Data cleaning,Deduplication,Decontamination,,PII Control,,Separate words into individual morphemes and identify the class of the morphemes,,,Refer to the same objects (“entities”),,,,Co-reference resolution,Semantic-role labelling,Named entity recognition,Word sense disambiguation,,,,This pipeline requires that labels be given to classify this text.,TRUE,,,A sequence-to-sequence model,,,The sequence length and the batch size,WordPiece,,,BPE,Unigram,,"In NLP, attention mechanism is useful in sequence to sequence tasks such as translation, speech recognition, and summarization",The attention mechanism is good at handling long sequence input,,Attention mechanism is good at context-aware processing,,A string containing all of the tokens,It's good practice to pad and truncate with the tokenizer as every input is a batch.,Find the persons mentioned in a sentence.,Some of the tokens in the input sentence are randomly masked and the labels are the original input tokens.,Writing short reviews of long documents,Answering questions about a document,Translating a text in Arabic into English,,,10,MobileNet,LeNet,,,VGG,,,FALSE,"Typically, we would use the last layer of VGG19's encoder to compute features (= the last layer of the convolutional layers, which is layer #16 in VGG19). This encoder is typically pre-trained on general datasets like ImageNet. Note that the raw feature output is 3D, so there is usually a MaxPool operation to flattent the feature into a 1D vector.    Once the encoder is pre-trained, we add the decoder at the end of the network. The decoder is usually made of one or more fully connected layers; there are three of them in VGG19. Then we fine-tune the network: fine-tuning means that only the decoding layers are trained using classification data (is cancer or not), which has the advantage of fast training and avoiding catastrophic forgetting. The output of the decoder is what is needed by medical professionals: a vector containing the probabilities of every classification: not cancer / cancer type 1 / etc.","1) Extract features from layer conv4_3, size 512 (after MaxPool)  2) Extract features from layer fc6, size 4096  3) Extract features from layer fc7. size 4096",Add a fully connected layer whose size is the number of classes we want to classify (not cancer / cancer type 1 / etc.) and fine-tune the network.,"True, original_model.features, 4096, self.classifier(f)","We have total loss = style loss + content loss. with:  Style loss = mean squred distance between Gram matrices (the distribution of features over a set of feature maps in a given layer).  Content loss = squared error loss between features.    Most activations (after each block of the network) are ReLU, except for the last layers that uses tanh.",This is a Fourier transform where g is the kernel/filtering function. It can be used for frequency analysis of signals or for spatial analysis of images.,Erosion,Dilation,Opening,Closing,Morphological Gradient,Top Hat,Black Hat,Sampling is the process that determines the size of the image to be obtained,,Quantization is a process that determines the value of each pixel in the image,,
1.14426E+11,427913904,10/01/2023 12:45:53 AM,10/04/2023 03:15:50 AM,12.177.129.82,,,,,Nektarios Sfyris,nektarios.sfyris@tii.ae,ARRC,Senior Robotics Engineer,Yes,Yes,Yes,chatgpt,solving well-defined and not too complex problems,"we have a lot of people who do engineering and need access to real-time and correct data, so minimizing the effort needed to access that data is very important",,,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,Gain some exposure and jargon in the generative AI field,,Yes,2+ years,7,"del student[""marks""]","student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,def is_palindrome(s): return s == s[::-1],,,,adding .drop_duplicates() to employee['salary'],reverse the table order ascending=True,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,6,"text = 'Hello! We are super excited to have you join the program to learn about generative AI amongst other things.'  print(text)    ### Your Code Below  import string  # Translator  trans = str.maketrans('', '', string.punctuation)    dict = {}    # Split to words  sentence = text.split()    for word in sentence:      # Remove punctuation      word_after_trans = word.translate(trans)        # Count each word      if word_after_trans:          if word_after_trans in dict:              dict[word_after_trans] += 1          else:              dict[word_after_trans] = 1    print(dict)",2xy + y,,,,,All of the mentioned,,Rain,,,,All of the above,,,,,,All of the above,,,Look for data leakage,See if it's an imbalanced dataset and apply oversampling,,,Keep adding more training data,Try different algorithms,Combine different models,Try stochastic gradient descent instead of batch gradient descent,Apply feature engineering techniques,I don't know,,,,,I don't know,I don't know,no answer,no answer,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,09/28/2023 01:35:40 PM,10/03/2023 11:50:44 PM,31.215.42.173,,,,,Jide Oyebanji,jide.oyebanji@yahoo.com,AMRV,Simulation Engineer,Yes,Yes,Yes,ChatGTP,NA,Topology Optimisation,To have a solid understanding of the concepts and trends in generative AI,,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",,,,Yes,2+ years,8,,"student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,def is_palindrome(s): return s == s[::-1],,,,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,7,"import re  wordBag = {}  text = “Hello! We are super excited to have you join the program to learn about generative AI amongst other things”    text = re.split(“!| “, text)  text.remove(‘')    for word in text:         wordBag[word]  = text.count(word)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/03/2023 08:56:18 PM,10/03/2023 09:22:43 PM,31.215.18.156,,,,,Hamza Alobeidli,Hamza.Alobeidli@tii.ae,AIDRC,Associate Researcher,Yes,Yes,Yes,"Falcon LLM, Noor LLM","Reduce the time looking for specific information. Improve the writing,,, etc.",I am developing Falcon 180B LLM and Finetune it.,To have a solid understanding of the concepts and trends in generative AI,,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,,To implement generative AI solutions in the lab or production environment,,,Yes,2+ years,10,,"student.pop(""marks"")","student.remove(""marks"")",,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,10,text = 'Hello! We are super excited to have you join the program to learn about generative AI amongst other things.'  print(text)    ### Your Code Below  import string    words = text.split()  words = [word.strip(string.punctuation) for word in words]    word_counts = {}    for word in words:    if word in word_counts:      word_counts[word] += 1    else:      word_counts[word] = 1    print(word_counts),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/03/2023 08:15:27 PM,10/03/2023 08:31:31 PM,217.164.230.18,,,,,Jiguang,He,DSRC,Senior Researcher,Yes,Yes,I do not understand what a prompt is,"Python, Keras","Grammer corrections, literature review",positioning and environmental mapping,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,,,,,,,Yes,1-3 months,6,,,"student.remove(""marks"")",,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,,I don't know,,,,I don't know,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/a8a2caac-d234-4be3-96e6-ab97d88fb9cb.png,,,I don't know,5,"import string    def word_count_without_punctuation(text):      # Create a translation table to remove punctuation      translator = str.maketrans('', '', string.punctuation)            # Remove punctuation and convert text to lowercase      cleaned_text = text.translate(translator).lower()            # Split the cleaned text into words      words = cleaned_text.split()            # Initialize an empty dictionary to store word counts      word_count = {}            # Count the occurrences of each word      for word in words:          if word in word_count:              word_count[word] += 1          else:              word_count[word] = 1            return word_count    # Example usage:  text = ""Hello! We are super excited to have you join the program to learn about generative AI amongst other things!""  result = word_count_without_punctuation(text)  print(result)  ",2xy + y,,,,,,I don't know,Green,,,,All of the above,,,,,,All of the above,,,,See if it's an imbalanced dataset and apply oversampling,,,Keep adding more training data,,,,,I don't know,PyTorch uses zero_grad() to sets all the gradients to zero for all the parameters in the model.,,,,,All of the above,1/x,"import seaborn as sns    # Visualize the distribution of wine quality  sns.countplot(x='target', data=data)  plt.xlabel('Wine Quality')  plt.ylabel('Count')  plt.title('Distribution of Wine Quality')  plt.show()  from sklearn.model_selection import train_test_split    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  from sklearn.preprocessing import StandardScaler    scaler = StandardScaler()  X_train_scaled = scaler.fit_transform(X_train)  X_test_scaled = scaler.transform(X_test)  from sklearn.preprocessing import StandardScaler    from imblearn.over_sampling import RandomOverSampler    ros = RandomOverSampler(random_state=42)  X_train_resampled, y_train_resampled = ros.fit_resample(X_train_scaled, y_train)  from sklearn.ensemble import RandomForestClassifier    clf = RandomForestClassifier(random_state=42)  from sklearn.model_selection import GridSearchCV    param_grid = {      'n_estimators': [100, 200, 300],      'max_depth': [None, 10, 20],  }    grid_search = GridSearchCV(clf, param_grid, cv=5, n_jobs=-1)  grid_search.fit(X_train_resampled, y_train_resampled)    best_params = grid_search.best_params_  feature_importances = grid_search.best_estimator_.feature_importances_        ",4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/03/2023 07:05:08 PM,10/03/2023 07:09:53 PM,31.219.145.116,,,,,Zubair Akhter,zubair.akhter@tii.ae,DERC,Senior Antenna Engineer,Yes,Yes,No,ChatGPT and Dall-E,No comment,Maybe ,,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,,,To implement generative AI solutions in the lab or production environment,,,Yes,1-3 months,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14428E+11,427913904,10/03/2023 05:30:16 PM,10/03/2023 05:41:36 PM,5.195.204.111,,,,,Tony Joseph,tony.joseph@tii.ae,ARRC,Mechatronics Engineer,Yes,Yes,Yes,ChatGPT,Help me summarize or make my messages more concise.,"I work on Low Level Control Architecture and Programming, and writing documentation for the same it can help me be more clear and concise.",To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,,,Gain some exposure and jargon in the generative AI field,,Yes,1-2 years,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14426E+11,427913904,10/02/2023 08:27:26 AM,10/03/2023 03:14:14 PM,2.50.149.139,,,,,Jaeden Amero,jaeden.amero@tii.ae,Directed Energy,Principal Software Engineer,Yes,Yes,Yes,"For generative AI, I've worked with and prefer the ""host it yourself"" options like AUTOMATIC1111 (for Stable Diffusion) and Oobabooga Text UI (for Falcon, Alpaca, Llama, and other LLM). I have experience with Sci-kit Learn, Pandas, NumPy, and recently started learning PyTorch.","LLMs would be primarly as a complement to Google searching (learning about things), but also as a way to improve my own writing. I'm more interest in multi-modal models than test-only LLMs. I currently work on and see uses for AI tools in signal processing applications, including classification and anomaly detection.","Yes, many. (See previous reply)",,,,,,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,Data modeling and processing; computer vision (in RF),Yes,2+ years,8,"del student[""marks""]","student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,8,"import re    text = ""Hello! We are super excited to have you join the program to learn about generative AI amongst other things!""    stripped = re.sub(r'[^\w\s]', '', text).lower()  wl = stripped.split(' ')  wc = {x: wl.count(x) for x in wl}    print(repr(wc))",2xy + y,Gini,Entropy,Sum of squared error (variance),,,,Green,Cross-entropy loss,,,,,F-1 score,,,Precision & Recall,,,,Look for data leakage,See if it's an imbalanced dataset and apply oversampling,Try a different evaluation metric,,Keep adding more training data,Try different algorithms,Combine different models,,Apply feature engineering techniques,"Bagging creates multiple datasets by sampling with replacement, while boosting adds models sequentially and adjusts their weights based on the error of the previous models",PyTorch uses zero_grad() to sets all the gradients to zero for all the parameters in the model.,It ensures that the gradients are fresh and ready to be computed for the current iteration.,It's often called after running the backward() function during training.,All of the above,,nn.Module is the base class for all neural network modules in PyTorch,grad_input = grad * (1 / (1 + np.exp(-self.x))) * (1 - (1 / (1 + np.exp(-self.x)))) ,"#!/usr/bin/env python3    import matplotlib.pyplot as plt  import numpy as np  import pandas as pd  import seaborn as sns  import sys  from collections import Counter  from sklearn.ensemble import RandomForestClassifier  from sklearn.preprocessing import RobustScaler  from sklearn.metrics import (      ConfusionMatrixDisplay,      accuracy_score,      confusion_matrix,      precision_recall_fscore_support,  )  from sklearn.model_selection import (      RandomizedSearchCV,      train_test_split,  )    # Download the test dataset  from imblearn.datasets import fetch_datasets      def getDatasetAsDataframe():      data = fetch_datasets()[""wine_quality""]        # Add feature names, as imblearn doesn't provide them like sklearn does.      data.feature_names = [          ""alcohol"",          ""chlorides"",          ""citric acid"",          ""density"",          ""fixed acidity"",          ""free sulfur dioxide"",          ""pH"",          ""residual sugar"",          ""sulphates"",          ""total sulfur dioxide"",          ""volatile acidity"",      ]        df = pd.DataFrame(          data=np.c_[data.data, data.target], columns=data.feature_names + [""target""]      )      df.info()      df.describe()        return df      def exploreDataset(df):      # -- From the histogram, we can see the dataset is very imbalanced, with      # thousands of ""-1"" target and almost two hundred ""1"" target.      print(""Dataset Exploration"")      print(""-------------------"")      print(""Label,Instances: "", end="""")      print(sorted(Counter(df.target).items()))      print(""Label,Frequency: "", end="""")      print({key: value / len(df.target) for key, value in Counter(df.target).items()})      df.target.value_counts().plot(kind=""bar"")      df.plot.hist(by=""target"", title=""Histogram by Target"")        # Target vs features scatter plots      df.plot(x=""target"", y=""free sulfur dioxide"", kind=""scatter"")      # View a subset of features in a pair plot      sns.pairplot(df[[""alcohol"", ""pH"", ""chlorides"", ""free sulfur dioxide"", ""target""]], hue=""target"")      def main():      df = getDatasetAsDataframe()        # 1. Apply visualizations techniques to explore the dataset      exploreDataset(df)        # Separate data into features [X] and label [y]      X = df.iloc[:, :-1].values  # features      y = df.iloc[:, -1:].values.ravel()  # labels        # 2. Create holdout dataset (or apply cross validation)      # -- Split into training and evaluation sets      X_train, X_test, y_train, y_test = train_test_split(          X, y, test_size=0.33, random_state=42      )        # 3. Scale the features      scaler = RobustScaler().fit(X_train)      X_train = scaler.transform(X_train)      X_test = scaler.transform(X_test)        # 4. Check for label distribution and apply resampling accordingly      # -- If I understand what's being asked, RobustScaler does this already        # 5. Choose one of the classification algorithms: random forest, gradient boosting, xgboost      # -- We've chosen random forest      estimator = RandomForestClassifier(random_state=42, n_jobs=-1)        # 6. Tune hyperparameters      # -- We use sklearn's RandomizedSearchCV to look for which parameters works      # best for our RandomForestClassifier on our problem/dataset.      grid = {}      grid[""bootstrap""] = [True, False]      grid[""max_depth""] = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120]      grid[""max_features""] = [""sqrt"", ""log2"", None]      grid[""min_samples_leaf""] = [1, 2, 4, 8]      grid[""min_samples_split""] = [2, 5, 10, 20]      grid[""n_estimators""] = [100, 200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]      model = RandomizedSearchCV(          estimator=estimator,          param_distributions=grid,          n_iter=100,          cv=5,          n_jobs=-1,          verbose=True,      )      model.fit(X_train, y_train)        # 7. Evaluate and create the performance report      # -- We use calculate our model accuracy and create a confusion_matrix to      # show misclassification.      pred_train = model.predict(X_train)      acc_train = accuracy_score(y_train, pred_train)      print(f""Training accuracy: {acc_train}"")      pred_test = model.predict(X_test)      acc_test = accuracy_score(y_test, pred_test)      print(f""Test accuracy: {acc_test}"")        # 8. Explain the top variables.      # -- Not quite sure what this means. If this means ""the features that best      # predict the outcome"", then we can read that from the models.      print(""Top Variables"")      print(""-------------"")      features = list(          zip(df.columns.to_list(), model.best_estimator_.feature_importances_)      )      features.sort(key=lambda x: x[1], reverse=True)      print(f""Most important features:\n {features}"")        precision, recall, fbeta_score, _ = precision_recall_fscore_support(          y_test, pred_test, pos_label=1, average=""binary""      )      print(""Performance Report"")      print(""------------------"")      print(f""Precision:\t{precision}"")      print(f""Recall:\t{recall}"")      print(f""F-beta:\t{fbeta_score}"")        # -- Display a confusion matrix      cm = confusion_matrix(y_test, pred_test)      cm_display = ConfusionMatrixDisplay(cm).plot()      plt.show()        return 0      if __name__ == ""__main__"":      sys.exit(main())  ",6,Adding noise,,Flipping,,Scaling,,,"Autonomous driving and robotics to detect objects such as cars, people, or houses",,Household object detection for augmented reality applications,Anomaly detection in medical diagnostic imaging,Facial feature points for face detection,"Irregular objects such as buildings, vehicles, or trees for autonomous vehicles",,,Back translation,Synonym replacement,Random deletion,,Text generation,,,Part-of-speech tagging (POS),binning,moving average smoothing,,,"#!/usr/bin/env python3  import bs4  import os  import requests  import sys      url = ""https://en.wikipedia.org/wiki/Generative_artificial_intelligence""  base_url = ""https://en.wikipedia.org/""      def main():      req = requests.get(url)      bs = bs4.BeautifulSoup(req.content, ""html.parser"")      for e in bs.select(""figure""):          img = e.img          if img:              src = base_url + img[""src""]              name = os.path.basename(src)              with open(name, ""wb"") as f:                  content = requests.get(src).content                  f.write(content)                text = """"              caption = e.figcaption.text              if caption:                  with open(name + "".caption"", ""w"") as f:                      f.write(f""{caption}"")        return 0      if __name__ == ""__main__"":      sys.exit(main())  ","#!/usr/bin/env python3  import os  import requests  import sys  from PIL import Image, ImageEnhance      url = ""https://upload.wikimedia.org/wikipedia/commons/8/88/Example-dog-on-the-internet.png""  name = os.path.basename(url)      def download():      req = requests.get(url)      with open(name, ""wb"") as f:          content = requests.get(url).content          f.write(content)      def sharp(im):      enhancer = ImageEnhance.Sharpness(im)      factor = 5      out = enhancer.enhance(factor)      out.save(""sharp-"" + name)      def rotate(im):      angle = 90      out = im.rotate(angle, expand=True)      out.save(""rotate-"" + name)      def flip(im):      out = im.transpose(Image.FLIP_LEFT_RIGHT)      out.save(""flip-"" + name)      def main():      download()      im = Image.open(name)      sharp(im)      rotate(im)      flip(im)        return 0      if __name__ == ""__main__"":      sys.exit(main())  ",6,Stop-word Removal,,,Lemmatization,Tokenization,,GPT,T5,BERT,,T5 is a encoder-decoder mixed models,BERT models are encoder models,GPT-3 is an autoregressive model,,,Data cleaning,Deduplication,,Toxicity and Bias Control,PII Control,,Separate words into individual morphemes and identify the class of the morphemes,,"Given a sentence or larger chunk of text, determine which words (“mentions”)",Refer to the same objects (“entities”),,,,Co-reference resolution,,Named entity recognition,Word sense disambiguation,,,,This pipeline requires that labels be given to classify this text.,FALSE,,,A sequence-to-sequence model,,,I don't know,WordPiece,,,BPE,Unigram,,"In NLP, attention mechanism is useful in sequence to sequence tasks such as translation, speech recognition, and summarization",The attention mechanism is good at handling long sequence input,,Attention mechanism is good at context-aware processing,,"A list of strings, each string being a token",The tokenizer and model should always be from the same checkpoint.,Find the grammatical components in a sentence.,Some of the tokens in the input sentence are randomly masked and the labels are the original input tokens.,Writing short reviews of long documents,Answering questions about a document,Translating a text in Arabic into English,Fixing the messages sent by my nephew/friend so they're in proper English,,5,MobileNet,LeNet,,,VGG,,,FALSE,I don't know.,I don't know.,"The dataset is too large to classify manually, even if humans could understand the extracted features. Maybe a GAN?","True, original_model.features, 4096, self.classifier(f)","I'm not too familiar with neural style transfer, but I'd expect at least two loss functions to be involved: style loss and content loss. Style loss would describe how similar in style (maybe general colors or shapes), and content loss would be more strict/firm and require spatial conherence between the output and the content image.","This is convolution. g(t) is what f(t) is being convolved with. Some might call g(t) a ""kernel"" (e.g. in an image processing context). In the specific context of computer vision, I don't know if g(t) has some typical meaning.",Erosion,Dilation,,,,,,Sampling is the process that determines the size of the image to be obtained,,Quantization is a process that determines the value of each pixel in the image,,
1.14426E+11,427913904,10/02/2023 12:42:47 PM,10/03/2023 02:24:05 PM,83.110.1.129,,,,,Eloy,eloy.roura@tii.ae,ARRC,Senior Director,Yes,Yes,No,CNNs for image processing,"It can help to interact with machines such as autonomous robots.  In my daily job it can also help to ease some tasks, for example making first drafts for proposals, new ideas on unknown topics, emails, etc.",Data augmentation for training models,To have a solid understanding of the concepts and trends in generative AI,,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,Yes,2+ years,6,"del student[""marks""]","student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Abstraction,10,I've not coded anything for the last year,I don't Know,,,,,,I don't know,Green,Cross-entropy loss,,Mean squared error,,,F-1 score,,,Precision & Recall,,,,,See if it's an imbalanced dataset and apply oversampling,Try a different evaluation metric,,Keep adding more training data,,Combine different models,,,"Bagging creates multiple datasets by sampling with replacement, while boosting adds models sequentially and adjusts their weights based on the error of the previous models",PyTorch uses zero_grad() to sets all the gradients to zero for all the parameters in the model.,,,,,"When creating a new nn class in PyTorch, we need to define both forward and backward methods",I don't know,it has been too long since my last DL coding experience,5,Adding noise,,Flipping,,Scaling,,,"Autonomous driving and robotics to detect objects such as cars, people, or houses",e-Commerce product categorization,Household object detection for augmented reality applications,Anomaly detection in medical diagnostic imaging,Facial feature points for face detection,"Irregular objects such as buildings, vehicles, or trees for autonomous vehicles",All of the mentioned,,,Synonym replacement,,,Text generation,,,Classification,,moving average smoothing,,,I am not for coding exercises atm,I am not for coding exercises atm (I could easily use openCV together with numpy for that),2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9,MobileNet,LeNet,GAN,,VGG,,,FALSE,for classification you will need an activation layer after the fc. the activation layer could be a softmax for example.,"you could use fc6 or fc7, both have 4096 features.",you can run the inference to extract the features together with an activation function to classify the vector into one class or another.,"True, original_model.features, 1000, self.classifier(f)","you would use three losses, one for the content, one for the style and one for the total variation.",i don't know,Erosion,Dilation,Opening,Closing,,,,,Sampling is dependent on both the content and the size of the image,,,
1.14427E+11,427913904,10/03/2023 01:10:56 PM,10/03/2023 01:16:54 PM,193.64.211.192,,,,,Oksana Sandulenko,oksana.sandulenko@tii.ae,SSRC,Program Manager,Yes,Yes,No,"ChatGPT, GrammarlyGo","summarizing meetings into MoMs, writing glorified emails to partners, etc.",No,To have a solid understanding of the concepts and trends in generative AI,,To be self-sufficient with no-code AI tools for business,,,,,Gain some exposure and jargon in the generative AI field,,No,I do not know Python,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14427E+11,427913904,10/03/2023 10:21:02 AM,10/03/2023 12:30:40 PM,5.195.220.140,,,,,Alvaro Orgaz Feurtes,alvaro.orgaz@tii.ae,Quantum Research Centre,Lead Quantum Computing Control,Yes,Yes,Yes,ChatGPT,"In many ways, particularly when developing software and preparing all types of documents.",Potentially helping with automated characterisation of quantum processors,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,Gain some exposure and jargon in the generative AI field,,Yes,2+ years,8,"del student[""marks""]","student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,5,"import re    def package_word_count(msg: str) -> dict[str, int]:      words = msg.split("" "")      result = {}      for word in words:          stripped_word = re.sub('[^a-zA-Z0-9]', '', word)          if not stripped_word in result:              result[stripped_word] = 1          else:              result[stripped_word] += 1      return result    msg = ""Hello! We are super excited to have you join the program to learn about generative AI amongst other things!""  print(package_word_count(msg))  ",2xy + y,,,,,,I don't know,Green,Cross-entropy loss,,,,,,,,,,I don't know,,,See if it's an imbalanced dataset and apply oversampling,,,Keep adding more training data,Try different algorithms,Combine different models,,Apply feature engineering techniques,I don't know,,,,,I don't know,I don't know,I don't know,I don't know,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14426E+11,427913904,10/02/2023 09:12:58 AM,10/03/2023 12:22:22 PM,2.50.151.47,,,,,Raghvendra Mall,raghvendra.mall@tii.ae,Biotechnology Research Center,Lead Researcher,Yes,Yes,Yes,Programming perspective:  a) sklearn b) tensorflow c) pytorch d) pytorch-geometric e) caret f) kernlab g) h2o   I have created several applications myself including machine learning webserver for protein property prediction (https://deeplearning-protein.qcri.org/index.html)    AI applications:  a) ChatGPT b) Dall-E,"ChatGPT can enable biotechnologists such as me for code generation assistance i.e. enable writing optimize code for various bioinformatics tasks such as whole genome analysis, differential expression analysis, question answering.    Moreover, biological LLMs such as ESM model can be fine-tuned for specific biological task such as protein solubility, toxicity, crystallization prediction tasks which are imperative in drug development and pharmaceutical settings","Biological LLMs such as ESM model can be fine-tuned for specific biological task such as protein solubility, toxicity, crystallization prediction tasks which are imperative in drug development and pharmaceutical settings.    Moreover, generative AI can be useful for designing new antibodies or chimeric antigen receptors with specific properties that can allow targeted therapy such as T-cell or Antibody based therapeutics",,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,,To learn how to fine-tune and apply AI models for my business domains,,,,,Yes,2+ years,9,"del student[""marks""]","student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,def is_palindrome(s): return s == s[::-1],,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,9,https://colab.research.google.com/drive/1KqNG26U4SOOOwqkL8PZNz0IxJO8GxpUo?usp=sharing,2xy + y,Gini,Entropy,Sum of squared error (variance),,,,Green,Cross-entropy loss,,,,,F-1 score,,,Precision & Recall,,,,,See if it's an imbalanced dataset and apply oversampling,Try a different evaluation metric,,Keep adding more training data,,Combine different models,,Apply feature engineering techniques,"Bagging creates multiple datasets by sampling with replacement, while boosting adds models sequentially and adjusts their weights based on the error of the previous models",,,,All of the above,,nn.Module is the base class for all neural network modules in PyTorch,grad*(1/(1+np.exp(-self.x)))*(1-1/(1+np.exp(-self.x))),https://tiiuae-my.sharepoint.com/:u:/g/personal/raghvendra_mall_tii_ae/EcTXH_wkTJ5Br1x0VJlpZ_gBIT-qRysGQw8LlQPRopAYBQ?e=RXI57N,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14427E+11,427913904,10/03/2023 10:32:08 AM,10/03/2023 10:34:45 AM,83.110.1.129,,,,,Shaima Albedwawi,Shaima.Albedwawi@tii.ae,Propulsion and Space Research Center,Senior Associate Researcher,Yes,No,No,None,Do quick literature survey to start from ,PPT slides design,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,,,,,,Yes,1-3 months,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14427E+11,427913904,10/03/2023 07:57:45 AM,10/03/2023 10:24:11 AM,83.110.1.129,,,,,Nicole Gervasoni,nicole.gervasoni@tii.ae,DSRC,Security Researcher,Yes,Yes,Yes,ChatGPT,yes,"help write quick code, gives information about tools",,,,To gain technical experience with machine learning and AI,,,,,,Yes,2+ years,9,"del student[""marks""]",,,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,def is_palindrome(s): return s == s[::-1],,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,,reverse the table order ascending=True,,,,,,I don't know,Inheritance,6,"import string  res = {}  for word in text.split(' '):    word = word.translate(str.maketrans('', '', string.punctuation))    if word in res:      res[word] = res[word] + 1    else:      res[word] = 1    res",2x + y,,,,,,I don't know,Green,,,Mean squared error,,,F-1 score,,,Precision & Recall,,,,,See if it's an imbalanced dataset and apply oversampling,Try a different evaluation metric,,Keep adding more training data,Try different algorithms,,,Apply feature engineering techniques,"Bagging creates multiple datasets by sampling with replacement, while boosting adds models sequentially and adjusts their weights based on the error of the previous models",,,,,I don't know,I don't know,don't know,don't know,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14427E+11,427913904,10/03/2023 09:08:20 AM,10/03/2023 09:20:24 AM,2.50.149.139,,,,,Mae AlMansoori,mae.almansoori@tii.ae,DERC,Principal Researcher,Yes,Yes,Yes,ChatGPT  MidJourney  Dall-E,It can take care of the repetitive tasks and save me time. Generate codes for data representation.,Comprehensive data analysis of a measurement campaign. ,,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,,,Gain some exposure and jargon in the generative AI field,,Yes,3 months to 1 year,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14427E+11,427913904,10/03/2023 09:16:36 AM,10/03/2023 09:20:23 AM,2.50.151.47,,,,,Hibba Yousef,Hibba.Yousef@tii.ae,BRC,Senior Associate Researcher,Yes,Yes,Yes,"ChatGPT, Bard","They eliminate monotonous tasks and greatly speed up tasks like researching, coding and comprehending difficult concepts.","Yes, generative AI would be extremely useful in cases of medical imaging where data is imbalanced and/or scarce.",To have a solid understanding of the concepts and trends in generative AI,,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,Yes,1-2 years,8,"del student[""marks""]","student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,8,"import string    def word_count(sentence):      # Step 1: Strip punctuation and convert to lowercase      translator = str.maketrans('', '', string.punctuation)      words = sentence.lower().translate(translator).split()        # List of common stopwords to exclude      stopwords = {'we', 'are', 'to', 'have', 'you', 'our', 'the', 'and', 'of', 'in', 'about', 'amongst', 'other'}        # Use a dictionary for counting occurrences, excluding stopwords      word_counts = {}      for word in words:          # Remove trailing punctuation          word = word.rstrip('!,.')                    if word not in stopwords:              if word in word_counts:                  word_counts[word] += 1              else:                  word_counts[word] = 1        return word_counts",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14427E+11,427913904,10/03/2023 07:50:07 AM,10/03/2023 09:08:42 AM,83.110.1.129,,,,,Renato Mello,renato.mello@tii.ae,Quantum Research Center,Associate Researcher,Yes,Yes,Yes,ChatGPT,Yes,Yes,To have a solid understanding of the concepts and trends in generative AI,,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",,Gain some exposure and jargon in the generative AI field,,Yes,2+ years,8,"del student[""marks""]","student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,8,"import numpy as np    string = ""Hello! We are super excited to have you join the program to learn about generative AI amongst other things!""  string = string.replace(""!"", """").split("" "")    words, counts = np.unique(string, return_counts=True)    dictionary = {word: count for word, count in zip(words, counts)}  print(dictionary)",2xy + y,Gini,Entropy,Sum of squared error (variance),,,,Green,Cross-entropy loss,,,,,F-1 score,,,Precision & Recall,,,,Look for data leakage,See if it's an imbalanced dataset and apply oversampling,Try a different evaluation metric,,,Try different algorithms,Combine different models,,Apply feature engineering techniques,"Bagging creates multiple datasets by sampling with replacement, while boosting adds models sequentially and adjusts their weights based on the error of the previous models",PyTorch uses zero_grad() to sets all the gradients to zero for all the parameters in the model.,It ensures that the gradients are fresh and ready to be computed for the current iteration.,,,,All of the above,np.exp(-x) / (1 + np.exp(-x))**2,.,6,,,,,,,I don't know,"Autonomous driving and robotics to detect objects such as cars, people, or houses",,Household object detection for augmented reality applications,,,"Irregular objects such as buildings, vehicles, or trees for autonomous vehicles",,,,,,,Text generation,Trasformer-based,,Part-of-speech tagging (POS),binning,moving average smoothing,,,.,.,5,Stop-word Removal,,Stemming,,Tokenization,,GPT,T5,BERT,,,BERT models are encoder models,,,I don't know,Data cleaning,,,,,I don't know,I don't know,,,,,,I don't know,,,,,,All of the mentioned,,"The 🤗 Transformers library is broken, as usual.",FALSE,An encoder model,,A sequence-to-sequence model,,,The sequence length and the batch size,,,Splitting on whitespace and punctuation,,Unigram,,,,,,I don't know,I don't know,I don't know,Find the grammatical components in a sentence.,I don't know,Writing short reviews of long documents,,Translating a text in Arabic into English,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14427E+11,427913904,10/03/2023 08:40:13 AM,10/03/2023 08:46:49 AM,92.97.67.110,,,,,Ali Yaqoob,ali.yaqoob@tii.ae,DERC,Senior Associate Researcher,Yes,Yes,Yes,"ChatGPT, MidJourney, Lexica ART.",They can summarize scientific papers to make the literature review process a lot faster. ,Summarizing scientific papers  Organizing equipment lists,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,Gain some exposure and jargon in the generative AI field,,No,I do not know Python,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14427E+11,427913904,10/03/2023 08:35:45 AM,10/03/2023 08:39:58 AM,2.50.149.139,,,,,Luciano Prado de Oliveira,luciano.prado@tii.ae,Direct Energy Research Center,Lead Researcher,Yes,No,No,NA,Provide information about technical topics.,"General information about sensors, etc.",,To learn how to use prompting to make myself more efficient at work,,,,,,,,No,I do not know Python,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14427E+11,427913904,10/03/2023 07:31:26 AM,10/03/2023 08:33:59 AM,2.50.149.139,,,,,Hamad Alyahyaee,hamad.alyahyaee@tii.ae,DERC,,Yes,Yes,No,*Chat-GPT  *Mid-Journey,it can increase the efficiency and optimize the use of time.  ,they can help by providing a baseline ( a start template) for all new scripts written in python / Matlab or any other programming language.,,,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,Yes,1-3 months,5,"del student[""marks""]","student.pop(""marks"")",,,I don't know,Yna PYnat tive PYnativ vitanYP,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,,,,I don't know,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/4b0a1e6b-c3dd-48f4-9437-0286177c6d83.png,,I don't know,2,I do not know ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14427E+11,427913904,10/02/2023 09:28:08 PM,10/02/2023 09:37:31 PM,92.96.200.122,,,,,Hibba Yousef,Hibba.Yousef@tii.ae,Biotechnology Research Center,Senior Associate Researcher,Yes,Yes,Yes,"ChatGPT, Bard","They eliminate monotonous tasks and greatly speed up tasks like researching, coding and comprehending difficult concepts. ","Yes, generative AI would be extremely useful in cases of medical imaging where data is imbalanced and/or scarce.",To have a solid understanding of the concepts and trends in generative AI,,,To gain technical experience with machine learning and AI,,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,Yes,1-2 years,7,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14427E+11,427913904,10/02/2023 07:34:11 PM,10/02/2023 07:36:37 PM,2.50.244.28,,,,,Iman Prayudi,Iman.Prayudi@tii.ae,DERC,Electronics Engineer,Yes,Yes,I do not understand what a prompt is,ChatGPT,"Search engine, English writing","Writing report, literature review, market research",To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,,,,,,Yes,2+ years,9,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14426E+11,427913904,10/02/2023 01:56:45 PM,10/02/2023 06:39:23 PM,161.0.213.126,,,,,Paola Ardon,paola.ardon@tii.ae,ARRC,Lead Researcher,Yes,Yes,Yes,"ChatGPt, MidJourney, Dall-E, Bard",They help to efficiently narrow the search previously done on the internet browser,Facilitating Human-robot collaboration and centered technologies across different use cases,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,,,,,Gain some exposure and jargon in the generative AI field,,Yes,2+ years,6,"del student[""marks""]","student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],reverse the table order ascending=True,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,7,https://tiiuae-my.sharepoint.com/:u:/g/personal/paola_ardon_tii_ae/ETIXYhaKqO5HobXJanGFI7IBhjcOf-Y7aSzJP90wa4wHsw?e=hivzyE,2xy + y,Gini,Entropy,,,,,Green,Cross-entropy loss,,,,,F-1 score,,Mean squared error,Precision & Recall,,,,Look for data leakage,See if it's an imbalanced dataset and apply oversampling,Try a different evaluation metric,,Keep adding more training data,,,,Apply feature engineering techniques,"Bagging creates multiple datasets by sampling with replacement, while boosting adds models sequentially and adjusts their weights based on the error of the previous models",,,,All of the above,,"When creating a new nn class in PyTorch, we need to define both forward and backward methods",grad * sigmoid_output * (1 - sigmoid_output),https://tiiuae-my.sharepoint.com/:u:/g/personal/paola_ardon_tii_ae/Ea46a16ESQNHgXCUgzZfS7MBXYILlJnahQlmBbEgjWJbIw?e=f6Ca7K,7,Adding noise,,Flipping,Random insertion,Scaling,,,"Autonomous driving and robotics to detect objects such as cars, people, or houses",e-Commerce product categorization,Household object detection for augmented reality applications,Anomaly detection in medical diagnostic imaging,,"Irregular objects such as buildings, vehicles, or trees for autonomous vehicles",,,Back translation,Synonym replacement,Random deletion,Cropping,,,,All of the above,binning,moving average smoothing,,,https://tiiuae-my.sharepoint.com/:u:/g/personal/paola_ardon_tii_ae/EYphWNn21FdHmuilrr7a9sIBdWMV__O_k2Y4RltxZyXQOA?e=3hrdsk,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/b6942c75-c56e-4454-ae13-4d163074b7dc.png,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,7,MobileNet,LeNet,,ViT,VGG,,,FALSE,"1. Import the VGG19 model from the torchvision library and load the pretrained weights. This pretrained model is ideally already been trained on a large dataset, such as ImageNet, and has learned to extract meaningful features.       2. Create a new model that takes the pretrained VGG19 as its base but with some modifications. Freezing the layers to use as feature extractors (typically the convolutional layers) and discard the fully connected layers.    3. In the forward() method, pass the input images through the modified VGG19 model to extract features.    4. Adding a classification head on top of the extracted features.    5. Training the custom classifier on top of the extracted features while keeping the VGG19 layers frozen. You can use the features extracted by VGG19 as input to the classifier.    6. Evaluate by passing new images through the VGG19FE model to extract features and then through the classifier for classification.",Using the Conv4_3 Layer:  Layer Name: conv4_3  Size of Feature Vector: 512    Using the FC6 Layer:  Layer Name: fc6  Size of Feature Vector: 4096    Using the FC7 Layer:  Layer Name: fc7  Size of Feature Vector: 4096,"By training a classification model on top of these features. These are the highlevel steps:   Feature Extraction, Data Splitting, Data Preprocessing, Classification Model, Model Training, Hyperparameter Tuning, Model Evaluation, Testing, Post-Processing, Visualization   ","True, original_model.features, 4096, self.classifier(f)","Different losses can be used during the training process to create an output image that combines the content of one image (the content image) with the artistic style of another image (the style image). Such as: content loss; style loss; total variation loss.    Regarding the use of activations in the training process, they can be content and style losses that rely on the activations (feature maps) of a pre-trained CNN to create an output image that merges the content and style of two input images. The training process optimizes these losses to generate visually appealing stylized images.",convolution of f and g functions. Where g(t) is the second function to be convoluted.,Erosion,Dilation,Opening,Closing,,,,,,,All of the above,
1.14426E+11,427913904,10/02/2023 05:22:04 PM,10/02/2023 05:31:23 PM,83.110.1.129,,,,,Enrico Natalizio,enrico.natalizio@tii.ae,Autonomous Robotics Research Center,Chief Researcher,Yes,Yes,Yes,"ChatGPT, MidJourney, Perplexity","Supporting with well written descriptions of r&d topics, providing state of the art for specific subjects, new images and research papers analysis",Prepare a comparative state of the art for positioning a new research contribution into the current body of literature,To have a solid understanding of the concepts and trends in generative AI,,,To gain technical experience with machine learning and AI,,,,Gain some exposure and jargon in the generative AI field,,No,I do not know Python,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14426E+11,427913904,10/02/2023 03:19:58 PM,10/02/2023 03:54:31 PM,2.50.149.139,,,,,kaoutar laachiri,Kaoutar.Laachiri@tii.ae,DERC,intern,Yes,Yes,No,chatgpt,correct code,-,,,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",,,,Yes,1-2 years,8,"del student[""marks""]","student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,8,https://tiiuae-my.sharepoint.com/:u:/g/personal/kaoutar_laachiri_tii_ae/EbEdTdbN-JFKiW2VE-vV17gB5uXZIg8M2bGD21Qd6MdszQ?e=GhgjAQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14426E+11,427913904,10/02/2023 09:21:02 AM,10/02/2023 03:36:02 PM,83.110.1.129,,,,,Prabakaran Balasubramanian,p.balasubramanian@tii.ae,AMRC,Senior Researcher,Yes,Yes,No,"ChatGPT, mid journey, slidesAI, Bard, etc.,","They can an excellent assistant for my research activities. Also, they can help increase my productivity by automating many data-collecting and extraction jobs. ","There can a mechanical engineering AI assistant which can be specifically trained for health monitoring of critical structures using the sensor data such as vibration, sound pressure and camera inputs. ",To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,Yes,2+ years,8,"del student[""marks""]","student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,8,"text = 'Hello! We are super super super excited to have you join the program to learn about generative AI amongst other things.'    ### Your Code Below  import string    def remove_punctuation(input_string):      translator = str.maketrans('', '', string.punctuation)      return input_string.translate(translator)  text = text.lower()  text_stripped = remove_punctuation(text)  text_stripped = text_stripped.split(' ')  text_dict = {}  for word in text_stripped:    if word not in text_dict:      text_dict[word] = 1    else:      text_dict[word] += 1   print(text_dict)",2xy + y,Gini,Entropy,Sum of squared error (variance),,,,Green,Cross-entropy loss,Huber loss,,,,F-1 score,,,Precision & Recall,,,,Look for data leakage,See if it's an imbalanced dataset and apply oversampling,Try a different evaluation metric,,,Try different algorithms,Combine different models,,Apply feature engineering techniques,I don't know,PyTorch uses zero_grad() to sets all the gradients to zero for all the parameters in the model.,,,,,"When creating a new nn class in PyTorch, backward method is not necessary since PyTorch does auto differentiation via autograd",i dont know.,"#%%  import pandas as pd  import numpy as np  import matplotlib.pyplot as plt  %matplotlib inline    # Download the test dataset  from imblearn.datasets import fetch_datasets    data = fetch_datasets()['wine_quality']    # Separate data into features [X] and lable [y]  data['target']  X = data['data']  y = data['target']    #%%  from sklearn.model_selection import train_test_split  from sklearn import preprocessing  from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier  from sklearn.metrics import mean_squared_error, r2_score, accuracy_score  import seaborn as sns      # %%  # split the data into Training , Validation and Testing datasets  X_train, X_test, y_train, y_test = train_test_split(X, y,                                                       test_size=0.2,                                                       random_state=123,                                                       stratify=y)  X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)    # %% Normalize the X dataset  scaler = preprocessing.StandardScaler().fit(X_train)  X_train_scaled = scaler.transform(X_train)  X_val_scaled = scaler.transform(X_val)  X_test_scaled = scaler.transform(X_test)  #%%  df = pd.DataFrame(scaler.transform(X))  df['quality'] = y  # chekcing the histograms  # Histograms  df.hist(bins=10,figsize=(6, 5))  plt.show()  # Density  df.plot(kind='density', subplots=True, layout=(4,3), sharex=False)  plt.show()  #%% Checking the correlation between features  colum_names = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']  # Correlation matrix  correlations = df.corr()  # Plot figsize  fig, ax = plt.subplots(figsize=(10, 10))  # Generate Color Map  colormap = sns.diverging_palette(220, 10, as_cmap=True)  # Generate Heat Map, allow annotations and place floats in map  sns.heatmap(correlations, cmap=colormap, annot=True, fmt="".2f"")  ax.set_xticklabels(      colum_names,      rotation=45,      horizontalalignment='right'  )  ax.set_yticklabels(colum_names);  plt.show()    #%% checking the scatter plot matrix    # Scatterplot Matrix  sm = pd.plotting.scatter_matrix(df, figsize=(6, 6), diagonal='kde')  #Change label rotation  [s.xaxis.label.set_rotation(40) for s in sm.reshape(-1)]  [s.yaxis.label.set_rotation(0) for s in sm.reshape(-1)]  #May need to offset label when rotating to prevent overlap of figure  [s.get_yaxis().set_label_coords(-0.6,0.5) for s in sm.reshape(-1)]  #Hide all ticks  [s.set_xticks(()) for s in sm.reshape(-1)]  [s.set_yticks(()) for s in sm.reshape(-1)]  plt.show()     # %%  # adjust the imbalance of dataset with oversampling  from imblearn.over_sampling import RandomOverSampler  oversample = RandomOverSampler(sampling_strategy='minority')  X_over, y_over = oversample.fit_resample(X, y)  # split the data into Training , Validation and Testing datasets  X_train, X_test, y_train, y_test = train_test_split(X_over, y_over,                                                       test_size=0.2,                                                       random_state=123,                                                       stratify=y_over)  X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)  # Normalize the X dataset  scaler = preprocessing.StandardScaler().fit(X_train)  X_train_scaled = scaler.transform(X_train)  X_val_scaled = scaler.transform(X_val)  X_test_scaled = scaler.transform(X_test)  # %% train the Random Forest Classfier    clf = RandomForestClassifier(max_depth=9, max_features='log2', max_leaf_nodes=9,                               n_estimators=150)  clf.fit(X_train, y_train)     pred = clf.predict(X_test)  print( r2_score(y_test, pred))  print( mean_squared_error(y_test, pred))  print(accuracy_score(y_test, pred))    #%% fine tune the hyper-parameters with grid search or select the best hyperparameters  from sklearn.model_selection import GridSearchCV, RandomizedSearchCV  param_grid = {      'n_estimators': [25, 50, 100, 150],      'max_features': ['sqrt', 'log2', None],      'max_depth': [3, 6, 9],      'max_leaf_nodes': [3, 6, 9],  }  grid_search = GridSearchCV(RandomForestClassifier(),                             param_grid=param_grid)  grid_search.fit(X_train, y_train)  print(grid_search.best_estimator_)  # %% best classifer performance  from sklearn.metrics import classification_report  print(classification_report(pred, y_test))    #%% features importances  importance=clf.feature_importances_    std = np.std([tree.feature_importances_ for tree in clf.estimators_],               axis=0)  indices = np.argsort(importance)  colum_names = indices  # Plot the feature importances of the forest  plt.figure()  plt.title(""Feature importances"")  plt.barh(range(X.shape[1]), importance[indices],         color=""b"",  align=""center"")    plt.yticks(range(X.shape[1]), colum_names)  plt.ylim([0, X.shape[1]])  plt.show()    # %%  ",7,,,,,,All of the above,,,,,,,,All of the mentioned,,Back translation,Synonym replacement,,,Text generation,,,All of the above,binning,moving average smoothing,,,"import requests   from bs4 import BeautifulSoup as bs   # load the projectpro webpage content   r = requests.get('https://en.wikipedia.org/wiki/Generative_artificial_intelligence')     # convert to beautiful soup   soup = bs(r.content)   # scrapping the links:-   # For all the 'href' links   for item in soup.findAll(""h2""):      print(""Text: {}, Image: {}"".format(          item.text, item.find_next(""img"").get(""src"")))","import cv2    img = cv2.imread(""C:\\Users\\P.Balasubramanian\\OneDrive - Technology Innovation Institute\\Documents\\b6942c75-c56e-4454-ae13-4d163074b7dc.png"")  print(type(img))  #     print(img.shape)  # (225, 400, 3)  img_flip_ud = cv2.flip(img, 0)  img_rotate_90_clockwise = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)  # Create the sharpening kernel  kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])      # Sharpen the image  sharpened_image = cv2.filter2D(img, -1, kernel)",3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,5,MobileNet,LeNet,,ViT,VGG,,,FALSE,"The image as a matrix can be sent through a series of convolution and pooling layers to obtain as much as low-level to high-level features. Once such features are extracted they can be sent though fully connected layers to arrive at the number of classes you need to classify the images. We can select the activation function based on our specific requirements. Also, we can choose to randomly disconnect certain portions to make the model get trained generally. The final layer will act as the probability of a certain image belonging to a certain class.","The pre-trained model can use the convolution layer features as they would have the basic recognition capability for classifying the images. AS they would be trained with lots of data, the basic features will be good enough to specifically tune for a specific purpose. The fully connected layers cannot be used for pre-trained feature extraction purposes, in my opinion. ",The features can then be connected through a series of fully connected layers each with reducing number of nodes to finally come at the layer with enough nodes as the number of classes you want the images to be classified as.,"True, original_model.features, 4096, self.classifier(f)",Huber loss is being used. ,Convolution function. The g(t) represents the kernel function. ,Erosion,Dilation,,,,,,,,,All of the above,
1.14426E+11,427913904,10/02/2023 02:39:51 PM,10/02/2023 03:13:55 PM,31.215.222.80,,,,,Charles Vanwynsberghe,charles.vanwynsberghe@tii.ae,AIDRC,Senior Researcher,Yes,Yes,Yes,"chatgpt, dall-e",yes,no,,To learn how to use prompting to make myself more efficient at work,,,,,,Gain some exposure and jargon in the generative AI field,,Yes,2+ years,7,,,"student.remove(""marks"")",,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,2,"text = 'Hello! We are super excited to have you join the program to learn about generative AI amongst other things.'  print(text)    ### Your Code Below  import string  def word_count(text):      # Remove punctuation from the text      translator = str.maketrans('', '', string.punctuation)      stripped_text = text.translate(translator)            # Convert the text to lowercase and split it into words      words = stripped_text.lower().split()            # Create a dictionary to store word counts      word_dict = {}            for word in words:          if word in word_dict:              word_dict[word] += 1          else:              word_dict[word] = 1                    return word_dict    print(word_count(text))",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14426E+11,427913904,10/02/2023 02:56:55 PM,10/02/2023 03:02:42 PM,83.110.1.129,,,,,Johanna Toivanen,johanna.toivanen@tii.ae,SSRC,Lead Security Engineer (/Team lead),Yes,Yes,No,ChatGPT,"yes, I use it as and assistant for daily work, related to any generic topics like job profile, or some generic technical questions",could it be used for security threat analysis of some kind? Also autonomous purposes it is already used in the team.,,,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,No,1-3 months,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14426E+11,427913904,10/02/2023 07:48:45 AM,10/02/2023 02:16:47 PM,83.110.1.129,,,,,Sara Khalifa Alseiari,sara.alseiari@tii.ae,Propulsion and Space Research Center,Associate Researcher,Yes,Yes,Yes,I have just tried using ChatGPT.,It could be helpful in generating good references.,"I still have not heard of any potential AI use cases, but probably in the future we will.",To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,Gain some exposure and jargon in the generative AI field,,Yes,1-3 months,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/28/2023 03:33:50 PM,10/02/2023 01:42:39 PM,83.110.1.129,,,,,Amanda Pieyre,amanda.pieyre@tii.ae,Propulsion and Space,Senior researcher Engine performance ,Yes,Yes,Yes,"Chat GPT, DALLE, regression models in python ","Writing emails, helping with presentations, redaction ",Writing,To have a solid understanding of the concepts and trends in generative AI,,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,,,,,Yes,2+ years,7,,"student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,def is_palindrome(s): return s == s[::-1],,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],reverse the table order ascending=True,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,6,"text = 'Hello! We are super excited to have you join the program to learn about generative AI amongst other things.'  print(text)    ### Your Code Below      import string  data = ""Hello! We are super excited to have you join the program to learn about generative AI amongst other things!""  def countWord(input_string):      d = {}      splited_input = input_string.split()      for word in splited_input:          word = word.translate(str.maketrans('', '', string.punctuation))          try:              d[word] += 1          except:              d[word] = 1      return d  dict = countWord(text)",2xy + y,Gini,,Sum of squared error (variance),,,,Green,Cross-entropy loss,,Mean squared error,,,F-1 score,,,Precision & Recall,,,,,,,I don't know,Keep adding more training data,Try different algorithms,,,,"Bagging creates multiple datasets by sampling with replacement, while boosting adds models sequentially and adjusts their weights based on the error of the previous models",PyTorch uses zero_grad() to sets all the gradients to zero for all the parameters in the model.,,,,,"When creating a new nn class in PyTorch, backward method is not necessary since PyTorch does auto differentiation via autograd",s = 1/(1+np.exp(-x))  grad_input = grad * s * (1 - s),test,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/28/2023 03:42:04 PM,10/02/2023 12:45:59 PM,94.57.160.190,,,,,Jennifer Simonjan,jennifer.simonjan@tii.ae,Autonomous Robotics Research Center,Senior Researcher,Yes,Yes,Yes,"ChatGPT, Dall-E, PiktID, Canva, MidJourney","I think AI tools like LLMs can advance also UAV applications, as UAVs are often used for surveillance or visual inspection, they provide a lot of image streams. AI tools can help to classify the scene and LLMs can help to decide what to do with the information or how to act upon it. ",Mentioned in the box above.,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,,,Gain some exposure and jargon in the generative AI field,,Yes,3 months to 1 year,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14426E+11,427913904,10/02/2023 10:32:16 AM,10/02/2023 12:01:18 PM,91.115.131.177,,,,,Aymen Fakhreddine,aymen.fakhreddine@tii.ae,AIDRC,Senior researcher,Yes,Yes,Yes,ChatGPT,Literature review,not specifically,To have a solid understanding of the concepts and trends in generative AI,,,To gain technical experience with machine learning and AI,,,,,,Yes,3 months to 1 year,5,,,,I don't' know,10 Chair 10 Table 20 Chair 20 Table,I don't know,,,,I don't know,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,4,n/a,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14426E+11,427913904,10/02/2023 11:50:20 AM,10/02/2023 11:58:22 AM,2.50.149.139,,,,,Evgeny Lonshakov,evgeny.lonshakov@tii.ae,DERC,Senior researcher ,Yes,Yes,Yes,ChatGPT,"Preparing the post, preparing scripts for Python, information search.",Preparing scripts for Python to process information and automatize data acquisition in lab. ,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,Yes,1-2 years,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14426E+11,427913904,10/02/2023 11:01:31 AM,10/02/2023 11:29:19 AM,83.110.1.129,,,,,Sebastien,sebastien@ssrc.tii.ae,SSRC,Director,Yes,Yes,Yes,OpenAI Dall.E (similar to MidJourney),"Having played quite a bit with https://en.wikipedia.org/wiki/ELIZA while growing up I find ChatGPT mind-blowing in comparison but I have yet to find a use in my job specifically: I see people using ChatGPT as a kind of Google and/or StackOverflow but with the same (worse?) risk of getting bad answers, like if you asked ChatGPT (version 3, probably fixed in version 4 but still) what is bigger between a chicken egg and a cow egg it would answer obviously the cow egg, which is funny because it's obviously wrong but in my line of work the devil is in the details so I don't feel like risking subtle hallucinations.","Not in my work per se but I compete in password cracking contests such as DEF CON Crack Me If You Can and I have been meaning to look into AI to get an advantage, or at least not lose out to teams who might be having the same idea.",To have a solid understanding of the concepts and trends in generative AI,,,To gain technical experience with machine learning and AI,,,,,Specifics about TII's Falcon class: using it with a single GPU such as the AMD Instinct MI300X etc,Yes,2+ years,5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14426E+11,427913904,10/02/2023 10:45:42 AM,10/02/2023 10:57:02 AM,31.215.128.146,,,,,chiara marcolla,chiara.marcolla@tii.ae,CRC,Lead Cryptographer,Yes,Yes,I do not understand what a prompt is,"In general, I only ask to check my English or improve my sentences. Or to check/modify some latex tabular",Save a lot of time if I have to write something very formal/ or with better English. (I know that it can do much more..),"Besides improving my English, I guess that it can also help with some research tasks (like curve fitting/ML problems)",To have a solid understanding of the concepts and trends in generative AI,,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,,,,,No,3 months to 1 year,5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14426E+11,427913904,10/02/2023 10:18:41 AM,10/02/2023 10:23:10 AM,2.50.149.139,,,,,Hend alketbi,Hend.alketbi@tii.ae,Directed energy research centre / x pulsed power,Senior electrical engineer,No,No,No,N/a,N/a,N/a,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,,,,,,No,I do not know Python,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14426E+11,427913904,10/02/2023 09:49:35 AM,10/02/2023 09:54:12 AM,2.50.149.139,,,,,Hajer Al Mahri,hajer.almahri@tii.ae,DERC,Senior Electrical Engineer,Yes,Yes,Yes,ChatGPT,"Communication, surveys, summarize information ","Writing emails, summarizing information ",To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,Gain some exposure and jargon in the generative AI field,,Yes,1-2 years,5,"del student[""marks""]",,,,10 Chair 20 Table,PYn PYnat ive PYnativ vitanYP,,,,I don't know,,reverse the table order ascending=True,,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/a8a2caac-d234-4be3-96e6-ab97d88fb9cb.png,,,I don't know,1,N/A,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/28/2023 04:11:13 PM,10/02/2023 09:52:32 AM,217.164.168.142,,,,,Humaid Ibrahim,Humaid.Ibrahim@tii.com,Propulsion and Space Research Center,Associate Researcher,Yes,Yes,Yes,"ChatGPT, Dall-E","Makes life easier in multiple ways. Can summarize long paragraphs, rewrite wordy sentences to more concise sentences.  ",Can use PPT generators to make a template for whatever topic I choose. Can summarize reports for myself to read faster.,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,Yes,2+ years,8,"del student[""marks""]","student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,9,"# I would use nltk but I don't know if I can use external libraries.  # So I hardcoded the filter words.  input=""Hello! We are super excited to have you join the program to learn about generative AI amongst other things!""    words = input.split()    clean_words = []  for word in words:      clean_word = ''.join(e for e in word.lower() if e.isalnum())      clean_words.append(clean_word)    filter_ = [""we"", ""are"", ""to"", ""have"", ""you"", ""the"", ""to"", ""about"", ""other""]  filtered_words = list(filter(lambda w: not w in filter_, clean_words))    counts = dict()  for i in filtered_words:    counts[i] = counts.get(i, 0) + 1    print(counts)  ",2xy + y,Gini,Entropy,,,,,Green,Cross-entropy loss,,,,,F-1 score,,,Precision & Recall,,,,Look for data leakage,,,,Keep adding more training data,Try different algorithms,Combine different models,Try stochastic gradient descent instead of batch gradient descent,Apply feature engineering techniques,I don't know,PyTorch uses zero_grad() to sets all the gradients to zero for all the parameters in the model.,It ensures that the gradients are fresh and ready to be computed for the current iteration.,,,,nn.Module is the base class for all neural network modules in PyTorch,grad*(1-grad),"import pandas as pd  import numpy as np  import matplotlib.pyplot as plt  from xgboost import XGBClassifier  from sklearn.model_selection import GridSearchCV  from sklearn.model_selection import train_test_split  from sklearn.metrics import classification_report  from sklearn.preprocessing import StandardScaler  from imblearn.over_sampling import SMOTE  from collections import Counter    # %matplotlib inline    # Download the test dataset  from imblearn.datasets import fetch_datasets    data = fetch_datasets()['wine_quality']    # Separate data into features [X] and label [y]  X = pd.DataFrame(data['data'])  y = pd.DataFrame(data['target'], columns=[""target""])    # Data visualizaton  fig, ax = plt.subplots(len(X.columns)+1, 1, figsize=(7, 9))  i=0  for feature in X.columns:      ax[i].plot(X[feature], label='Feature No.' + str(feature))      ax[i].legend(loc='upper left')      plt.setp(ax[i].get_xticklabels(), visible=False)      i+=1  ax[-1].plot(y, label=""Target"")  ax[-1].legend(loc='upper left')  plt.subplots_adjust(hspace=.0)  plt.show()    print(""Original Distribution of target variable"", Counter(y[""target""]))  # Upon investigation, the -1 class is 4715, +1 class is 183.    # Convert -1 to 0 in target dataset  y[y[""target""] == -1] = 0    # Holdout set  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0, stratify=y)  print(""Train target distribution"", Counter(y_train[""target""]), ""\nTest target distribution"", Counter(y_test[""target""]))    # SMOTE can be used to equalize the classes  oversample = SMOTE()  X_train, y_train = oversample.fit_resample(X_train, y_train)  print(""Train target distribution after upsampling"", Counter(y_train[""target""]))    # Train Validation split  # X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)      # Data Scaling  scaler = StandardScaler()  scaler.fit(X_train) # It is fit only to the train set to ensure no data leakage    X_train[X_train.columns] = scaler.transform(X_train[X_train.columns])  X_test[X_test.columns] = scaler.transform(X_test[X_test.columns])    # Below is the tuning code.  # Commented out so you don't have to re-run the training process.  # model = XGBClassifier(objective='binary:logistic')  # params = {  #         'min_child_weight': [1, 5, 10],  #         'gamma': [0.5, 1, 1.5, 2, 5],  #         'subsample': [0.6, 0.8, 1.0],  #         'colsample_bytree': [0.6, 0.8, 1.0],  #         'max_depth': [3, 4, 5]  #         }  #  # grid = GridSearchCV(model, param_grid=params, n_jobs=-1, verbose=2, cv=3, scoring='accuracy')  # grid.fit(X_train, y_train)  # sorted(grid.cv_results_.keys())  # print('\n All results:')  # print(grid.cv_results_)  # print('\n Best estimator:')  # print(grid.best_estimator_)  # print('\n Best hyperparameters:')  # print(grid.best_params_)    # Best results were:  # {'colsample_bytree': 0.8, 'gamma': 0.5, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 1.0}      model = XGBClassifier(objective='binary:logistic', colsample_bytree=0.8,                        gamma=0.5, max_depth=5, min_child_weight=1, subsample=1)    model.fit(X_train, y_train)  preds = pd.DataFrame(model.predict(X_test), columns=[""target""])  preds[preds[""target""] == 0] = -1  y_test[y_test[""target""] == 0] = -1    print(classification_report(y_test, preds[""target""]))    # Precision is the number of positives identified are actually positive.  # Recall measures how many of the positive cases are correctly identified as positive  # F1 score is a combination of the precision and recall    # Not displayed here is when I comment out the SMOTE code,  # the f1-score of the small class (1) decreases to 0.29 but overall accuracy increases to 96%  # With SMOTE, f1 score of class (1) is 0.33, and overall accuracy is 95%  ",8,Adding noise,,,,Scaling,,,"Autonomous driving and robotics to detect objects such as cars, people, or houses",,Household object detection for augmented reality applications,Anomaly detection in medical diagnostic imaging,,"Irregular objects such as buildings, vehicles, or trees for autonomous vehicles",,,,Synonym replacement,,,,,Scaling,Part-of-speech tagging (POS),binning,moving average smoothing,,,"import requests  from bs4 import BeautifulSoup    URL = ""https://en.wikipedia.org/wiki/Generative_artificial_intelligence""  page = requests.get(URL)  bs = BeautifulSoup(page.content, ""html.parser"")  links = bs.find_all('div', {'class': 'image'})  img = bs.findAll('img')  x = 0  caption = ''  for i in img:      src = i.get('src')      try:          title = i.find_next(""a"")[""title""]      except:          title = ''        print(src, title)  ","import cv2  import requests  import numpy as np    #Dog URL  url = ""https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Example-dog-on-the-internet.png/220px-Example-dog-on-the-internet.png""    with open('dog.png', 'wb') as f:      f.write(requests.get(url).content)    img = cv2.imread(""dog.png"", 1)  cv2.imshow('dog', img)    flip_img = cv2.flip(img, 1)  cv2.imshow('flipped dog', flip_img)    rotate_img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)  cv2.imshow('rotated dog', rotate_img)    kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])  sharp_img = cv2.filter2D(img, -1, kernel)  cv2.imshow('sharpened dog', sharp_img)    cv2.waitKey(0)  ",4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14426E+11,427913904,10/02/2023 09:32:17 AM,10/02/2023 09:40:06 AM,2.50.149.139,,,,,Mohamed AlYousef,mohamed.alyousef@tii.ae,DERC,Lead Researcher,Yes,Yes,I do not understand what a prompt is,ChatGPT,Not sure they can help with my job,Not particularly,To have a solid understanding of the concepts and trends in generative AI,,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,,,,Gain some exposure and jargon in the generative AI field,,No,I do not know Python,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14426E+11,427913904,10/02/2023 09:28:55 AM,10/02/2023 09:38:54 AM,31.215.56.105,,,,,Malavika Balakrishnan,malavika.balakrishnan@tii.ae,SSRC,Senior associate -  Software Engineer,Yes,Yes,Yes,"ChatGPT,  OpenAI",ChatGPT helps us to get the right answer to questions whose answers are not very apt on Google. They also help us to generate job descriptions for new hires. Almost everything can be easily found on ChatGPT.,"In devops, Generative AI like ChatGPT can be used to find answers to questions related to Coverity or blackduck or any of the devops tools whose answers are generally tough to find on Google. Also, ChatGPT gives the exact snippet to the questions which we ask. ",To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,Gain some exposure and jargon in the generative AI field,,Yes,2+ years,9,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/29/2023 02:18:55 PM,10/02/2023 09:03:17 AM,176.205.192.95,,,,,Ridhi Jain,ridhi.jain@tii.ae,DSRC,Researcher,Yes,Yes,Yes,"AgentGPT, ChatGPT, FalconLLM","By assisting faster research and development. Also, these tools themselves are subjects for exploration in my research.",Yes.  1. Generating secure code: Learning how prompts can affect the quality of generated code.  2. Coupling these tools with verification tools to detect bugs and vulnerabilities.,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,,,,,,Yes,2+ years,7,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14426E+11,427913904,10/02/2023 08:53:12 AM,10/02/2023 08:58:44 AM,83.110.1.129,,,,,Michael Baddeley,Michael.Baddeley@tii.ae,SSRC,Principal Researcher,Yes,Yes,Yes,"ChatGPT, Copilot","They are extremely useful as assistants for pair programming, evaluating code completeness / for errors, and analyzing datasets. Moreover they can assist with how to present information to new audiences, and helping with written tasks such as datasheets.",An interesting one I found recently was use in the analysis of wireguard logs to inspect network traffic. It was able to highlight suspicious data packets in a matter of seconds. ,,,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,,To implement generative AI solutions in the lab or production environment,,,Yes,2+ years,9,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14426E+11,427913904,10/02/2023 08:44:22 AM,10/02/2023 08:47:38 AM,83.110.1.129,,,,,Kapil Krishnan,kapil.krishnan@tii.ae,AMRC,Researcher,Yes,No,No,None,Not sure yet,Understanding the prospects of new materials and optimization of processes,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,Gain some exposure and jargon in the generative AI field,,Yes,3 months to 1 year,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14426E+11,427913904,10/02/2023 08:13:01 AM,10/02/2023 08:17:09 AM,2.50.149.139,,,,,Denis Philippovskiy,Denis.Philippovskiy@tii.ae,DERC,Lead Laser Researcher,Yes,Yes,I do not understand what a prompt is,-,"Meeting notes and summary, to-do lists, scientific articles abstracts, e-mail compositions",-,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,,To implement generative AI solutions in the lab or production environment,,,No,I do not know Python,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14426E+11,427913904,10/02/2023 08:11:19 AM,10/02/2023 08:15:06 AM,2.50.151.47,,,,,Garry Heaven,garry.heaven@tii.ae,BRC,Systems Administrator & Database Senior Manager ,Yes,Yes,No,ChatGPT,Assistance with generalized IT research. Potential to assist in technology selections. Ability to assist with boiler plate code generation.,Nothing specific currently,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,Yes,3 months to 1 year,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/28/2023 09:53:15 PM,10/02/2023 08:10:26 AM,81.243.216.89,,,,,Tarcisio Marinelli Pereira Silva,tarcisio.silva@tii.ae,Advanced Materials Research Center,Researcher,No,No,No,I have never used AI tools yet,"AI is a powerful tool and can bring many benefits to research, such as automatizing processes, optimizing problems, and much more. ","AI can be used to tune and optimize active vibration controllers, which is the research topic of my work.",To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,,To implement generative AI solutions in the lab or production environment,Gain some exposure and jargon in the generative AI field,,Yes,1-3 months,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14426E+11,427913904,10/02/2023 07:45:23 AM,10/02/2023 08:01:30 AM,83.110.1.129,,,,,Renan,renan.santos@tii.ae,Propulsion and Space Research Center,Researcher,Yes,Yes,No,ChatGPT,generating basic codes and answering basic questions ,Yes,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,,,,To implement generative AI solutions in the lab or production environment,,,Yes,3 months to 1 year,6,,"student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,,,,I don't know,,,,I don't know,Encapsulation,1,N/A,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14426E+11,427913904,10/02/2023 07:13:59 AM,10/02/2023 07:27:01 AM,2.50.149.139,,,,,Ali Al Ali,ali.alali@tii.ae,DERC,Lab operation ,Yes,No,No,none ,"I don't think it can help me, all my task is technical service, operating the lab and maintain it.",none ,,,,To gain technical experience with machine learning and AI,,,To implement generative AI solutions in the lab or production environment,,,No,I do not know Python,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14426E+11,427913904,10/02/2023 07:18:48 AM,10/02/2023 07:23:32 AM,2.50.149.139,,,,,Abdulla AL Ali,abdulla.alali@tii.ae,DERC,Sinor design engineer,No,No,I do not understand what a prompt is,none,it will lay the groundwork for job ,start the design. ,To have a solid understanding of the concepts and trends in generative AI,,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,,"To learn how to build NLP, LLM, or Computer Vision models",,,,No,I do not know Python,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/28/2023 05:33:29 PM,10/01/2023 11:12:48 PM,31.215.94.220,,,,,Bogdan Chifor,bogdan.chifor@tii.ae,SSRC,Lead Researcher,Yes,Yes,No,N/A,Yes,Assisting in code writing,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,,,Gain some exposure and jargon in the generative AI field,,Yes,3 months to 1 year,6,"del student[""marks""]",,,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,def is_palindrome(s): return s == s[::-1],,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,,,,,,I don't know,Polymorphism,3,"def main():      phrase = input('Enter input:\n')        word_cnt = {}      for word in phrase.split("" ""):          if word_cnt.get(word) == None:              word_cnt[word] = 1          else:              word_cnt[word] = word_cnt[word] + 1        print(word_cnt)    if __name__ == ""__main__"":      main()  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14426E+11,427913904,10/01/2023 12:23:29 AM,10/01/2023 09:42:26 PM,12.177.129.82,,,,,Daniel,daniel.tortei@tii.ae,ARRC,Lead Researcher in Computer Vision,Yes,Yes,No,ChatGPT,conditional generation of  images,conditional generation of  daytime shadows in satellite-alike images ,To have a solid understanding of the concepts and trends in generative AI,,,,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,Gain some exposure and jargon in the generative AI field,,Yes,2+ years,7,"del student[""marks""]","student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Abstraction,9,"text = 'Hello! We are super excited to have you join the program to learn about generative AI amongst other things.'    punctuations = '''!()-[]{};:'""\,<>./?@#$%^&*_~'''  for char in text:    if char in punctuations:      text = text.replace(char, '')    text_list = text.split(' ')  text_dict = {}  for word in text_list:    text_dict[word] = text_list.count(word)    print(text_dict)    ",2xy + y,Gini,Entropy,,,,,Green,Cross-entropy loss,,,,,F-1 score,,,Precision & Recall,,,,,See if it's an imbalanced dataset and apply oversampling,,,Keep adding more training data,,,,Apply feature engineering techniques,"Bagging creates multiple datasets by sampling with replacement, while boosting adds models sequentially and adjusts their weights based on the error of the previous models",PyTorch uses zero_grad() to sets all the gradients to zero for all the parameters in the model.,,It's often called after running the backward() function during training.,,,nn.Module is the base class for all neural network modules in PyTorch,grad*self.forward(self.x)*(1-self.forward(self.x)),"import pandas as pd  import numpy as np  import matplotlib.pyplot as plt  from seaborn import sns  from sklearn.preprocessing import StandardScaler  from sklearn.metrics import classification_report, confusion_matrix, f1_score  from sklearn.model_selection import StratifiedShuffleSplit, RandomizedSearchCV  from sklearn.ensemble import RandomForestClassifier  from sklearn.utils import resample    %matplotlib inline      # Download the test dataset  from imblearn.datasets import fetch_datasets    # outlier cutoff  cutoff = 0.02 * len(tmp)  def remove_outliers(tmp, cutoff):      cols = list(tmp.columns)      cols.remove('label')      for col in cols:              counts, vals = np.histogram(tmp[col])          min_val = np.min(tmp[col]) - 1          max_val = np.max(tmp[col]) + 1          for val, count in zip(vals, counts):              if count < cutoff:                  min_val = val              else:                  break          for val, count in zip(vals[::-1], counts[::-1]):              if count < cutoff:                  max_val = val              else:                  break          print(f""{min_val} {max_val}"")          tmp = tmp[(tmp[col] > min_val) & (tmp[col] < max_val)]       return tmp    def print_stats(X, y, resultingRF):      print(confusion_matrix(y, resultingRF['classifier'].best_estimator_.predict(X),  labels = [-1, 1]))      print(classification_report(y, resultingRF['classifier'].best_estimator_.predict(X)))      print('variable importance in descending order: \n')      pd.DataFrame(resultingRF['classifier'].best_estimator_.feature_importances_, index=pd.DataFrame(X).columns).sort_values(by=0, ascending=False)    data = fetch_datasets()['wine_quality']    # Separate data into features [X] and lable [y]  data['target']  X = data['data']  y = data['target']    # Data exploration  print(data.keys())  print(np.histogram(y))  for dim in range(X.shape[1]):      print(np.histogram(X[:,dim]))    df = pd.DataFrame(X)  print(X.shape)  df.describe()  df[list(df.columns)].hist(bins=15, figsize=(15, 6), layout=((X.shape[1] // 4) + 1, 4))    sc = StandardScaler()  df = pd.DataFrame(sc.fit_transform(X), columns = df.columns)  tmp = pd.concat([df, pd.DataFrame(y, columns=['label'])], axis=1)  tmp = tmp.dropna()  sns.pairplot(tmp)    tmp = remove_outliers(tmp, cutoff)  sns.pairplot(tmp)  sns.heatmap(tmp.corr(), xticklabels=tmp.columns, yticklabels=tmp.columns)      # Training  y = np.array(tmp['label'])  train_labels = list(tmp.columns)  train_labels.remove('label')  X = np.array(tmp[train_labels])    # stratified k-fold train/validate split generator  k_fold = 5  train_idx = []  val_idx = []  stratgen = StratifiedShuffleSplit(n_splits=k_fold, test_size=0.2, random_state=0)  for idx1, idx2 in stratgen.split(np.zeros(y.shape), y):      train_idx.append(idx1)      val_idx.append(idx2)    # Parameters for randomized grid search  n_estimators = np.linspace(100, 1000, int((1000-100)/200) + 1, dtype=int)  max_features = ['auto', 'sqrt']  max_depth = [1, 2, 5, 10, 20, 50, 75, 100]  min_samples_split = [2, 5, 10, 15, 20]  min_samples_leaf = [1, 2, 3, 4]  bootstrap = [True, False]  criterion=['gini', 'entropy']  random_grid = {'n_estimators': n_estimators,                 'max_depth': max_depth,                 'min_samples_split': min_samples_split,                 'min_samples_leaf': min_samples_leaf,                 'bootstrap': bootstrap,                 'criterion': criterion}    resultingRF = {'classifier': None, 'val_X': None, 'val_y': None}  best_score = 0  for i in range(k_fold):      # prepare fold data      trainFold_X = X[train_idx[i]]      trainFold_y = y[train_idx[i]]      valFold_X = X[val_idx[i]]      valFold_y = y[val_idx[i]]      # handle imbalance      trainFold_X_majority = trainFold_X[trainFold_y == -1]      trainFold_X_minority = trainFold_X[trainFold_y == 1]      trainFold_Y_majority = trainFold_y[trainFold_y == -1]      trainFold_X_minority_upsampled = resample(trainFold_X_minority,random_state=42,n_samples=trainFold_X_majority.shape[0],replace=True)      trainFold_X = np.concatenate((trainFold_X_majority, trainFold_X_minority_upsampled))      trainFold_y = np.concatenate((trainFold_Y_majority, -trainFold_Y_majority))      indices = [x for x in range(trainFold_y.shape[0])]      np.random.shuffle(indices)      trainFold_X = trainFold_X[indices]      trainFold_y = trainFold_y[indices]        rf_base = RandomForestClassifier()      rf_random = RandomizedSearchCV(estimator = rf_base,                                     param_distributions = random_grid,                                     n_iter = 30,                                      cv = k_fold,                                     verbose=2,                                     random_state=42,                                      n_jobs = 16,                                     refit=True)      rf_random.fit(trainFold_X, trainFold_y)      score = f1_score(valFold_y, rf_random.best_estimator_.predict(valFold_X), pos_label=1)      if score > best_score:          resultingRF['classifier'] = rf_random          resultingRF['val_X'] = valFold_X          resultingRF['val_y'] = valFold_y          best_score = score    # stats of the best model on holdout set   print_stats(resultingRF['val_X'], resultingRF['val_y'], resultingRF)  # stats of the best model on all data   print_stats(X, y, resultingRF)  ",5,Adding noise,,Flipping,,Scaling,,,"Autonomous driving and robotics to detect objects such as cars, people, or houses",e-Commerce product categorization,Household object detection for augmented reality applications,,,,,,,Synonym replacement,,,,Trasformer-based,,Part-of-speech tagging (POS),binning,moving average smoothing,,,"from bs4 import BeautifulSoup  import requests  import re    html_page = requests.get('https://en.wikipedia.org/wiki/Generative_artificial_intelligence')  soup = BeautifulSoup(html_page.content, 'html.parser')    soup = BeautifulSoup(html, 'html.parser')  links = soup.find_all('figure')    res = {}  for item in links:      if item.find('img') is not None:           src = 'https://' + item.find('img')['src']          tmp = item.find('figcaption')          cap = re.sub('<.*?>', '', str(tmp), flags=re.DOTALL)          res[src] = cap","import requests  import shutil  import cv2  import matplotlib.pyplot as plt  import numpy as np    url = ""https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Example-dog-on-the-internet.png/220px-Example-dog-on-the-internet.png""  file_name = './dog.png'    res2 = requests.get(url, stream = True)  if res2.status_code == 200:      with open(file_name,'wb') as f:          shutil.copyfileobj(res2.raw, f)      print('Image sucessfully Downloaded: ',file_name)  else:      print('Image Couldn\'t be retrieved')        img = cv2.imread('./dog.png')  plt.imshow(img)    # rotated  angle = 22  M = cv2.getRotationMatrix2D((img.shape[1]//2, img.shape[0]//2), angle, 1.0)  dst = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]))  plt.imshow(dst)    # flipped  dst = cv2.flip(img, 1)  plt.imshow(dst)    # sharpened  kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])  dst = cv2.filter2D(img, -1, kernel)  plt.imshow(dst)",1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9,MobileNet,LeNet,GAN,,VGG,,,FALSE,"convolution filters extract low level features in the first layers, such as vertical and horizontal edges. Strongest features are being pooled into next convolution block. As the the information is propagated through the network, features get convolved and pooled again and again resulting in feature maps, which are high level aggregated representations of lower level features.  High level features cover more spatial resolution than low level features. All elements of feature maps are combined (fully, exhaustively, i.e. each with each other) in a fully connected layer afterwards, by applying a linear dot product operation with a weights matrix. The results (""activations"") are summed up and a nonlinear activation function is applied on the output of the layer. The number of final fully connected layer's nodes equals the number of classes. The most activated node (softmax function output) is the predicted class.",1. features from conv4_3 layer - ?x?x512  2. features from fc6 layer -  1x4096  3. features from fc7 layer -  1x4096  ,"First, split the 4k images into a train/validation/test split. I do have the extracted features for each sample (4096 vector).  I need to fine tune the VGG19, i.e. to train the last fully connected layer with 1000 nodes by giving these extracted features as input.  Crossentropy loss will be calculated on softmax output during training/fine tuning.","True, original_model.features, 4096, self.classifier(f)","content loss and style loss.    the content image is the image to which we wish to transfer style.  the style image is the image from which we want to use the style.   we calculate activations of intermediary layers from both images by passing them through a pretrained network.  we define a content and a style loss.  the generated image is the image whose activations (at the same level) need to match activations from both style and content images, minimizing style and content losses. generated image is also passed through same pretrained network and only pixels of the generated image are updated while the weights in the network are being frozen.",convolution operation  g(t) represents the weighting function of f(tau) in convolution,Erosion,Dilation,Opening,Closing,Morphological Gradient,Top Hat,,Sampling is the process that determines the size of the image to be obtained,,Quantization is a process that determines the value of each pixel in the image,,
1.14426E+11,427913904,10/01/2023 09:17:22 PM,10/01/2023 09:22:15 PM,90.181.249.73,,,,,Vikram Kaushik,vikram.kaushik@tii.ae,AMRC,Senior Project Manager,Yes,Yes,No,ChatGPT,Cannot rely on the information generated by ChatGPT entirely right now as I tried to get references and the links were not matching.,Help in research.,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,,To implement generative AI solutions in the lab or production environment,Gain some exposure and jargon in the generative AI field,,Yes,3 months to 1 year,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14426E+11,427913904,10/01/2023 08:10:44 PM,10/01/2023 09:10:10 PM,31.215.72.67,,,,,Hicham Anouar,hicham.anouar@tii.ae,AIDRC,Lead Researcher,Yes,Yes,Yes,ChatGpt,they may give an initial sate of the art on a new research topic or idea. they may also help when learning new coding language or library (python/pytorch  for example) ,yes many possible use cases in wireless communications,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,Yes,1-3 months,5,,"student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,def is_palindrome(s): return s == s[::-1],,,,,,,I don't know,,,,I don't know,Inheritance,5,N/A,2xy + y,,Entropy,,,,,Green,Cross-entropy loss,,,,,,,,Precision & Recall,,,,,See if it's an imbalanced dataset and apply oversampling,,,Keep adding more training data,,,,Apply feature engineering techniques,I don't know,PyTorch uses zero_grad() to sets all the gradients to zero for all the parameters in the model.,It ensures that the gradients are fresh and ready to be computed for the current iteration.,,,,"When creating a new nn class in PyTorch, backward method is not necessary since PyTorch does auto differentiation via autograd",grad*d(sigma())/d(x),N/A,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14426E+11,427913904,10/01/2023 12:42:04 PM,10/01/2023 12:46:41 PM,12.177.129.82,,,,,Amina Almarri,Amina.Almarri@tii.ae,ARRC,Research ,Yes,Yes,I do not understand what a prompt is,ChatGPT,Easy learning ,Human Robots interaction ,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,Gain some exposure and jargon in the generative AI field,,Yes,1-2 years,8,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14426E+11,427913904,10/01/2023 08:48:15 AM,10/01/2023 09:45:37 AM,217.164.230.246,,,,,David Gerault,david.gerault@tii.ae,CRC,Senior Cryptanalyst,Yes,Yes,Yes,ChatGPT,"For basic use cases, they can help with bibliography, writing improvement, and generating visuals faster for academic presentations.","I work on the use of AI/ML for cryptanalysis; the main problematic is training a ML algorithm to distinguish between cryptographically generated data and random data (c.f., seminal paper here https://eprint.iacr.org/2019/037). In this line of work, the cryptographer choses inputs to the cryptographic function that will lead to patterns in the output that a ML algorithm can recognize.     At the moment the focus is on the distinguishing part, i.e., improving/finetuning the ML algorithm that distinguishes. A first use case for me is to improve the input selection part with generative AI, i.e., train a generator in parallel with the distinguisher, that will hopefully select inputs to the cryptographic functions that lead to more identifiable patterns in the output. Some challenges are the size of the search space (the outputs of the cryptographic function, between which we try to find relations, range from 32 to 512 bits), and the representation of inputs (usually represented bitwise to facilitate important operations such as XOR).",To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",,,,Yes,2+ years,7,"del student[""marks""]",,,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,def is_palindrome(s): return s == s[::-1],,,,adding .drop_duplicates() to employee['salary'],,,,,,,I don't know,Inheritance,7,"text = 'Hello! We are super excited to have you join the program to learn about generative AI amongst other things.'  print(text)    ### Your Code Below    counts = {}  punctuation = '''!()-[]{};:'""\,<>./?@#$%^&*_~'''  for word in text.lower().split():    tmp_word =''    for c in word:      if c not in punctuation:        tmp_word += c    if word not in counts:      counts[tmp_word] = 1    else:      counts[tmp_word] += 1        print(counts)  ",I don't Know,,,,,,I don't know,Green,Cross-entropy loss,,Mean squared error,,,F-1 score,,Mean squared error,Precision & Recall,,,,Look for data leakage,,,,,Try different algorithms,Combine different models,,Apply feature engineering techniques,I don't know,,,,,I don't know,I don't know,I don't know,import pandas as pd  import numpy as np  import matplotlib.pyplot as plt  %matplotlib inline    # Download the test dataset  from imblearn.datasets import fetch_datasets    data = fetch_datasets()['wine_quality']    # Separate data into features [X] and lable [y]  data['target']  X = data['data']  y = data['target'],2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/28/2023 04:16:34 PM,10/01/2023 09:40:34 AM,83.110.1.129,,,,,Himank Gupta,himank.gupta@tii.ae,ARRC,Research Engineer,Yes,Yes,Yes,"ChatGPT, preplexity, Bard, Bing",It can help to write some scripts which can automate the process,"Yes.  We can pass the potential threats as a prompt to the tool, and it can  generate the solution for the same.",To have a solid understanding of the concepts and trends in generative AI,,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,,,Gain some exposure and jargon in the generative AI field,,Yes,3 months to 1 year,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14425E+11,427913904,09/30/2023 04:48:56 PM,09/30/2023 05:36:06 PM,198.199.206.164,,,,,Ahmed AlKatheeri,ahmed.alkatheeri@tii.ae,ARRC,Engineer,Yes,Yes,Yes,Chatgpt. Dall-E. Consensus.,-generate presentations and videos that showcase what we've done.  -simplify the reading of scientific papers and reduce entry time to any new topic (with citations and references).  -tuning controllers faster.  -applying concepts from other fields into robotics.   -generate code that speeds up the process.  -identify features in images.   -understand a task and break it down into logical actions for a robot.,-Write a summary of scientific papers with citations (Related work section).  -Drones controllers sometimes get put into unstable situations due to environmental factors. It would be great if we have a controller on top that takes over in those situations and recovers the drone without damage. ,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,Gain some exposure and jargon in the generative AI field,Learn how to adjust an already available LLM model like gpt2 and Falcon to work on my application.,Yes,2+ years,7,"del student[""marks""]",,,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,,,,,,I don't know,Inheritance,4,"import string  text_without_punctuation = text.translate(str.maketrans('','', string.punctuation))  lower_case_text = text_without_punctuation.lower()  text_list = lower_case_text.split()  # create dictionary  final_dict = dict(zip(text_list, [1]*len(text_list)))  print(final_dict)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14425E+11,427913904,09/30/2023 04:32:15 PM,09/30/2023 04:50:01 PM,198.199.206.163,,,,,Ahmed AlKatheeri,Ahmed.alkatheeri@tii.ae,ARRC,Engineer,Yes,Yes,Yes,Chatgpt. Dall-E. Consensus.,-tuning controllers faster.   -applying concepts that are already applied in other fields into the robotics field.   -generate code that speeds up the process substantially.   -identify features in images.  -identify a mission and split it into logical tasks that the robot can follow.   -generate presentations and videos that can showcase what we've done in a nice and easy to follow way.  -Simplify the reading of scientific documents and summarize the development in a field. (Reduce entry time to any new topic and find all related work with references),Drones controllers sometimes get thrown into unstable situations because of the environment. We can directly apply AI to use the normal controller and switch whenever it gets into an unstable situation.  Write a summary of a bunch of scientific papers with citations (related works section),To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,Gain some exposure and jargon in the generative AI field,Learn how to adjust an already built LLM model like gpt2 or falcon to my application.,Yes,2+ years,8,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14425E+11,427913904,09/30/2023 03:08:40 PM,09/30/2023 03:12:38 PM,5.194.215.229,,,,,Papa,Leye,DERC,Lead Researcher,Yes,No,No,NA,NA,NA,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,,,,,Yes,3 months to 1 year,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14425E+11,427913904,09/30/2023 08:49:50 AM,09/30/2023 08:52:42 AM,217.164.167.84,,,,,Alice Pagnoux,Alice.Pagnoux@tii.ae,AI & Digital RC,Engineer,Yes,Yes,Yes,ChatGPT,"AI tools can help me daily for my programming tasks, generate codes that allow me to go faster and save time.",AI for code generation,To have a solid understanding of the concepts and trends in generative AI,,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",,,,Yes,2+ years,7,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/28/2023 03:23:11 PM,09/29/2023 02:01:12 PM,156.203.120.28,,,,,Test_g,Test_g,Test_g,Test_g,Yes,Yes,I do not understand what a prompt is,Test_g,Test_g,Test_g,,,To be self-sufficient with no-code AI tools for business,,,,,,,Yes,1-2 years,7,"del student[""marks""]",,"student.remove(""marks"")",,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,def is_palindrome_1(s): return s == s[::2],def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],reverse the table order ascending=True,adjust the referencing to be iloc[N],,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/a8a2caac-d234-4be3-96e6-ab97d88fb9cb.png,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/4b0a1e6b-c3dd-48f4-9437-0286177c6d83.png,,Polymorphism,7,N/A,2xy + y,Gini,Entropy,,,,,Green,,,,,I don't know,,,,,,I don't know,,,,,I don't know,,,,,Apply feature engineering techniques,"Bagging creates multiple datasets by sampling with replacement, while boosting adds models sequentially and adjusts their weights based on the error of the previous models",,,It's often called after running the backward() function during training.,,,"When creating a new nn class in PyTorch, we need to define both forward and backward methods",N/A,N/A,6,,,,,Scaling,,,,,,,Facial feature points for face detection,,,,,,Random deletion,,,,,Part-of-speech tagging (POS),,moving average smoothing,,,N/A,N/A,7,,Sentence Segmentation,,,,,GPT,,,,,,GPT-3 is an autoregressive model,,,,Deduplication,,,,,Is an extension of propositional logic,,"Given a sentence or larger chunk of text, determine which words (“mentions”)",,,,,,,Named entity recognition,,,,,"This pipeline requires several sentences, not just one.",TRUE,,A decoder model,,,,The sequence length and the hidden size,,,Splitting on whitespace and punctuation,,,,,The attention mechanism is good at handling long sequence input,,,,A list of IDs,The tokenizer and model should always be from the same checkpoint.,Find whether a sentence is grammatically correct or not.,"Some of the tokens in the input sentence are randomly masked and the labels are the original input tokens, shifted to the left.",,Answering questions about a document,Translating a text in Arabic into English,,,8,MobileNet,,,,,,,TRUE,N/A,N/A,N/A,"False, original_model.features, 512, self.classifier()",N/A,N/A,,Dilation,Opening,,,,,Sampling is the process that determines the size of the image to be obtained,,,,
1.14424E+11,427913904,09/29/2023 10:20:33 AM,09/29/2023 12:53:13 PM,92.99.196.160,,,,,Vipin Sharma,vipin.sharma@tii.ae,Autonomous Robotics Research Center,Robotics Engineer: UGV Perception,Yes,Yes,Yes,"ChatGPT, Dall-E","Yes, specially with debugging issues",#NAME?,To have a solid understanding of the concepts and trends in generative AI,,,To gain technical experience with machine learning and AI,,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,Yes,2+ years,7,"del student[""marks""]","student.pop(""marks"")","student.remove(""marks"")",,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,def is_palindrome(s): return s == s[::-1],,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,7,"def remove_punctuation(text):      punctuation = """"""!()-[]{};:'""\,<>./?@#$%^&*_~""""""      no_punct = """"      for char in text:          if char not in punctuation:              no_punct += char      return no_punct      def word_counter(sentence):      sentence_without_punctuation = remove_punctuation(sentence)      word_count = {}      for word_object in sentence_without_punctuation.split():          if word_object in word_count:              word_count[word_object] += 1          else:              word_count[word_object] = 1      return word_count      print(""Word Count:\n"", word_counter(text))",2xy + y,Gini,Entropy,,,,,Green,Cross-entropy loss,,,,,F-1 score,,,Precision & Recall,,,,Look for data leakage,See if it's an imbalanced dataset and apply oversampling,Try a different evaluation metric,,,,Combine different models,,Apply feature engineering techniques,I don't know,PyTorch uses zero_grad() to sets all the gradients to zero for all the parameters in the model.,It ensures that the gradients are fresh and ready to be computed for the current iteration.,,,,nn.Module is the base class for all neural network modules in PyTorch,grad_input = self.x * (1 - self.x) * grad,https://colab.research.google.com/drive/1HmZIVM3DsavmO381Ao3IY7QYm8Z3G_F7?usp=sharing,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,7,MobileNet,LeNet,,ViT,VGG,,,TRUE,"When using VGG19, or any CNN as a fixed feature extractor, the idea is to use the pre-trained convolution layers to extract features from the input image and these extracted features are used to train the classifier, which can be a set of fully connected layers or further convolution layers to get the desired output.    The idea is to use the knowledge learned by the CNN by training on a big dataset (say ImageNet) and using that knowledge to our task at hand. The knowledge acquired by the CNN for understanding things like edges, colors, etc. by getting trained on a big dataset would remain more or less the same and can be reused for training on a different dataset, with relatively less number of images.    If the dataset the model is being re-trained on is not large, we can avoid back-propagating through the feature extraction layers and use them as fixed feature extractor, however, if the dataset the model is being re-trained on is sufficiently large, we can train the layers used for feature extraction as well using backprop to further enhance the model's prediction capabilities.    The code snippet can be modified based on the provided information as shown below    class VGG19FE(torch.nn.Module):      def __init__(self):          super(VGG19FE, self).__init__()          original_model = models.vgg19(pretrained=True)                    self.real_name = (((type(original_model).__name__)))          self.real_name = ""vgg19""            self.features = original_model.features            # Dummy input tensor to pass through the feature extractor          # Assume the input size is (num_channels, height, width) = (3, 224, 224)           x = torch.randn(1, 3, 224, 224)          f = self.features(x)  # pass the dummy input through the feature extractor          self.num_features = f.view(f.size(0), -1).size(1)          self.classifier = torch.nn.Sequential(              torch.nn.Linear(self.num_features, 2048),              torch.nn.ReLU(),              torch.nn.Dropout(p=0.5),              torch.nn.Linear(2048, 1024),              torch.nn.ReLU(),              torch.nn.Dropout(p=0.5),              torch.nn.Linear(1024, 2)          )        def forward(self, x):          f = self.features(x)          f = f.view(f.size(0), -1)          y = self.classifier(f)          print(y.data.size())          return y        To further elaborate    Feature Extraction:   - The self.features attribute contains the convolutional layers of the original VGG19 model, which are responsible for extracting features from the input images   - When an image is passed through self.features(x), it goes through multiple convolutional, ReLU activation, and pooling layers, transforming the image into a high-dimensional feature map that represents the content of the image.      Flattening:   - The extracted feature map f is reshaped or flattened before passing it to the fully connected layers.   - f = f.view(f.size(0), -1) reshapes the feature map into a 2D tensor where each row represents the flattened features of a corresponding image in the batch.    Classification:    - The flattened feature map is then passed through the self.classifier, a sequential model containing fully connected layers, ReLU activation layers, and Dropout layers.    - The classifier will output the probabilities of the image belonging to one of the pancreatic cancer classes.","When using a CNN for features extraction, the features can be extracted from various layers depending on the level of abstraction required, as the deeper we go into the model, the more abstract the features get, capturing more and more semantic information    This is what the self.featues shows when you print it    Sequential(    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (1): ReLU(inplace=True)    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (3): ReLU(inplace=True)    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (6): ReLU(inplace=True)    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (8): ReLU(inplace=True)    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (11): ReLU(inplace=True)    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (13): ReLU(inplace=True)    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (15): ReLU(inplace=True)    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (17): ReLU(inplace=True)    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (20): ReLU(inplace=True)    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (22): ReLU(inplace=True)    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (24): ReLU(inplace=True)    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (26): ReLU(inplace=True)    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (29): ReLU(inplace=True)    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (31): ReLU(inplace=True)    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (33): ReLU(inplace=True)    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))    (35): ReLU(inplace=True)    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)  )    Assuming an input image dimension of 224x224x3, here are 3 different ways of how features can be can be extracted    1. Extracting from the Last Convolutional Layer:  - Layer Name: The last convolutional layer is the final Conv2d layer before the MaxPool2d, named features[34] if we are accessing it through the layer index in PyTorch.   - Size of the Feature Vector: The spatial dimensions of the feature maps at this layer are 7×7 due to the five max-pooling layers, each reducing the size by a factor of 2. Since this layer has 512 filters, the depth is 512. Therefore, the size of the flattened feature vector is: 7×7x512 = 25088  - If we have a limited amount of data for re-training our model, we'd typically go with this approach and freeze the feature extractor (i.e. won't train the convolution layers of feature extractor using backprop)    2. Extracting from an Intermediate Convolutional Layer:  - Layer Name: As an example, let's choose the last Conv2d layer of the 3rd block, usually accessed as features[16] in PyTorch.  - Size of the Feature Vector: The spatial dimensions at this layer would be 28×28 as it is after the third max-pooling layer. This layer also has 256 filters. Therefore, the size of the flattened feature vector is: 28×28×256=200704  - If we have a good enough data, we'd typically use this approach as the intermediatory layers still have foundational knowledge of image features and we can train the model to better adapt to our specific dataset and use case    3. Extracting from the First Convolutional Layer:  - Layer Name: The first Conv2d layer in VGG19 is usually accessed as features[0] in PyTorch.  Size of the Feature Vector: The spatial dimensions at this layer are still 224×224 as there is no max-pooling yet, and the layer has 64 filters. Therefore, the size of the flattened feature vector is: 224×224×64=3211264  - If we have an abundant amount of data, this is the favored choice as we will be able to train the whole model on our specific dataset but at the same time, we don't have to go though the pain of designing the CNN from scratch. We will be using a well established CNN architecture that is proven to perform well on classification tasks    ","A CNN classifier typically consists of three components: a feature extractor, a feature aggregator, and a classifier. In our scenario, a pre-trained VGGNet is employed as the feature extractor. Post feature extraction, the aggregator combines these features to form a comprehensive representation, which is then fed to the classifier. In this instance, the classifier is composed of several fully connected layers, as depicted in the provided code snippet.    To refine the model's predictions, the classifier's raw outputs, or logits, are passed through a sigmoid or softmax activation function, converting them into probabilities representing the likelihood of each category. During training, a loss function, like softmax loss, quantifies the discrepancy between the model's predictions and the actual targets, guiding the model in tuning its parameters through back-propagation and optimization algorithms like gradient descent.    To improve the model's efficacy further, sophisticated feature aggregation techniques such as Feature Pyramid Networks (FPNs), Cross-Stage-Partial Connection Networks (CSPNets), and BiseNets can be incorporated. Additionally, modules like spatial attention can be integrated to augment the model's ability to focus on the most pertinent sections of the feature map, thereby enhancing its classification accuracy.","True, original_model.features, 4096, self.classifier(f)","(Did a bit of googling to answer this question as I have limited knowledge of neural style transfer)    Neural Style Transfer typically uses a combination of Content Loss and Style Loss    Content Loss      - Content loss ensures that the generated image maintains the same content as the base image      - Content loss is calculated by comparing the feature maps of the generated image and the base image      - The feature maps are output of the intermediate layers of the CNN model being used (VGG19 in this case)      - It is usually computed using Mean Squared Error (MSE) between the feature maps of the generated image and the base image        L_content = MSE(feature_maps_generated_image, feature_maps_base_image)    Style Loss      - Style loss ensures that the generated image has the similar style as the style image      - Style loss is calculated by comparing the Gram Matrix of the generated image and the style image          - Gram Matrix is a matrix of dot products of the feature maps and is a measure of the correlation between the feature maps      - It is usually computed using Mean Squared Error (MSE) between the Gram Matrix of the generated image and the style image at each layer        L_style = MSE(Gram_Matrix(feature_maps_generated_image), Gram_Matrix(feature_maps_style_image))    Total Loss      - Total loss is the weighted sum of the content loss and the style loss      - The weights are hyperparameters that can be tuned to get the desired results        L_total = alpha * L_content + beta * L_style    Activations in Training Process      - The activations of the intermediate layers of the CNN model are used to calculate the content loss and the style loss      - In the give use case, the activations of the intermediate layers of the VGG19 model are used      - The activations of the deeper layers are typically used to calculate the content loss as they contain more semantic information      - The activations of earlier layers are usually used to calculate the style loss as they contain more information about the textures and colors",#NAME?,Erosion,Dilation,Opening,Closing,,,,,,Quantization is a process that determines the value of each pixel in the image,,
1.14424E+11,427913904,09/29/2023 06:24:43 AM,09/29/2023 11:25:23 AM,94.57.48.207,,,,,Dr. Antaryami Mohanta,antaryami.mohanta@tii.ae,Directed Energy Research Center,Lead Researcher,Yes,Yes,Yes,ChatGPT,It can provide information and reword the text or writing.,"I haven't explored specific use cases for generative AI in my work yet, but I'm open to exploring how it could be beneficial in the future.",To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,Gain some exposure and jargon in the generative AI field,,Yes,2+ years,6,"del student[""marks""]",,,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,def is_palindrome(s): return s == s[::-1],def is_palindrome_1(s): return s == s[::2],def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/a8a2caac-d234-4be3-96e6-ab97d88fb9cb.png,,,Inheritance,7,"text = 'Hello! We are super excited to have you join the program to learn about generative AI amongst other things.'  print(text)    ### Your Code Below  text_1 = text.replace(""!"","""").replace(""."", """").split("" "")  text_dict= {}  for word in text_1:      e = 0      for j in text_1:          if j == word:              e = e+1      text_dict[word]=e  print(text_dict)",2xy + y,,,,,,I don't know,I don't know,,,Mean squared error,,,F-1 score,,,,,,,,See if it's an imbalanced dataset and apply oversampling,,,Keep adding more training data,,,,,I don't know,,,,,I don't know,I don't know,grad_input = [grad],xxxx,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/29/2023 10:10:54 AM,09/29/2023 10:13:58 AM,217.164.42.153,,,,,Alexis GANDON,alexis.gandon@tii.ae,DERC,Senior EMC engineer,No,Yes,Yes,bing conversation,limited yet,no,,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,No,I do not know Python,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/28/2023 02:45:58 PM,09/29/2023 02:10:27 AM,70.30.45.95,,,,,test,test,test,test,Yes,No,No,test,test,test,To have a solid understanding of the concepts and trends in generative AI,,,,,,,,,Yes,1-3 months,6,,"student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,def is_palindrome_1(s): return s == s[::2],,,adding .drop_duplicates() to employee['salary'],,,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/a8a2caac-d234-4be3-96e6-ab97d88fb9cb.png,,,Inheritance,6,test,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/28/2023 08:39:42 PM,09/28/2023 08:47:57 PM,5.38.34.207,,,,,Juan del Carmen Grados Vasquez,juan.grados@tii.ae,Cryptography Research Center,Cryptanalyst,Yes,Yes,I do not understand what a prompt is,Chatgpt,To make models based on end-user description to search for distinguishers,To make models based on end-user description to search for distinguishers,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,Yes,2+ years,7,"del student[""marks""]",,,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ vitanYP,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,1,"import string    def word_count_without_punctuation(text):      text = text.translate(str.maketrans('', '', string.punctuation)).lower()      words = text.split()            word_count = {}      for word in words:          if word in word_count:              word_count[word] += 1          else:              word_count[word] = 1            return word_count    sentence = ""Hello! We are super excited to have you join the program to learn about generative AI amongst other things!""  result = word_count_without_punctuation(sentence)  print(result)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/28/2023 07:46:45 PM,09/28/2023 08:37:55 PM,174.95.68.223,,,,,test_david,test_david,test_david,test_david,Yes,Yes,Yes,test_david,test_david,test_david,,,To be self-sufficient with no-code AI tools for business,,,,,,,Yes,2+ years,6,"del student[""marks""]","student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,PYn PYnat ive PYnativ vitanYP,def is_palindrome(s): return s == s[::-1],,,,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,5,test_david,2xy + y,Gini,Entropy,,,,,Green,Cross-entropy loss,,,,,F-1 score,R-squared,Mean squared error,Precision & Recall,All of the above,,,Look for data leakage,,Try a different evaluation metric,,Keep adding more training data,,,,Apply feature engineering techniques,"Bagging speeds up model training by parallelizing computation, while boosting reduces overfitting by adding regularization",,It ensures that the gradients are fresh and ready to be computed for the current iteration.,,,,I don't know,test_david,test_david,10,,Synonym replacement,,,,,,,,,,,"Irregular objects such as buildings, vehicles, or trees for autonomous vehicles",,,,,Random deletion,,,,,NER,,moving average smoothing,,,test_david,test_david,7,Stop-word Removal,,,,Tokenization,,GPT,T5,BERT,,T5 is a encoder-decoder mixed models,BERT models are encoder models,GPT-3 is an autoregressive model,GPT models are encoder-only models,,,,Decontamination,,,,Separate words into individual morphemes and identify the class of the morphemes,,"Given a sentence or larger chunk of text, determine which words (“mentions”)",,,,,,,Named entity recognition,,,,,This pipeline requires that labels be given to classify this text.,TRUE,,,A sequence-to-sequence model,,,"The sequence length, the batch size, and the hidden size",,,Splitting on whitespace and punctuation,,,,,,,Attention mechanism is good at context-aware processing,,A string containing all of the tokens,It's good practice to pad and truncate with the tokenizer as every input is a batch.,Find whether a sentence is grammatically correct or not.,"Some of the tokens in the input sentence are randomly masked, and the label is whether the sentence is positive or negative.",,,,Fixing the messages sent by my nephew/friend so they're in proper English,,10,,,GAN,ViT,,,,TRUE,test_david,test_david,test_david,"True, original_model.features, 1000, self.classifier(f)",test_david,test_david,,,Opening,,,,,,,Quantization is a process that determines the value of each pixel in the image,,
1.14424E+11,427913904,09/28/2023 07:57:19 PM,09/28/2023 07:59:17 PM,87.200.37.79,,,,,Wenbin Li,wenbin.li@tii.ae,AIDRC,senior researcher,Yes,Yes,Yes,ChatGPT,they can provide insights and ideas,yes many,,,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,Gain some exposure and jargon in the generative AI field,,Yes,3 months to 1 year,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/28/2023 02:44:53 PM,09/28/2023 07:56:14 PM,83.110.1.129,,,,,Hang,hang.zou@tii.ae,DSRC,Researcher,Yes,Yes,Yes,"pytorch, Transformer (HuggingFace)",I can work more effieciently,Collaborative Generative Agents,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,Gain some exposure and jargon in the generative AI field,,Yes,3 months to 1 year,6,"del student[""marks""]",,"student.remove(""marks"")",,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,,reverse the table order ascending=True,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Polymorphism,6,"import string  text_new = text.translate(str.maketrans('', '', string.punctuation))  words = text_new.split()  table = dict.fromkeys(words,0)  for word in words:    table[word] += 1    print(table)",2xy + y,Gini,Entropy,,,,,,Cross-entropy loss,,,,,F-1 score,,,,,,,,See if it's an imbalanced dataset and apply oversampling,,,,Try different algorithms,Combine different models,,Apply feature engineering techniques,I don't know,PyTorch uses zero_grad() to sets all the gradients to zero for all the parameters in the model.,It ensures that the gradients are fresh and ready to be computed for the current iteration.,,,,nn.Module is the base class for all neural network modules in PyTorch,grad_input = self.x * (1-grad)*grad,"import pandas as pd  import numpy as np  import matplotlib.pyplot as plt  %matplotlib inline    # Download the test dataset  from imblearn.datasets import fetch_datasets    data = fetch_datasets()['wine_quality']    # Separate data into features [X] and lable [y]  data['target']  X = data['data']  y = data['target']      # Apply visualizations techniques to explore the dataset  # Basic statistics  print(X.describe())    # Distribution of labels  plt.figure(figsize=(8, 5))  y.value_counts().plot(kind='bar')  plt.title('Distribution of Wine Quality Labels')  plt.xlabel('Quality')  plt.ylabel('Count')  plt.show()    # Create holdout dataset (or apply cross validation)  from sklearn.model_selection import train_test_split    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)    # Scale the features  from sklearn.preprocessing import StandardScaler    scaler = StandardScaler()  X_train_scaled = scaler.fit_transform(X_train)  X_test_scaled = scaler.transform(X_test)    # Check for label distribution and apply resampling accordingly  from imblearn.over_sampling import SMOTE    smote = SMOTE(random_state=42)  X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)    # Choose one of the classification algorithms: random forest, gradient boosting, xgboost  from sklearn.ensemble import RandomForestClassifier    clf = RandomForestClassifier(random_state=42)  clf.fit(X_train_resampled, y_train_resampled)    # Tune hyperparameters  from sklearn.model_selection import GridSearchCV    param_grid = {      'n_estimators': [50, 100, 150],      'max_depth': [None, 10, 20, 30],      'min_samples_split': [2, 5, 10]  }    grid_search = GridSearchCV(clf, param_grid, cv=3)  grid_search.fit(X_train_resampled, y_train_resampled)    # Get the best parameters  best_params = grid_search.best_params_  print(best_params)    # Evaluate and create the performance report  from sklearn.metrics import classification_report, accuracy_score    y_pred = grid_search.predict(X_test_scaled)    print(""Accuracy:"", accuracy_score(y_test, y_pred))  print(""\nClassification Report:\n"", classification_report(y_test, y_pred))    # Explain the top variables.  feature_importances = grid_search.best_estimator_.feature_importances_  features = data['feature_names']    # Display in descending order  sorted_indices = np.argsort(feature_importances)[::-1]  for i in sorted_indices:      print(f""{features[i]}: {feature_importances[i]}"")",6,Adding noise,,Flipping,,Scaling,,,"Autonomous driving and robotics to detect objects such as cars, people, or houses",e-Commerce product categorization,Household object detection for augmented reality applications,Anomaly detection in medical diagnostic imaging,Facial feature points for face detection,"Irregular objects such as buildings, vehicles, or trees for autonomous vehicles",,,Back translation,Synonym replacement,Random deletion,,Text generation,,,Part-of-speech tagging (POS),,moving average smoothing,,,"from bs4 import BeautifulSoup  import requests  url = 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence'  r = requests.get(url)  html = r.text  soup = BeautifulSoup(html)  links = soup.find_all('img')  for link in links:    url = link['src']    caption = link.get('alt', 'No caption available')  # Defaults to 'No caption available' if 'alt' is missing    print(link)    print(caption+':')    print('http:'+url+'\n')","import requests  import torch  import torch.nn.functional as F  import torchvision.transforms.functional as TF  from torchvision.io import read_image, write_png, decode_image    # Download the image   image_url = ""https://upload.wikimedia.org/wikipedia/commons/8/88/Example-dog-on-the-internet.png""    response = requests.get(image_url, stream=True)  response.raise_for_status()    image_tensor = decode_image(torch.ByteTensor(bytearray(response.content)))  print(image_tensor.shape)    # Augmentation using torchvision    # Rotate the image by 45 degrees  rotated_tensor = TF.rotate(image_tensor,45)  write_png(rotated_tensor, ""rotated_image.png"")    # Flip the image (horizontal flip)  flipped_tensor = TF.hflip(image_tensor)  write_png(flipped_tensor, ""flipped_image.png"")    # Sharpen the image  sharpening_kernel = torch.tensor([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])[:, :, None, None].float()  sharpened_tensor = F.conv2d(image_tensor[None].float(), sharpening_kernel)  sharpened_tensor = torch.clamp(sharpened_tensor, 0, 255).byte()    write_png(sharpened_tensor[0], ""sharpened_image.png"")",8,Stop-word Removal,Sentence Segmentation,Stemming,Lemmatization,Tokenization,,GPT,T5,BERT,,T5 is a encoder-decoder mixed models,BERT models are encoder models,GPT-3 is an autoregressive model,,,Data cleaning,Deduplication,,Toxicity and Bias Control,,,Separate words into individual morphemes and identify the class of the morphemes,,,,All of the above,,,,,,,,All of the mentioned,,This pipeline requires that labels be given to classify this text.,TRUE,,,,All of the above,,"The sequence length, the batch size, and the hidden size",WordPiece,,,BPE,,,"In NLP, attention mechanism is useful in sequence to sequence tasks such as translation, speech recognition, and summarization",,Local attention helps reduce the computation burden,Attention mechanism is good at context-aware processing,,A list of IDs,The tokenizer and model should always be from the same checkpoint.,Find the persons mentioned in a sentence.,"Some of the tokens in the input sentence are randomly masked and the labels are the original input tokens, shifted to the left.",Writing short reviews of long documents,Answering questions about a document,Translating a text in Arabic into English,Fixing the messages sent by my nephew/friend so they're in proper English,,6,MobileNet,LeNet,,,VGG,,,FALSE,load VGG19 from pre-trained model  add a MLC  freezing Layers of VGG19  train the new NN with provided dataset  evaluate the performance of training  inference on new images,Features from Convolutional Layer (conv4_3): 512  Features from Fully Connected Layer (fc6): 4096  Features from Fully Connected Layer (fc7): 4096,use classification algorithm such as SVM and KNN to do so.,"True, original_model.features, 4096, self.classifier(f)","content loss + style loss  For content loss, the activations of a specific layer in the neural network are used to represent the content of the image  For style loss, activations from multiple layers in the network are used to represent the style of the image through Gram Matrix",Convolution and convolution kernel,Erosion,Dilation,Opening,Closing,Morphological Gradient,Top Hat,Black Hat,,,Quantization is a process that determines the value of each pixel in the image,,
1.14424E+11,427913904,09/28/2023 07:16:24 PM,09/28/2023 07:19:17 PM,92.96.251.194,,,,,Shaikha Almarzooqi,shaikha.almarzooqi@tii.ae,DERC,Electrical Engineer,Yes,Yes,I do not understand what a prompt is,ChatGPT,it summarized papers when doing literature review   simplifies understanding new topics   ,not really ,,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,,,,,,Yes,1-3 months,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/28/2023 02:08:49 PM,09/28/2023 07:13:34 PM,176.205.179.217,,,,,Juan Cereijo,juan.cereijo@tii.ae,QRC,Associate Researcher,Yes,Yes,Yes,"Tensorflow, Github Copilot",Review or help when writing articles or code.,Review or help when writing articles or code.,,,,To gain technical experience with machine learning and AI,,"To learn how to build NLP, LLM, or Computer Vision models",,,,Yes,2+ years,8,"del student[""marks""]","student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,def is_palindrome(s): return s == s[::-1],,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,6,https://colab.research.google.com/drive/1I7ZQhlfBpwYd-QOEkBb4Wb1uUlm-xhxC?usp=sharing,2xy + y,Gini,,Sum of squared error (variance),,,,Green,Cross-entropy loss,,Mean squared error,,,,,Mean squared error,,,,,Look for data leakage,See if it's an imbalanced dataset and apply oversampling,Try a different evaluation metric,,Keep adding more training data,Try different algorithms,Combine different models,Try stochastic gradient descent instead of batch gradient descent,,I don't know,,It ensures that the gradients are fresh and ready to be computed for the current iteration.,,,,"When creating a new nn class in PyTorch, we need to define both forward and backward methods",grad*self.forward(self.x)*(1-self.forward(self.x)),https://colab.research.google.com/drive/1I7ZQhlfBpwYd-QOEkBb4Wb1uUlm-xhxC?usp=sharing,5,Adding noise,,Flipping,,Scaling,,,,,,,,,All of the mentioned,,Back translation,Synonym replacement,Random deletion,,Text generation,Trasformer-based,,Classification,,,,all of the above,https://colab.research.google.com/drive/1pIuS5mSVUMMH5YJWfdcTLHw2YssLDKHR?usp=sharing,https://colab.research.google.com/drive/1pIuS5mSVUMMH5YJWfdcTLHw2YssLDKHR?usp=sharing,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/28/2023 06:21:11 PM,09/28/2023 07:06:53 PM,99.229.11.66,,,,,dw,dwa,dwa,wda,No,No,Yes,w,d,d,To have a solid understanding of the concepts and trends in generative AI,,,,,,,,d,Yes,2+ years,5,,"student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ vitanYP,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,,,,I don't know,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/a8a2caac-d234-4be3-96e6-ab97d88fb9cb.png,,,I don't know,5,m,I don't Know,,,,,All of the mentioned,,Rain,,,Mean squared error,,,,,,,,I don't know,Celebrate the great performance and try to deploy the model,,,,,,,,,Apply feature engineering techniques,"Bagging speeds up model training by parallelizing computation, while boosting reduces overfitting by adding regularization",,,,,I don't know,"When creating a new nn class in PyTorch, backward method is not necessary since PyTorch does auto differentiation via autograd",n,n,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/28/2023 06:48:04 PM,09/28/2023 06:56:50 PM,99.229.11.66,,,,,Test_Joan,Test_Joan,N/A,N/A,No,No,I do not understand what a prompt is,N/A,N/A,N/A,,,,,,,,,N/A,Yes,2+ years,9,,"student.pop(""marks"")",,I don't' know,I don't know,I don't know,,,,I don't know,,,,I don't know,,,,I don't know,I don't know,9,N/A,I don't Know,,,,,,I don't know,I don't know,,,,,I don't know,,,,,,I don't know,,,,,I don't know,,,,,Apply feature engineering techniques,"Bagging creates multiple datasets by sampling with replacement, while boosting adds models sequentially and adjusts their weights based on the error of the previous models",,,It's often called after running the backward() function during training.,,,"When creating a new nn class in PyTorch, backward method is not necessary since PyTorch does auto differentiation via autograd",N/A,N/A,5,,,,,,,I don't know,,,,,,,,I don't know,,,,,,Trasformer-based,,All of the above,,moving average smoothing,,,N/A,N/A,5,,,Stemming,,,,,,,I don't know,,,GPT-3 is an autoregressive model,,,,Deduplication,,,,,I don't know,,,,All of the above,,,,,,Word sense disambiguation,,,,This pipeline requires longer inputs; this one is too short,TRUE,,A decoder model,,,,"The sequence length, the batch size, and the hidden size",,,,,Unigram,,,The attention mechanism is good at handling long sequence input,,,,"A list of strings, each string being a token","No, it seems correct.",Find whether a sentence is grammatically correct or not.,I don't know,,,,,I don't know,5,,,,,,Stable Diffusion,,I don't know,N/A,N/A,N/A,"False, original_model.features, 4096, self.classifier(f)",N/A,N/A,,Dilation,,,,,,,,,All of the above,
1.14424E+11,427913904,09/28/2023 04:03:09 PM,09/28/2023 06:23:23 PM,24.114.65.245,,,,,test,test,test,test,No,Yes,Yes,test,test,test,To have a solid understanding of the concepts and trends in generative AI,,,,,,,,,Yes,1-3 months,5,,"student.pop(""marks"")",,,10 Chair 10 Table,Yna PYnat tive PYnativ PYnativ,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,,,adjust the referencing to be iloc[N],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/4b0a1e6b-c3dd-48f4-9437-0286177c6d83.png,,Inheritance,1,test,x^2 + x + 8,,,,,,I don't know,I don't know,,,Mean squared error,,,,,,,,I don't know,,Look for data leakage,,,,Keep adding more training data,,,,,"Bagging creates multiple datasets by sampling with replacement, while boosting adds models sequentially and adjusts their weights based on the error of the previous models",,,,All of the above,,"When creating a new nn class in PyTorch, backward method is not necessary since PyTorch does auto differentiation via autograd",test,test,5,,,Flipping,,,,,,,,Anomaly detection in medical diagnostic imaging,,,,,,,,Cropping,,,,Classification,,moving average smoothing,,,test,test,5,,,Stemming,,,,,,BERT,,T5 is a encoder-decoder mixed models,,,,,,,Decontamination,,,,Separate words into individual morphemes and identify the class of the morphemes,,"Given a sentence or larger chunk of text, determine which words (“mentions”)",,,,,,,,Word sense disambiguation,,,,"This pipeline requires several sentences, not just one.",FALSE,An encoder model,,,,,The sequence length and the hidden size,,,Splitting on whitespace and punctuation,,,,,The attention mechanism is good at handling long sequence input,,,,A list of IDs,The tokenizer and model should always be from the same checkpoint.,Find the persons mentioned in a sentence.,Some of the tokens in the input sentence are randomly masked and the labels are the original input tokens.,Writing short reviews of long documents,,,,,10,,,,ViT,,,,FALSE,test,test,test,"False, original_model.features, 512, self.classifier()",test,test,,,,Closing,,,,Sampling is the process that determines the size of the image to be obtained,,,,
1.14423E+11,427913904,09/28/2023 01:41:32 PM,09/28/2023 06:02:37 PM,83.110.1.129,,,,,Pranesh Santikellur,pranesh.santikellur@tii.ae,SSRC,Senior Embedded Security Researcher,Yes,Yes,Yes,"ChatGPT, Mid-Journey, DALL-E, ChatPDF, Tensorflow, PyTorch",It makes the research exploration easy and increases the pace and productivity.  ,List of two main use-cases here:  1. Conversational First Responder Device: Enabling Secure and  Human-like Interactions in First Responder Applications  using Large Language Models  2. TacLLM: Generative AI-Based Tactical Situational Awareness  System for Improved Decision Making and Analysis for the First Responder Project,To have a solid understanding of the concepts and trends in generative AI,,,,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,Yes,2+ years,8,"del student[""marks""]",,,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,def is_palindrome(s): return s == s[::-1],,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,10,"text = 'Hello! We are super excited to have you join the program to learn about generative AI amongst other things.'  print(text)    ### Your Code Below  import string    punctuation = set(string.punctuation)  words = []  for char in text:      if char not in punctuation:          words.append(char)    text = """".join(words)    words = text.split()    word_counts = {}  for word in words:      if word in word_counts:          word_counts[word] += 1      else:          word_counts[word] = 1    print(word_counts)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14423E+11,427913904,09/28/2023 01:37:42 PM,09/28/2023 04:37:41 PM,94.202.213.126,,,,,Samridha Shrestha,samridha.shrestha@tii.ae,SSRC,Machine Learning Engineer,Yes,Yes,Yes,"ChatGPT, MidJourney, Stable Diffusion, ElevenLabs Text to Audio",Learning new technical concepts quickly; Quick prototyping of an idea or concept in code and generating boilerplate code to start codebases quickly,Security Analyses of written code; Inspection of system calls in software containers for malicious or anomalies activities,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,Yes,2+ years,8,"del student[""marks""]","student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,,,adjust the referencing to be iloc[N],,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/a8a2caac-d234-4be3-96e6-ab97d88fb9cb.png,,,Inheritance,10,from collections import defaultdict    def wcounter(sent: str) -> dict:    wcount = defaultdict(int)    sent = ''.join([c for c in sent if c.isalpha() or c == ' '])    for w in sent.split():      wcount[w] += 1    return wcount,2xy + y,Gini,Entropy,,,,,Green,Cross-entropy loss,,,,,F-1 score,,,Precision & Recall,,,,Look for data leakage,See if it's an imbalanced dataset and apply oversampling,Try a different evaluation metric,,Keep adding more training data,Try different algorithms,Combine different models,Try stochastic gradient descent instead of batch gradient descent,Apply feature engineering techniques,"Bagging creates multiple datasets by sampling with replacement, while boosting adds models sequentially and adjusts their weights based on the error of the previous models",PyTorch uses zero_grad() to sets all the gradients to zero for all the parameters in the model.,,,,,"When creating a new nn class in PyTorch, backward method is not necessary since PyTorch does auto differentiation via autograd",grad_input = grad * sigmoid(grad) * ( 1 - sigmoid(grad))  # where sigmoid is the sigmoid function,"# Commented out IPython magic to ensure Python compatibility.  import pandas as pd  import numpy as np  import matplotlib.pyplot as plt  # %matplotlib inline    # Download the test dataset  from imblearn.datasets import fetch_datasets    data = fetch_datasets()['wine_quality']    # Separate data into features [X] and lable [y]  data['target']  X = data['data']  y = data['target']    # check data shapes  print(X.shape, y.shape, np.unique(y, return_counts=True))    # inspect data statistics  Xy_data = pd.DataFrame({f'feature_{i+1}': X[:, i] for i in range(X.shape[1])})  Xy_data[""target""] = y  Xy_data.describe()    # generate correlation matrix  Xy_data.iloc[:, :-1].corr()    # Visualize the distribution of wine quality  plt.hist(y, edgecolor='k')  plt.xlabel('Wine Quality')  plt.ylabel('Frequency')  plt.title('Distribution of Wine Quality')  plt.show()    # train test split  from sklearn.model_selection import train_test_split    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)    print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)    # scale features  from sklearn.preprocessing import StandardScaler    scaler = StandardScaler()  X_train_scaled = scaler.fit_transform(X_train)  X_test_scaled = scaler.transform(X_test)    # try oversampling first  from imblearn.over_sampling import RandomOverSampler    ros = RandomOverSampler(random_state=42)  X_resampled, y_resampled = ros.fit_resample(X_train_scaled, y_train)    # select model and train on resampled data  from sklearn.ensemble import RandomForestClassifier  from sklearn.model_selection import GridSearchCV    param_grid = {      'n_estimators': [100, 200, 300],      'max_depth': [10, 20, 30],      'min_samples_split': [2, 5, 10],      'min_samples_leaf': [1, 2, 4]  }    grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5)  grid_search.fit(X_resampled, y_resampled)  best_rf_model = grid_search.best_estimator_    # evaluate model on test data  from sklearn.metrics import classification_report, confusion_matrix    y_pred = best_rf_model.predict(X_test_scaled)  print(classification_report(y_test, y_pred))  print(confusion_matrix(y_test, y_pred))    # explaining top variables  feature_importance = best_rf_model.feature_importances_  print(feature_importance)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/28/2023 03:26:37 PM,09/28/2023 04:25:43 PM,83.110.1.129,,,,,Abdulla Alseiari,Abdulla.Alseiari@tii.ae,PSRC,Lead Researcher - Predictions Analytic,Yes,Yes,No,AI tools for prognostic in maintenance ,Optimize the accuracy of fault prognosis ,Predictive Maintenance ,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,,,,,Yes,1-3 months,5,,,"student.remove(""marks"")",,10 Chair 20 Table,I don't know,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,,,,I don't know,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/a8a2caac-d234-4be3-96e6-ab97d88fb9cb.png,,,Abstraction,4,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/28/2023 01:54:14 PM,09/28/2023 04:00:42 PM,2.48.80.9,,,,,Alejandro Garcia-Vaquero Velasco,alejandro.garcia-vaquero@tii.ae,ARRC,Senior Hardware Design and System Integration Engineer,Yes,Yes,Yes,"ChatGPT and Google Bard, ",Boosts performance and helps breaking down the problem. Also it generates most of the boilerplate code and then its just filling the appropriate functions,"Help me coding, brainstorming to solve a problem. Also sometimes writing business english polite emails.",,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,Yes,2+ years,7,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/28/2023 03:50:56 PM,09/28/2023 03:57:04 PM,31.215.238.253,,,,,Juan Grados,juan.grados@tii.ae,Cryptography Research Center,Cryptanalyst ,Yes,Yes,No,Chatgpt ,To code some tedious and basic tasks.,In the generation of model to search for cipher distinguishers,,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,Yes,2+ years,7,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14423E+11,427913904,09/28/2023 01:38:24 PM,09/28/2023 03:53:03 PM,5.195.137.87,,,,,Pedro Henrique Silva,pedro.silva@tii.ae,SSRC,Lead Security Engineer,Yes,Yes,Yes,TensorFlow (CNN and LSTM)  Scikit-learn (ML)  Keras (CNN and LSTM)  AutoML  YOLOv3   ChatGPT  Bard  Dall-E,"In the security field AI is already used frequently for authentication (face ID, voice recognition, etc), phishing detection, but it also can be enhanced for cases such as Reverse Engineering (binary analysis and decompilation), Vulnerability Assessment (scanning and recommendation) and Threat Detection (monitoring and prevention).",Mostly in Reverse Engineering (binary analysis and decompilation) and Vulnerability Assessment (scanning and recommendation),To have a solid understanding of the concepts and trends in generative AI,,,,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,Yes,2+ years,9,"del student[""marks""]","student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,10,"import string      def remove_punctuation(input_string):      translator = str.maketrans("""", """", string.punctuation)      return input_string.translate(translator)    def word_counter(input_string):      string_wo_punct = remove_punctuation(input_string)      words = string_wo_punct.split()            counter = {}      for word in words:          if counter.get(word) is None:              counter[word] = 1          else:              counter[word] += 1                    return counter        text = 'Hello! We are super excited to have you join the program to learn about generative AI amongst other things.'  print(word_counter(text))",2xy + y,Gini,Entropy,,,,,Green,Cross-entropy loss,,,,,F-1 score,,,Precision & Recall,,,,,See if it's an imbalanced dataset and apply oversampling,Try a different evaluation metric,,,Try different algorithms,Combine different models,,Apply feature engineering techniques,"Bagging creates multiple datasets by sampling with replacement, while boosting adds models sequentially and adjusts their weights based on the error of the previous models",PyTorch uses zero_grad() to sets all the gradients to zero for all the parameters in the model.,,,,,I don't know,grad * forward(x) * (1-forward(x)),Skip,,Adding noise,,Flipping,Random insertion,,,,"Autonomous driving and robotics to detect objects such as cars, people, or houses",,Household object detection for augmented reality applications,,,,,,Back translation,Synonym replacement,Random deletion,,Text generation,Trasformer-based,,Part-of-speech tagging (POS),binning,moving average smoothing,,,Skip,Skip,,Stop-word Removal,Sentence Segmentation,Stemming,Lemmatization,Tokenization,,GPT,,BERT,,,,,,I don't know,,,,,,I don't know,I don't know,,,,,,I don't know,,,,,,,I don't know,This pipeline requires that labels be given to classify this text.,FALSE,,,A sequence-to-sequence model,,,I don't know,,,Splitting on whitespace and punctuation,,,,,,,,I don't know,A string containing all of the tokens,I don't know,Find the chunk of words in a sentence that answers a question.,I don't know,Writing short reviews of long documents,,,,,,MobileNet,LeNet,,,VGG,,,FALSE,I don't know,I don't know,I don't know,"True, original_model.features, 4096, self.classifier(f)",I don't know,Convolution ,Erosion,Dilation,,,,,,,Sampling is dependent on both the content and the size of the image,Quantization is a process that determines the value of each pixel in the image,,
1.14424E+11,427913904,09/28/2023 03:47:43 PM,09/28/2023 03:52:51 PM,92.96.204.224,,,,,Etienne Goffinet,etienne.goffinet@gmail.com,Biotechnology Research Center,Senior Researcher,Yes,Yes,Yes,"LSTM, CNN, Transformers",-,-,,,,,,,To implement generative AI solutions in the lab or production environment,,,Yes,2+ years,8,"del student[""marks""]","student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,def is_palindrome(s): return s == s[::-1],,,,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,8,"import re  from collections import Counter    def count_words(sentence):      words = re.sub(r'[^\w\s]','',sentence)      return dict(Counter(words.split()))    ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/28/2023 03:48:55 PM,09/28/2023 03:51:07 PM,83.110.1.129,,,,,Yu Tian,yu.tian@tii.ae,DSRC,Researcher,Yes,Yes,Yes,"pytorch  chatgpt, dalle",yes,write code and paper,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,Gain some exposure and jargon in the generative AI field,,Yes,2+ years,8,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14423E+11,427913904,09/28/2023 01:35:03 PM,09/28/2023 03:46:11 PM,92.96.204.224,,,,,Etienne Goffinet,etienne.goffinet@gmail.com,Biotechnology Research Center,Senior researcher,Yes,Yes,Yes,"elmo representations using lstm, transformers (encoder only, decoder only, both), cnn",It is yet to be researched,Not yet,To have a solid understanding of the concepts and trends in generative AI,,,,,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,Yes,2+ years,5,"del student[""marks""]","student.pop(""marks"")","student.remove(""marks"")",,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,def is_palindrome(s): return s == s[::-1],,,,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,8,"import re  from collections import Counter    def count_words(sentence):      sentence_wo_punctuation = re.sub(r'[^\w\s]','',sentence)      word_list = sentence_wo_punctuation.split()      return dict(Counter(word_list))",2xy + y,Gini,Entropy,Sum of squared error (variance),,,,Green,Cross-entropy loss,,,,,F-1 score,,,Precision & Recall,,,,Look for data leakage,,Try a different evaluation metric,,Keep adding more training data,Try different algorithms,Combine different models,,Apply feature engineering techniques,"Bagging creates multiple datasets by sampling with replacement, while boosting adds models sequentially and adjusts their weights based on the error of the previous models",PyTorch uses zero_grad() to sets all the gradients to zero for all the parameters in the model.,It ensures that the gradients are fresh and ready to be computed for the current iteration.,,,,All of the above,grad_input = np.exp(grad) / (1 + np.exp(grad))**2,"import pandas as pd    from xgboost import XGBClassifier  from xgboost import plot_importance  from matplotlib import pyplot as plt  from imblearn.datasets import fetch_datasets  from sklearn.model_selection import GridSearchCV  from sklearn.model_selection import train_test_split  from sklearn.preprocessing import LabelEncoder, StandardScaler  from sklearn.metrics import confusion_matrix, classification_report    data = fetch_datasets()['wine_quality']    # Separate data into features [X] and lable [y]  data['target']  X = data['data']  y = data['target']    df = pd.DataFrame(data['data'])  df.columns = [""fixed acidity"", ""volatile acidity"", ""citric acid"", ""residual sugar"", 'chlorides', ""free sulfur dioxide"",                ""total sulfur dioxide"", ""density"", ""pH"", ""sulphates"", 'alcohol']    # Scale Data  x_scaled = StandardScaler().fit_transform(df)    # Create train/test split  X_train, X_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, random_state=1)    # Balance labels  class_count = [sum(y_train == value) for value in list(set(y_train))]  X_train_undersampled = pd.concat([pd.DataFrame(X_train[y_train == value]).sample(min(class_count)) for value in list(set(y_train))])  X_train_undersampled = X_train_undersampled.sample(frac=1).reset_index(drop=True)    # Train predictor  model = XGBClassifier()  le = LabelEncoder()  y_train = le.fit_transform(y_train)  model.fit(X_train, y_train)  y_pred = model.predict(X_test)    # Get confusion matrix  y_test = le.fit_transform(y_test)  conf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)  labels = ['Class -1', 'Class 1']  fig = plt.figure()  ax = fig.add_subplot(111)  cax = ax.matshow(conf_mat, cmap=plt.cm.Blues)  fig.colorbar(cax)  ax.set_xticklabels([''] + labels)  ax.set_yticklabels([''] + labels)  plt.xlabel('Predicted')  plt.ylabel('Expected')  plt.show()      # Grid Search on hyper-parameters  parameters = {      'max_depth': range (5, 10, 1),      'n_estimators': range(50, 300, 50),      'learning_rate': [0.05 * i for i in range(6)]  }    grid_search = GridSearchCV(      estimator=model,      param_grid=parameters,      scoring = 'roc_auc',      n_jobs = 16,      cv = 3,      verbose=True  )    grid_search.fit(X_train, y_train)  best_model = grid_search.best_estimator_    print(best_model.max_depth, best_model.n_estimators, best_model.learning_rate)    # Classification report    y_pred = best_model.predict(X_test)  print(classification_report(y_test, y_pred, target_names=['class -1', 'class 1']))    # Plotting the variable importance  best_model.get_booster().feature_names = list(df.columns)  plot_importance(best_model.get_booster())  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14423E+11,427913904,09/28/2023 01:37:10 PM,09/28/2023 03:30:19 PM,94.203.20.36,,,,,Duran Martin,duran.martin@tii.ae,Propulsion and Space Research Centre,Researcher,Yes,Yes,Yes,ChatGPT,"I use these tools for refined searches to point me in the right direction to solve specific problems ranging from thermodynamics, instructions on software packages to python functions","I use these tools for refined searches to point me in the right direction to solve specific problems ranging from thermodynamics, instructions on software packages to python functions",To have a solid understanding of the concepts and trends in generative AI,,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,,To implement generative AI solutions in the lab or production environment,,,Yes,2+ years,7,"del student[""marks""]","student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,1,text = 'Hello! We are super excited to have you join the program to learn about generative AI amongst other things.'  print(text)    ### Your Code Below  from string import punctuation    new_text = ''  for char in text:      if char in punctuation:          pass      else:          new_text = new_text + char    words = (new_text.lower()).split()    word_dict = {}  for i in words:      if i in word_dict:          word_dict[i] += 1      else:          word_dict[i] = 1  print(word_dict),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/28/2023 02:01:19 PM,09/28/2023 03:26:17 PM,2.50.149.139,,,,,Jaeden Amero,jaeden.amero@tii.ae,Directed Energy,Principal Software Engineer,Yes,Yes,Yes,"For generative AI, I've worked with and prefer the ""host it yourself"" options like AUTOMATIC1111 (Stable Diffusion) and Oobabooga Text UI (with Falcon, Alpaca, Llama, and other models). I have experience with Numpy, Pandas, Scikit-learn, PyTorch. For optimizing deployment of models (inference) I've worked with Apache TVM (a model compiler). I also previously wrote my own machine learning toolkit.","LLMs would be primarily as a complement to Google searching (learning about things), but also as a way to improve my own writing. I'm more interested in multi-modal models than text-only LLMs. I'm primarily working with DSP. With multi-modal models, there is a large amount of data analysis and insight generation I can do.","Yes, many. (See previous reply)",,,,,,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,Data modeling and processing; computer vision (in RF),Yes,2+ years,8,"del student[""marks""]","student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,8,"import re                                                                                                                                                                                                                                                                                                                             text = ""Hello! We are super excited to have you join the program to learn about generative AI amongst other things!""                                                                                                                                                                                                            stripped = re.sub(r'[^\w\s]', '', text).lower()                                                                                                                    wl = stripped.split(' ')                                                                                                                                           wc = {x: wl.count(x) for x in wl}                                                                                                                                                                                                                                                                                                     print(repr(wc)) ",2xy + y,Gini,Entropy,Sum of squared error (variance),,,,Green,Cross-entropy loss,,,,,F-1 score,,,Precision & Recall,,,,Look for data leakage,See if it's an imbalanced dataset and apply oversampling,Try a different evaluation metric,,Keep adding more training data,Try different algorithms,Combine different models,,Apply feature engineering techniques,"Bagging creates multiple datasets by sampling with replacement, while boosting adds models sequentially and adjusts their weights based on the error of the previous models",PyTorch uses zero_grad() to sets all the gradients to zero for all the parameters in the model.,It ensures that the gradients are fresh and ready to be computed for the current iteration.,It's often called after running the backward() function during training.,All of the above,,nn.Module is the base class for all neural network modules in PyTorch,todo,todo,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/28/2023 03:18:29 PM,09/28/2023 03:26:10 PM,83.110.1.129,,,,,Appar,appar.thusoo@tii.ae,SSRC,,Yes,Yes,Yes,"Loudly, Chat-GPT, Dall-E, Co-pilot etc.","They automate stuff that's already known and done, which saves a lot of time to do something on top of it",yeah quite a lot. AI based fuzzer to start with,To have a solid understanding of the concepts and trends in generative AI,,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,Yes,2+ years,8,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14423E+11,427913904,09/28/2023 01:37:20 PM,09/28/2023 03:09:17 PM,83.110.1.129,,,,,Prabakaran Balasubramanian,p.balasubramanian@tii.ae,AMRC,Senior Researcher,Yes,Yes,No,"ChatGPT, Bard, MidJourney, SlidesAI","It will help to reduce the time it takes to solve a problem. It can also help brainstorm ideas, give feedback and help understand a complicated topic and also can be excellent assistant. ","Yes. It is possible to train a generative AI specifically for the mechanical engineering work. Also, I am trying to develop a damage detection algorithm from vibration data. For this purpose, I would like to use generative AI with some other CNN.",,,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,Yes,2+ years,8,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/28/2023 02:56:24 PM,09/28/2023 03:08:42 PM,83.110.1.129,,,,,Abdul Mannan Zafar,Abdul.Zafar@tii.ae,BRC,Researcher,Yes,Yes,Yes,ChatGPT,Yes very effective and robust. ,Yes,To have a solid understanding of the concepts and trends in generative AI,,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,Gain some exposure and jargon in the generative AI field,,Yes,3 months to 1 year,6,,,"student.remove(""marks"")",,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,def is_palindrome(s): return s == s[::-1],,,,,reverse the table order ascending=True,,,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/4b0a1e6b-c3dd-48f4-9437-0286177c6d83.png,,Inheritance,1,N/A,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/28/2023 02:57:59 PM,09/28/2023 02:59:40 PM,5.31.221.166,,,,,Haithem Boussaid,haithem.boussaid@tii.ae,BRC,Lead researcher,Yes,Yes,Yes,chatGPT,code,radiology report,,To learn how to use prompting to make myself more efficient at work,,,To learn how to fine-tune and apply AI models for my business domains,,,,,Yes,2+ years,7,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/28/2023 02:15:32 PM,09/28/2023 02:49:49 PM,94.59.214.178,,,,,Alessandro Marini,alessandro.marini@tii.ae,PSRC,Senior Researcher,Yes,Yes,No,DALL-E 2  ChatGPT,writing code  process data  summarize existing/write new document,auto-tuning of model parameters in computational fluid dynamics  ,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,,,,,,Yes,1-2 years,5,"del student[""marks""]","student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,def is_palindrome(s): return s == s[::-1],,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,1,"import string    str1 = ""Hello! We are super excited to have you join the program to learn about generative AI amongst other things!""  str1 = str1.translate(str.maketrans('', '', string.punctuation))    words = str1.split()  word_count = {}    for word in words:    word = word.lower()    if word in word_count:      word_count[word] += 1    else:      word_count[word] = 1    print(word_count)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14423E+11,427913904,09/28/2023 01:48:12 PM,09/28/2023 02:46:39 PM,5.31.221.166,,,,,Haithem Boussaid,haithem.boussaid@tii.ae,BRC,Lead Researcher,Yes,Yes,Yes,chatGPT,write code and emails,generate radiology report from medical images,,To learn how to use prompting to make myself more efficient at work,,,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,Yes,2+ years,7,,,"student.remove(""marks"")",,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,adjust the referencing to be iloc[N],,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,10,"import string    def count_words(sentence):      # Initialize an empty dictionary to store word counts.      word_counts = {}        # Split the sentence into words using whitespace as a delimiter.      words = sentence.split()        # Remove punctuation from each word and update the word counts.      for word in words:          # Remove punctuation from the word using str.translate() method.          cleaned_word = word.translate(str.maketrans('', '', string.punctuation))            # Check if the cleaned word is not empty.          if cleaned_word:              # Convert the cleaned word to lowercase (assuming case-insensitive counting).              cleaned_word = cleaned_word.lower()                # Update the word count in the dictionary.              if cleaned_word in word_counts:                  word_counts[cleaned_word] += 1              else:                  word_counts[cleaned_word] = 1        return word_counts    # Example sentence  sentence = ""Hello! We are super excited to have you join the program to learn about generative AI amongst other things!""  result = count_words(sentence)  print(result)  ",2xy + y,Gini,Entropy,,,,,Green,Cross-entropy loss,,,,,F-1 score,,,Precision & Recall,,,,Look for data leakage,See if it's an imbalanced dataset and apply oversampling,Try a different evaluation metric,,Keep adding more training data,Try different algorithms,Combine different models,Try stochastic gradient descent instead of batch gradient descent,Apply feature engineering techniques,"Bagging creates multiple datasets by sampling with replacement, while boosting adds models sequentially and adjusts their weights based on the error of the previous models",PyTorch uses zero_grad() to sets all the gradients to zero for all the parameters in the model.,It ensures that the gradients are fresh and ready to be computed for the current iteration.,It's often called after running the backward() function during training.,All of the above,,nn.Module is the base class for all neural network modules in PyTorch,sigmoid_output = 1 / (1 + np.exp(-self.x))  grad_input = grad * sigmoid_output * (1 - sigmoid_output),"# Step 1: Apply visualization techniques to explore the dataset    # Example: Create a histogram for one feature  plt.hist(X['alcohol'], bins=20, color='skyblue')  plt.xlabel('Alcohol Content')  plt.ylabel('Frequency')  plt.title('Distribution of Alcohol Content')  plt.show()    # Step 2: Create a holdout dataset (or apply cross-validation)    from sklearn.model_selection import train_test_split    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)    # No output to display for this step    # Step 3: Scale the features    from sklearn.preprocessing import StandardScaler    scaler = StandardScaler()  X_train_scaled = scaler.fit_transform(X_train)  X_test_scaled = scaler.transform(X_test)    # No output to display for this step    # Step 4: Check for label distribution and apply resampling accordingly    from imblearn.over_sampling import RandomOverSampler    # Example: Apply random oversampling to balance classes  ros = RandomOverSampler(random_state=42)  X_resampled, y_resampled = ros.fit_resample(X_train_scaled, y_train)    # No output to display for this step    # Step 5: Choose one of the classification algorithms (Random Forest as an example)    from sklearn.ensemble import RandomForestClassifier    clf = RandomForestClassifier(n_estimators=100, random_state=42)    # No output to display for this step    # Step 6: Tune hyperparameters    from sklearn.model_selection import GridSearchCV    param_grid = {      'n_estimators': [100, 200, 300],      'max_depth': [None, 10, 20],  }    grid_search = GridSearchCV(clf, param_grid, cv=3)  grid_search.fit(X_resampled, y_resampled)  best_classifier = grid_search.best_estimator_    # No output to display for this step    # Step 7: Evaluate and create the performance report    from sklearn.metrics import classification_report, confusion_matrix    y_pred = best_classifier.predict(X_test_scaled)  report = classification_report(y_test, y_pred)  confusion = confusion_matrix(y_test, y_pred)    print(""Classification Report:\n"", report)  print(""Confusion Matrix:\n"", confusion)    # Example output:  # Classification Report:  #               precision    recall  f1-score   support  #  #            0       0.86      0.84      0.85       178  #            1       0.61      0.64      0.62        61  #  #     accuracy                           0.78       239  #    macro avg       0.73      0.74      0.73       239  # weighted avg       0.79      0.78      0.78       239  #  # Confusion Matrix:  # [[149  29]  #  [ 22  39]]    # Step 8: Explain the top variables (feature importance for Random Forest as an example)    feature_importance = best_classifier.feature_importances_  sorted_indices = np.argsort(feature_importance)[::-1]    # Example: Display the top 10 important features  top_features = X.columns[sorted_indices][:10]  print(""Top 10 Important Features:"", top_features)    # Example output:  # Top 10 Important Features: Index(['alcohol', 'sulphates', 'volatile acidity', 'total sulfur dioxide',  #        'chlorides', 'citric acid', 'residual sugar', 'density', 'fixed acidity',  #        'free sulfur dioxide'],  #       dtype='object')  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/28/2023 02:12:24 PM,09/28/2023 02:44:13 PM,217.164.168.142,,,,,Humaid Ibrahim,Humaid.Ibrahim@tii.com,Propulsion and Space Research Center,Associate Researcher,Yes,Yes,Yes,"ChatGPT, Dall-E, slidesgo","It can rephrase wordy sentences and summarize long texts that would otherwise be hard to read. It can look up common or general topics and give me a quick report on it, but it's not good for more specific and technical topics. For the image side, creating generic diagrams for reports and presentations can save a lot of time. ",Summary/paraphrasing of paragraphs. Makes reading much faster. Generation of images for presentations. Creating a template presentation for whatever topic I specify.,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,Yes,2+ years,9,"del student[""marks""]","student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,10,"# I would use nltk to filter out the stopwords, but I'm not sure if I can use other libraries so I just hardcoded the stopwords.  inp = ""Hello! We are super excited to have you join the program to learn about generative AI amongst other things!""  words = inp.split()  words_corrected = []  for word in words:      normal_string=''.join(filter(str.isalnum, word.lower()))      words_corrected.append(normal_string)    filter_words = [""we're"", ""we"", ""are"", ""to"", ""have"", ""you"", ""our"", ""ai"", ""about"", ""other"", ""the""]  output = list(filter(lambda w: not w in filter_words,words_corrected))  output = dict((i,output.count(i)) for i in output)  print(output)  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14423E+11,427913904,09/28/2023 01:42:13 PM,09/28/2023 02:43:48 PM,83.110.1.129,,,,,Hang,hang.zou@tii.ae,DSRC,Researcher,Yes,Yes,Yes,"ChatGPT, AutoGPT, Generative Agents, DALLE2, Stable Diffusion",AI tools have changed my way of working completely,Collaborative Generative Agents,To have a solid understanding of the concepts and trends in generative AI,,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,Gain some exposure and jargon in the generative AI field,,Yes,3 months to 1 year,6,"del student[""marks""]",,"student.remove(""marks"")",,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,,reverse the table order ascending=True,adjust the referencing to be iloc[N],,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,5,"import string  text_new = text.translate(str.maketrans('', '', string.punctuation))  words = text_new.split()  table = dict.fromkeys(words,0)  for word in words:    table[word] += 1    print(table)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/28/2023 02:40:34 PM,09/28/2023 02:40:56 PM,70.30.45.95,,,,,test,test,test,test,No,No,No,test,test,test,,,,,,,To implement generative AI solutions in the lab or production environment,,,Yes,1-3 months,7,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14423E+11,427913904,09/28/2023 01:35:26 PM,09/28/2023 02:38:04 PM,83.110.1.129,,,,,Norbert Tihanyi,norbert.tihanyi@tii.ae,AIDRC,Lead Researcher,Yes,Yes,Yes,"PyTorch, TensorFlow, FalconLLM, GPT-3.5-turbo API, Keras, etc.. ","YES, definitely!","YES, I am doing research in this field.",To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,Gain some exposure and jargon in the generative AI field,,Yes,2+ years,7,,,"student.remove(""marks"")",,10 Chair 10 Table 20 Chair 20 Table,PYn PYnat ive PYnativ vitanYP,def is_palindrome(s): return s == s[::-1],,,,adding .drop_duplicates() to employee['salary'],,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/f3bc211f-2a88-4f6b-822e-09b2758c276b.png,,,,Inheritance,7,"import string  k='Hello! We are super excited to have you join the program to learn about generative AI amongst other things.'  a = str.maketrans('', '', string.punctuation);d = k.translate(a).lower()  a = d.split();b={}  for c in a:          if c in b: b[c] += 1          else: b[c] = 1    print(b)",2xy + y,Gini,Entropy,,,,,Green,Cross-entropy loss,,Mean squared error,,,F-1 score,,,Precision & Recall,,,,,See if it's an imbalanced dataset and apply oversampling,Try a different evaluation metric,,Keep adding more training data,Try different algorithms,Combine different models,Try stochastic gradient descent instead of batch gradient descent,Apply feature engineering techniques,None of the above,PyTorch uses zero_grad() to sets all the gradients to zero for all the parameters in the model.,,,,,nn.Module is the base class for all neural network modules in PyTorch,N/A,N/A,,,,,,,,I don't know,,,,,,,,I don't know,,,,,,,Scaling,Classification,,,random sampling,,N/A,N/A,,Stop-word Removal,Sentence Segmentation,Stemming,Lemmatization,Tokenization,,GPT,T5,BERT,,T5 is a encoder-decoder mixed models,BERT models are encoder models,GPT-3 is an autoregressive model,,,Data cleaning,,,,,,Separate words into individual morphemes and identify the class of the morphemes,,"Given a sentence or larger chunk of text, determine which words (“mentions”)",,,,,,,,,,,I don't know,This pipeline requires that labels be given to classify this text.,TRUE,,,,All of the above,,The sequence length and the batch size,,,,BPE,,,,,,Attention mechanism is good at context-aware processing,,None of the above,"No, it seems correct.",Find the chunk of words in a sentence that answers a question.,I don't know,Writing short reviews of long documents,,,,,,MobileNet,LeNet,,,VGG,,,I don't know,N/A,N/A,N/A,I don't know,N/A,N/A,,,,,Morphological Gradient,,,,,,,I don't know
1.14424E+11,427913904,09/28/2023 01:37:08 PM,09/28/2023 02:33:31 PM,83.110.1.129,,,,,Carsten Wolff,carsten.wolff@tii.ae,Biotechnology,Exec. Dir. Environmental Biotech,Yes,Yes,No,ChatGPT,bioinformatics applications for biotech will help with pattern detection and modeling.,yes,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,,,To implement generative AI solutions in the lab or production environment,Gain some exposure and jargon in the generative AI field,,No,I do not know Python,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/28/2023 02:21:33 PM,09/28/2023 02:26:42 PM,2.50.149.139,,,,,Nouf AlEissaee,nouf.aleissaee@tii.ae,DERC,Senior associate researcher,Yes,Yes,I do not understand what a prompt is,Email generator,It helps to brainstorm and answers our thoughts,AI email toner,,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,,,,To implement generative AI solutions in the lab or production environment,,,Yes,1-3 months,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/28/2023 02:11:17 PM,09/28/2023 02:24:39 PM,2.50.149.139,,,,,Sultan Abughazal,sultan.abughazal@tii.ae,DERC,Research Associate,Yes,Yes,Yes,"Lamini, ludwig, BERT, FLAN, Falcon",Find pieces of information in large corpuses of text.,Yes.,,,,,,,To implement generative AI solutions in the lab or production environment,,Push the state-of-the-art.,Yes,2+ years,9,"del student[""marks""]","student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,,,def is_palindrome_2(s): return s.lower() == s[::-1].lower(),,adding .drop_duplicates() to employee['salary'],,,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/a8a2caac-d234-4be3-96e6-ab97d88fb9cb.png,,,Inheritance,10,"import re  s = ""Hello! We are super excited to have you join the program to learn about generative AI amongst other things!""  s = re.sub(r'[.,/#!$%^&*;:{}=-_`~()]', """", s.lower()).split(' ')  print({w: len([0 for i in range(len(s)) if s[i]==w]) for w in s})",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/28/2023 02:15:40 PM,09/28/2023 02:19:40 PM,83.110.1.129,,,,,Redoine ZOUITIN,redoine.zouitin@tii.ae,ATRC,Senior Project Manager,Yes,Yes,No,"Chat GPT, CareerFlow, Wix",I'm convinced that AI could improve productivity by handling basic and repetitive tasks. ,"Scheduling meetings, booking meeting rooms or travels, market surveys, competition analysis, to understand specific jargons, get information about a customer or a project, regulation analysis ",To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,,,,,Gain some exposure and jargon in the generative AI field,,No,I do not know Python,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/28/2023 02:10:24 PM,09/28/2023 02:12:50 PM,83.110.1.129,,,,,Rahul Lakhwat,rahul.lakhawat@tii.ae,SSRC,Lead Program Manager,Yes,Yes,Yes,"Chatgpt, Bard","summarizing, ideation, formualtion of complex topics etc. ",1. Use to create attractive & precise project description & summaries,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,,,,,,,No,I do not know Python,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/28/2023 02:03:08 PM,09/28/2023 02:11:43 PM,83.110.1.129,,,,,Redoine ZOUITIN,redoine.zouitin@tii.ae,ATRC,Senior Project Manager,Yes,Yes,No,"Careerflow, Chat GPT, wix","find accurate information about a project, competition, a customer, a product. Understand very specific technical jargon etc...","market studies, regulations analysis, competition surveys",To have a solid understanding of the concepts and trends in generative AI,,To be self-sufficient with no-code AI tools for business,,,,,Gain some exposure and jargon in the generative AI field,,Yes,3 months to 1 year,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14423E+11,427913904,09/28/2023 01:44:15 PM,09/28/2023 02:07:48 PM,2.50.149.139,,,,,Anas Malas,anas.malas@tii.ae,DERC,Electronics Associate Engineer,Yes,Yes,Yes,"ChatGPT 3-4, Midjourny, DallE 2, DallE mini","They help me find information faster, build clearer connections between things, and organize myself.","Most of my job is a generative AI use case. Make a device's block diagram, turn it into a schematic, turn that into PCB and order that. Build the enclosure for it and send it off to the 3D printer. Take everything and put it into a powerpoint that explains the why-what-and how. The question is how long until it gets better than me.",To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,,,,To implement generative AI solutions in the lab or production environment,,,Yes,1-3 months,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/28/2023 01:58:47 PM,09/28/2023 02:06:59 PM,2.50.155.109,,,,,Abrar Alhammadi,abrar.alhammadi@tii.ae,PSRC,Senior associate researcher,Yes,Yes,Yes,I have tried ChatGPT casually ,help with running simulations and checking the quality of the results,let AI tell me what settings I need to use in ANSYS simulations and whether my results are good or need to be modified ,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,,,,,,No,I do not know Python,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14423E+11,427913904,09/28/2023 01:50:42 PM,09/28/2023 02:00:18 PM,2.50.149.139,,,,,Giuseppe Scurria,giuseppe.scurria@tii.ae,Directed Energy Research Center,Lead Researcher,Yes,Yes,No,Chat GPT,#NAME?,#NAME?,,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,,"To learn how to build NLP, LLM, or Computer Vision models",,,,Yes,1-2 years,7,,"student.pop(""marks"")",,,10 Chair 10 Table 20 Chair 20 Table,Yna PYnat tive PYnativ PYnativ,def is_palindrome(s): return s == s[::-1],,,,,,,I don't know,,,https://surveymonkey-assets.s3.amazonaws.com/survey/409515070/rte/4b0a1e6b-c3dd-48f4-9437-0286177c6d83.png,,I don't know,3,N/A,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14424E+11,427913904,09/28/2023 01:53:42 PM,09/28/2023 01:58:27 PM,217.164.230.18,,,,,Jiguang He,jiguang.he@tii.ae,AIDRC,Senior Researcher ,Yes,Yes,No,"Python, PyTorch, Keras","Yes, of course.","literature review, generate simulation codes, and also modify/enhance my written texts.  ",To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,Gain some exposure and jargon in the generative AI field,,Yes,1-3 months,7,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14423E+11,427913904,09/28/2023 01:51:36 PM,09/28/2023 01:53:03 PM,83.110.1.129,,,,,Tasneim Aldhanhani,tasneim.aldhanhani@tii.ae,DSRC,Researcher,Yes,Yes,Yes,Chat GPT,Perform the work faster.,Yes,To have a solid understanding of the concepts and trends in generative AI,,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,Gain some exposure and jargon in the generative AI field,,Yes,3 months to 1 year,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14423E+11,427913904,09/28/2023 01:41:38 PM,09/28/2023 01:50:31 PM,83.110.1.129,,,,,Himank Gupta,himank.gupta@tii.ae,ARRC,Research Engineer,Yes,Yes,Yes,"Preplexity, Chatgpt, Bard","Since ChatGPT was only trained up until 2021, it can only provide obsolete responses to the vast majority of technical questions.   Writing scripts is a skill that comes in handy when working with video. ","Errors in communication should serve as a prompt for generative AI, and the output should be a troubleshooting option. ",To have a solid understanding of the concepts and trends in generative AI,,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,Yes,3 months to 1 year,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14423E+11,427913904,09/28/2023 01:40:03 PM,09/28/2023 01:49:34 PM,185.25.79.186,,,,,Damien De Maya,damien.demaya@tii.ae,SSRC,Lead Program Manager,Yes,No,No,None,It can support tasks such as internet search and provide tailored reports.,No,,To learn how to use prompting to make myself more efficient at work,,,To learn how to fine-tune and apply AI models for my business domains,,,Gain some exposure and jargon in the generative AI field,,Yes,1-3 months,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14423E+11,427913904,09/28/2023 01:48:11 PM,09/28/2023 01:49:32 PM,2.50.149.139,,,,,Aaesha,aaesha.alali@tii.ae,DERC,Senior Associate researcher,Yes,No,Yes,"ChatGPT, Dall-E",#NAME?,-,,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,,,To implement generative AI solutions in the lab or production environment,,,No,1-3 months,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14423E+11,427913904,09/28/2023 01:45:55 PM,09/28/2023 01:47:14 PM,83.110.1.129,,,,,Natalia Ghisi,natalia.ghisi@tii.ae,PSRC,Engineer,Yes,Yes,Yes,"ChatGPT, MidJourney, Canva Image generator and other image generators",task automation and algorithmic engineering,Algorithmic engineering,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,,,To implement generative AI solutions in the lab or production environment,,,Yes,1-3 months,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14423E+11,427913904,09/28/2023 01:37:02 PM,09/28/2023 01:46:25 PM,2.50.149.139,,,,,Aaesha,aaesha.alali@tii.ae,DERC,Senior Associate researcher,Yes,No,Yes,"ChatGPT, DELL-E",Doing math calculations and post-processing the data,-,,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,,To implement generative AI solutions in the lab or production environment,,,No,1-3 months,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14423E+11,427913904,09/28/2023 01:41:10 PM,09/28/2023 01:45:23 PM,2.50.149.139,,,,,Sultan Abughazal,sultan.abughazal@tii.ae,DERC,Research Associate,Yes,Yes,Yes,"BERT, FLAN, Lamini, ludwig.",Finding pieces of information from a large corpus of text.,Yes.,,,,,,,To implement generative AI solutions in the lab or production environment,,Push the state-of-the-art.,Yes,2+ years,9,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14423E+11,427913904,09/28/2023 01:44:12 PM,09/28/2023 01:45:14 PM,2.50.149.139,,,,,Oginne Lapuz,oginne.lapuz@tii.ae,DERC,Senior Electronics Engineer,Yes,Yes,Yes,"DALL-E, ChatGPT",It will assist with faster research.,None for now,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,,"To learn how to build NLP, LLM, or Computer Vision models",,,,Yes,2+ years,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14423E+11,427913904,09/28/2023 01:35:54 PM,09/28/2023 01:44:53 PM,83.110.1.129,,,,,Brahim Farhat,brahim.farhat@tii.ae,AIDRC,Researcher ,Yes,Yes,Yes,ChatGPT,"It can enhance our coding style,   Give suggestion to tackle certain problems    There are many verticals that chatgpt can enhance for me. To be precise, it makes my time much more efficient.","There are many related to XR applications. Also, many for Fleet Control System. ",To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,Yes,1-2 years,4,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14423E+11,427913904,09/28/2023 01:35:28 PM,09/28/2023 01:44:26 PM,83.110.1.129,,,,,Nayan Wadhwani,nayan.wadhwani@tii.ae,BRC,Intern,Yes,Yes,Yes,capcut.ai  chatgpt,I think academically it helps a lot in terms of paraphrasing. ,It can be used to create synthetic MRI data using GAN diffusion models .,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",To implement generative AI solutions in the lab or production environment,,,Yes,1-3 months,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14423E+11,427913904,09/28/2023 01:41:33 PM,09/28/2023 01:44:17 PM,83.110.1.129,,,,,Natalia Ghisi,natalia.ghisi@tii.ae,PSRC,Engineer,Yes,Yes,No,"ChatGPT, MidJourney, Canva AI image generator, and other AI image generators","It can automate tasks, help to write and correct texts, collect and analyze data and improve algorithmic engineering for creating complex geometries",In the application of algorithmic engineering to create design tools,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,,,To implement generative AI solutions in the lab or production environment,,,Yes,1-3 months,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14423E+11,427913904,09/28/2023 01:35:26 PM,09/28/2023 01:43:27 PM,2.50.149.139,,,,,Oginne Lapuz,oginne.lapuz@tii.ae,DERC,Senior Electronics Engineer,Yes,Yes,Yes,"Dall-E, ChatGPT, Midjourney",It will help assist me in researching certain topics and implementing work faster.  ,Nothing as of this moment,To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,,To gain technical experience with machine learning and AI,,"To learn how to build NLP, LLM, or Computer Vision models",,,,Yes,2+ years,3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14423E+11,427913904,09/28/2023 01:36:01 PM,09/28/2023 01:41:39 PM,83.110.1.129,,,,,Tasneim Aldhanhani,tasneim.aldhanhani@tii.ae,DSRC,Researcher,Yes,Yes,Yes,#NAME?,"It can help in perform the job faster, however security must be considered. ",Yes.,To have a solid understanding of the concepts and trends in generative AI,,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,To learn how to fine-tune and apply AI models for my business domains,"To learn how to build NLP, LLM, or Computer Vision models",,,,No,I do not know Python,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1.14423E+11,427913904,09/28/2023 01:35:43 PM,09/28/2023 01:40:10 PM,83.110.1.129,,,,,Natalia Ghisi,natalia.ghisi@tii.ae,PSRC,Engineer,Yes,Yes,No,"ChatGPT, MidJourney, Canva AI image generator, DeepAI image generator","To automate tasks, search and filter data, revise and correct texts, prepare presentations and images for paper and presentations.  To improve algorithmic engineering tools to create complex designs","Yes, to improve algorithmic engineering tools to create complex designs",To have a solid understanding of the concepts and trends in generative AI,To learn how to use prompting to make myself more efficient at work,To be self-sufficient with no-code AI tools for business,To gain technical experience with machine learning and AI,,,To implement generative AI solutions in the lab or production environment,,,Yes,1-3 months,2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
